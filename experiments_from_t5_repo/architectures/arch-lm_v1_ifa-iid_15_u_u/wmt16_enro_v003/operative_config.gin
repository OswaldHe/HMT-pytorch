import mesh_tensorflow.optimize
import mesh_tensorflow.transformer.learning_rate_schedules
import mesh_tensorflow.transformer.transformer_layers
import t5.models.mesh_transformer
import t5.data.sentencepiece_vocabulary

# Macros:
# ==============================================================================
d_ff = 3072
d_kv = 64
d_model = 768
dropout_rate = 0.1
MIXTURE_NAME = 'wmt16_enro_v003'
num_heads = 12
num_layers = 12
model_parallelism = 1
split= "train"
tokens_per_batch = 65536

# Parameters for AdafactorOptimizer:
# ==============================================================================
AdafactorOptimizer.beta1 = 0.0
AdafactorOptimizer.clipping_threshold = 1.0
AdafactorOptimizer.decay_rate = None
AdafactorOptimizer.epsilon1 = 1e-30
AdafactorOptimizer.epsilon2 = 0.001
AdafactorOptimizer.factored = True
AdafactorOptimizer.min_dim_size_to_factor = 128
AdafactorOptimizer.multiply_by_parameter_scale = True

# Parameters for constant_learning_rate:
# ==============================================================================
constant_learning_rate.learning_rate = 0.001

# Parameters for DenseReluDense:
# ==============================================================================
DenseReluDense.dropout_rate = %dropout_rate
DenseReluDense.hidden_size = %d_ff

# Parameters for get_dataset:
# ==============================================================================

# Parameters for get_sentencepiece_model_path:
# ==============================================================================
get_sentencepiece_model_path.mixture_or_task_name = %MIXTURE_NAME

# Parameters for get_variable_dtype:
# ==============================================================================
get_variable_dtype.activation_dtype = 'bfloat16'

# Parameters for LayerStack:
# ==============================================================================
LayerStack.dropout_rate = %dropout_rate
LayerStack.norm_epsilon = 1e-06

# Parameters for make_layer_stack:
# ==============================================================================
make_layer_stack.block_scope = True
make_layer_stack.layers = \
    [@mesh_tensorflow.transformer.transformer_layers.SelfAttention,
     @mesh_tensorflow.transformer.transformer_layers.DenseReluDense]
make_layer_stack.num_layers = %num_layers

# Parameters for mesh_train_dataset_fn:
# ==============================================================================
mesh_train_dataset_fn.mixture_or_task_name = %MIXTURE_NAME

# Parameters for pack_dataset:
# ==============================================================================

# Parameters for pack_or_pad:
# ==============================================================================
# None.

# Parameters for run:
# ==============================================================================
run.autostack = True
run.batch_size = ('tokens_per_batch', %tokens_per_batch)
run.dataset_split = %split
run.ensemble_inputs = None
run.eval_checkpoint_step = None
run.eval_dataset_fn = None
run.eval_summary_dir = None
run.export_path = ''
run.iterations_per_loop = 100
run.keep_checkpoint_max = None
run.layout_rules = \
    'ensemble:ensemble,batch:batch,d_ff:model,heads:model,vocab:model,experts:batch'
run.learning_rate_schedule = @learning_rate_schedules.constant_learning_rate
run.mesh_shape = @mesh_tensorflow.transformer.utils.tpu_mesh_shape()
run.mode = 'train'
run.model_type = 'lm'
run.optimizer = @optimize.AdafactorOptimizer
run.perplexity_eval_steps = 10
run.predict_fn = None
run.save_checkpoints_steps = 5000
run.sequence_length = {'inputs': 512, 'targets': 512}
run.train_dataset_fn = @t5.models.mesh_transformer.mesh_train_dataset_fn
run.train_steps = 786432
run.variable_filter = None
run.vocabulary = @t5.data.sentencepiece_vocabulary.SentencePieceVocabulary()

# Parameters for SelfAttention:
# ==============================================================================
SelfAttention.attention_kwargs = None
SelfAttention.dropout_rate = %dropout_rate
SelfAttention.key_value_size = %d_kv
SelfAttention.num_heads = %num_heads
SelfAttention.num_memory_heads = 0
SelfAttention.relative_attention_num_buckets = 32
SelfAttention.relative_attention_type = 'bias_shared'
SelfAttention.shared_kv = False

# Parameters for SentencePieceVocabulary:
# ==============================================================================
SentencePieceVocabulary.extra_ids = 100
SentencePieceVocabulary.sentencepiece_model_file = \
    @t5.models.mesh_transformer.get_sentencepiece_model_path()

# Parameters for serialize_num_microbatches:
# ==============================================================================
serialize_num_microbatches.tokens_per_microbatch_per_replica = 2048

# Parameters for tpu_estimator_model_fn:
# ==============================================================================
tpu_estimator_model_fn.outer_batch_size = 1
tpu_estimator_model_fn.tpu_summaries = False
tpu_estimator_model_fn.init_checkpoint = %init_checkpoint

# Parameters for tpu_mesh_shape:
# ==============================================================================
tpu_mesh_shape.ensemble_parallelism = None
tpu_mesh_shape.model_parallelism = %model_parallelism
tpu_mesh_shape.tpu_topology = %tpu_topology

# Parameters for Unitransformer:
# ==============================================================================
Unitransformer.d_model = %d_model
Unitransformer.ensemble = None
Unitransformer.input_full_attention = True
Unitransformer.label_smoothing = 0.0
Unitransformer.loss_denominator = None
Unitransformer.loss_fn = None
Unitransformer.loss_on_targets_only = False
Unitransformer.max_length = 512
Unitransformer.name = 'transformer'
Unitransformer.positional_embedding = False
Unitransformer.shared_embedding_and_softmax_weights = True
Unitransformer.vocab_divisor = 128
Unitransformer.z_loss = 0.0001
