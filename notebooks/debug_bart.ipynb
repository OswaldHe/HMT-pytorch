{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa87f4-b3aa-4f36-8a90-0f43c1150536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e7c8d16-69ab-4b37-bbed-07572bfcf479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# from megatron.data.dataset_utils import get_indexed_dataset_\n",
    "\n",
    "import horovod.torch as hvd\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "import datasets\n",
    "from huggingface_hub import hf_hub_download\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from trainer import Trainer, TrainerArgs\n",
    "\n",
    "\n",
    "import transformers  # noqa: E402\n",
    "from transformers import AutoConfig, AutoTokenizer, HfArgumentParser  # noqa: E402\n",
    "\n",
    "from utils import collect_run_configuration, get_cls_by_name, get_optimizer  # noqa: E402\n",
    "import optimizers  # noqa: E402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "3a8e5fdb-77df-457d-8748-e7f81d700481",
   "metadata": {},
   "outputs": [],
   "source": [
    "class holder:\n",
    "    pass\n",
    "\n",
    "args = holder\n",
    "args.task_name = 'quality'\n",
    "args.seed = 0\n",
    "args.batch_size = 2\n",
    "args.data_n_workers = 1\n",
    "args.target_seq_len = 10\n",
    "args.gradient_accumulation_steps = 1\n",
    "args.sum_loss = True\n",
    "args.input_seg_size = 512\n",
    "args.input_size = 512\n",
    "args.bptt_depth = -1\n",
    "args.model_attr = 'model'\n",
    "args.source_prefix = ''\n",
    "args.input_seq_len = 512\n",
    "\n",
    "args.num_mem_tokens = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a10990-a8c9-4b6c-8f9f-c5869f848f63",
   "metadata": {},
   "source": [
    "### Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c723aac8-0eb3-456a-b7f8-8d8b992deb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephfs/home/bulatov/bulatov/hvdenv/lib/python3.8/site-packages/cryptography/hazmat/backends/openssl/x509.py:14: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe9fa0ed-739c-4162-bcb7-701dcee64140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6780835-c236-4bea-a762-62f7dbe0c2b6",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3bcb23b1-9a0b-4a67-9add-8b765b7b5619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "config.json\n",
      "events.out.tfevents.1658487760.dgx2.1487056.0\n",
      "events.out.tfevents.1658492318.dgx2.1498274.0\n",
      "model_best.pth\n"
     ]
    }
   ],
   "source": [
    "!ls ../../runs/debug/hyperpartisan_news_detection/facebook/bart-base/lr1e-05_linear_adamw_wd1e-03_512_mem0/run_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6be9ccfa-446d-4f4b-bb85-7f2553fe86f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_path = '../../runs/debug/hyperpartisan_news_detection/facebook/bart-base/lr1e-05_linear_adamw_wd1e-03_512_mem0/run_1/model_best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ad8a042a-9a44-4a32-bed5-1fe9452c7544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling_rmt_enc_dec import RMTEncoderDecoderForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "74563c30-5098-40d7-8a4f-bb88e19b079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration\n",
    "# model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "\n",
    "state_dict = torch.load(cpt_path, map_location='cpu')\n",
    "config = AutoConfig.from_pretrained('facebook/bart-base')\n",
    "model = BartForConditionalGeneration(config)\n",
    "# # model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "06c62ef3-ce8f-4aa8-be91-28158a29b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls ../../runs/debug/hyperpartisan_news_detection/facebook/bart-base/lr1e-05_linear_adamw_wd1e-03_512_mem0/run_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "40481053-21b1-4e5b-a6d2-b542ba5fcb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RMTEncoderDecoderForConditionalGeneration(base_model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e0a8b021-a035-4127-9ca5-9581087c8b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.load_state_dict(state_dict['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b4d4c2b4-7aa2-470c-b9c5-744ec0cf799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_params(num_mem_tokens=args.num_mem_tokens, \n",
    "                input_size=args.input_size,\n",
    "                input_seg_size=args.input_seg_size,\n",
    "                model_attr=args.model_attr,\n",
    "                # backbone_cls=backbone_cls,\n",
    "                sum_loss=args.sum_loss,\n",
    "                bptt_depth=args.bptt_depth, \n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                cls_token_id=tokenizer.cls_token_id, \n",
    "                sep_token_id=tokenizer.sep_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776432fb-3980-4a70-9c43-878289ff254f",
   "metadata": {},
   "source": [
    "### Hyperpartisan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "38d17073-619f-43f0-8d4f-aef211867a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class HyperpartisanDataset(Dataset):\n",
    "    def __init__(self, datafile, x_field='text', label_field='label'):\n",
    "        if isinstance(datafile, str):\n",
    "            # convert str path to folder to Path\n",
    "            datafile = Path(datafile)\n",
    "        self.data = []\n",
    "        for line in datafile.open('r'):\n",
    "            self.data += [json.loads(line)]\n",
    "        self.x_field = x_field\n",
    "        self.label_field = label_field\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx][self.x_field]\n",
    "        label = self.data[idx][self.label_field]\n",
    "        return x, label\n",
    "\n",
    "\n",
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r\"\\b(a|an|the)\\b\", \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8cfecbe3-fad9-431e-b8c8-f443bff94d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_attention_first_token = False  # should be True for LED\n",
    "encode_plus_kwargs = {'truncation': True,\n",
    "                      'padding': 'longest',\n",
    "                      'pad_to_multiple_of': 1}\n",
    "generate_kwargs = {'max_length': args.target_seq_len, 'min_length': args.target_seq_len}\n",
    "\n",
    "def collate_fn(batch):\n",
    "    inputs, labels = zip(*batch)\n",
    "    if args.source_prefix:\n",
    "        inputs = [args.source_prefix + inp for inp in inputs]\n",
    "    features = tokenizer.batch_encode_plus(list(inputs), max_length=args.input_seq_len,\n",
    "                                           return_tensors='pt', **encode_plus_kwargs)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer.batch_encode_plus(list(labels), max_length=args.target_seq_len,\n",
    "                                             return_tensors='pt', **encode_plus_kwargs).input_ids\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    features['labels'] = labels\n",
    "    if 'global_attention_mask' in features:\n",
    "        # features[\"global_attention_mask\"] = [[1] + [0] * (len(attn_mask) - 1) for attn_mask in features[\"attention_mask\"]]\n",
    "        logger.warning('WHAT SHOULD BE HERE FOR LED??')\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f5062ae2-b4d3-4c0e-b92a-cfcbecbbfcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/kuratov/data/hyperpartisan_news_detection/train.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3335e51b-5018-44f4-809d-57d7d198605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hvd.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4fc44edb-d79c-4af4-b494-89c16b960482",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HyperpartisanDataset(data_path)\n",
    "# shuffle train data each epoch (one loop over train_dataset)\n",
    "train_sampler = DistributedSampler(train_dataset, rank=hvd.rank(), num_replicas=hvd.size(), shuffle=True,\n",
    "                                   drop_last=False, seed=args.seed)\n",
    "per_worker_batch_size = args.batch_size * args.gradient_accumulation_steps\n",
    "global_batch_size = per_worker_batch_size * hvd.size()\n",
    "kwargs = {'pin_memory': True, 'num_workers': args.data_n_workers}\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=per_worker_batch_size, sampler=train_sampler,\n",
    "                              collate_fn=collate_fn, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "890b2811-af99-409c-9541-e10508c6138b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "for item in train_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4c6bcfb6-1e18-49e3-920f-f622c55b8fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "src, tgt = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "cb85342e-dead-4a54-823b-aa0b492764d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_plus_kwargs = {'truncation': True,\n",
    "                      'padding': 'longest',\n",
    "                      'pad_to_multiple_of': 1}\n",
    "inp = tokenizer.batch_encode_plus([src], return_tensors='pt', padding='max_length', truncation=True)\n",
    "labels = tokenizer.batch_encode_plus([tgt], return_tensors='pt', padding=False, truncation=True)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9e811d50-dd5f-40e1-861c-1795f73ce5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**inp, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e335e8a3-04ae-492f-82cb-81337606a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = model.generate(**inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "93e4f4d9-13b6-4b34-9368-9d1119c77e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 20]),\n",
       " tensor([[   2,    0, 4148,    5,   97,  865,    6,    5,  433,   34, 1179,    5,\n",
       "          3302,    9,   10, 2235, 2235, 2235,   12,    2]]))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated.shape, generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3e142028-3d09-410e-b509-c11e0b08267c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 20]),\n",
       " tensor([[   2,    0,    6,   61,   16,   10, 3556,   13,    5,  232,    4,  370,\n",
       "           240,   10, 3556,    9,  476,    4,   20,    2]]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated.shape, generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1fff69ed-7120-4bc6-acec-6611d194a36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 20]),\n",
       " tensor([[  2,   0, 113, 170, 348, 300,   7, 120,  66,   9, 259,  60,  26,  65,\n",
       "            9,   5, 917,   4,  22,   2]]))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated.shape, generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8f308915-b4a7-4c74-ba0d-5dc1ed0652e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As seen on The Five Police Group Boycotts Ben &amp; Jerry\\'s After Black Lives Matter Endorsement As more women come forward with allegations of sexual misconduct against Donald Trump, the Republican nominee is lashing out at the mainstream media, which he claims is running with this \"total fiction\" to distract from Hillary Clinton\\'s scandals. At a rally in Greensboro, N.C., Trump said these accusations are part of a conspiracy involving the Clinton campaign and what he called “the corrupt media.” Greg Gutfeld agreed with much of Trump\\'s assessment on \"The Five\" today, saying, \"The media wants Hillary to win. There\\'s no doubt about that.\" Judge Jeanine on Trump Accusers: \\'All on One Day? It\\'s a Little Too Convenient\\' Gutfeld explained that Trump has actually been \"set up,\" as he was given countless hours of coverage and \"billions of dollars of free media,\" only to have the rug pulled out from under him. \"The media . [and] Hillary and Obama, they knew elevating Donald Trump - giving him an air of respectability in the press, as well - turned him into the Republican nominee. Then, out came the knives.\" Watch the co-hosts of \"The Five\" discuss above, and let us know what you think in the comments. New WikiLeaks Bombshell: Clinton Aides Discussed \\'Emails to and from POTUS\\''"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7e9fc3cc-d05b-4d4c-a978-194c1eb8d420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'false'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "90d28ca8-a034-429d-bdbd-664abb1a01e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s><s>On the other hand, the media has raised the possibility of a Clinton Clinton Clinton-</s>']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7da318-ffb2-4e74-85c5-00c184bf6358",
   "metadata": {},
   "source": [
    "###  QuALITy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ff422d72-efd4-4987-9dba-741156a9a388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   0, 1620,  450,  ...,    1,    1,    1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5acca418-ed33-474b-af0f-035ae17455cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bf8caa3-e92a-4f70-9161-116eb3944f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'quality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d16952ed-9ccb-4916-92a5-0972661ff80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # cut too long strings because they may slow down tokenization\n",
    "    inputs = [b['input'][:args.input_seq_len * 10] for b in batch]\n",
    "    labels = [b['output'][:args.target_seq_len * 10] for b in batch]\n",
    "    features = tokenizer.batch_encode_plus(list(inputs), return_tensors='pt', **encode_plus_kwargs)\n",
    "    labels = np.array([labels_map[t] for t in labels])\n",
    "    features['labels'] = torch.from_numpy(labels)\n",
    "    return features\n",
    "\n",
    "dataset = datasets.load_dataset('tau/scrolls', task_name)\n",
    "train_dataset = dataset['train']\n",
    "# shuffle train data each epoch (one loop over train_dataset)\n",
    "train_sampler = DistributedSampler(train_dataset, rank=hvd.rank(), num_replicas=hvd.size(), shuffle=True,\n",
    "                                   drop_last=False, seed=args.seed)\n",
    "\n",
    "kwargs = {'pin_memory': True, 'num_workers': args.data_n_workers}\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, sampler=train_sampler,\n",
    "                              collate_fn=collate_fn, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b8d8ada-f21d-4d50-9e2d-15ec3163d730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get validation dataset\n",
    "valid_dataloader = None\n",
    "valid_dataset = dataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9cc6cac-99fa-4bd2-b6c7-209faa7efa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sampler = DistributedSampler(valid_dataset, rank=1, num_replicas=1, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=2, sampler=valid_sampler,\n",
    "                              collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c166df38-ad7f-4d81-8c85-59f3a72030a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '52995_I3M5VUMM_1',\n",
       " 'pid': '52995_I3M5VUMM_1_0',\n",
       " 'input': 'Why is Si retirement so significant to the Space Exploration Team? \\n\\n (A) There aren’t enough working people in the world. They won’t be able to find a replacement.\\n (B) As one of two remaining spacemen, it would likely mean the defunding and shut down of the Space Exploration Team.\\n (C) Training new spacemen is costly and time consuming. They won’t have anyone else ready after him.\\n (D) His retirement may inspire others to stop working as well, which would be hugely detrimental as most people don\\'t feel the drive to work as is.  \\n\\n\\nSPACEMAN ON A SPREE\\n\\n\\n\\n\\n   BY MACK REYNOLDS\\n\\n\\n\\n\\n   Illustrated by Nodel\\n\\n\\n\\n\\n   What\\'s more important—Man\\'s conquest\\n\\n\\n   of space, or one spaceman\\'s life?\\n\\n\\n\\n\\n\\n\\n   I\\n\\n\\n\\n\\n   They gave him a gold watch. It was meant to be symbolical, of course.\\n In the old tradition. It was in the way of an antique, being one of the\\n timepieces made generations past in the Alpine area of Eur-Asia. Its\\n quaintness lay in the fact that it was wound, not electronically by\\n power-radio, but by the actual physical movements of the bearer, a free\\n swinging rotor keeping the mainspring at a constant tension.\\n\\n\\n\\n\\n   They also had a banquet for him, complete with speeches by such\\n bigwigs of the Department of Space Exploration as Academician Lofting\\n Gubelin and Doctor Hans Girard-Perregaux. There was also somebody\\n from the government who spoke, but he was one of those who were\\n pseudo-elected and didn\\'t know much about the field of space travel\\n nor the significance of Seymour Pond\\'s retirement. Si didn\\'t bother to\\n remember his name. He only wondered vaguely why the cloddy had turned\\n up at all.\\n\\n\\n\\n\\n   In common with recipients of gold watches of a score of generations\\n before him, Si Pond would have preferred something a bit more tangible\\n in the way of reward, such as a few shares of Variable Basic to add to\\n his portfolio. But that, he supposed, was asking too much.\\n\\n\\n\\n\\n   The fact of the matter was, Si knew that his retiring had set them\\n back. They hadn\\'t figured he had enough shares of Basic to see him\\n through decently. Well, possibly he didn\\'t, given their standards.\\n But Space Pilot Seymour Pond didn\\'t have their standards. He\\'d had\\n plenty of time to think it over. It was better to retire on a limited\\n crediting, on a confoundedly limited crediting, than to take the two or\\n three more trips in hopes of attaining a higher standard.\\n\\n\\n\\n\\n   He\\'d had plenty of time to figure it out, there alone in space on the\\n Moon run, there on the Venus or Mars runs. There on the long, long\\n haul to the Jupiter satellites, fearfully checking the symptoms of\\n space cafard, the madness compounded of claustrophobia, monotony,\\n boredom and free fall. Plenty of time. Time to decide that a one\\n room mini-auto-apartment, complete with an autochair and built-in\\n autobar, and with one wall a teevee screen, was all he needed to\\n find contentment for a mighty long time. Possibly somebody like\\n Doc Girard-Perregaux might be horrified at the idea of living in a\\n mini-auto-apartment ... not realizing that to a pilot it was roomy\\n beyond belief compared to the conning tower of a space craft.\\n\\n\\n\\n\\n   No. Even as Si listened to their speeches, accepted the watch and\\n made a halting little talk of his own, he was grinning inwardly. There\\n wasn\\'t anything they could do. He had them now. He had enough Basic to\\n keep him comfortably, by his standards, for the rest of his life. He\\n was never going to subject himself to space cafard again. Just thinking\\n about it, now, set the tic to going at the side of his mouth.\\n\\n\\n\\n\\n   They could count down and blast off, for all he gave a damn.\\n\\n\\n\\n\\n\\n\\n   The gold watch idea had been that of Lofting Gubelin, which was\\n typical, he being in the way of a living anachronism himself. In fact,\\n Academician Gubelin was possibly the only living man on North America\\n who still wore spectacles. His explanation was that a phobia against\\n having his eyes touched prohibited either surgery to remould his\\n eyeballs and cure his myopia, or contact lenses.\\n\\n\\n\\n\\n   That was only an alibi so far as his closest associate, Hans\\n Girard-Perregaux, was concerned. Doctor Girard-Perregaux was convinced\\n Gubelin would have even worn facial hair, had he but a touch more\\n courage. Gubelin longed for yesteryear, a seldom found phenomenon under\\n the Ultrawelfare State.\\n\\n\\n\\n\\n   Slumped in an autochair in the escape room of his Floridian home,\\n Lofting Gubelin scowled at his friend. He said, acidly, \"Any more\\n bright schemes, Hans? I presume you now acknowledge that appealing to\\n the cloddy\\'s patriotism, sentiment and desire for public acclaim have\\n miserably failed.\"\\n\\n\\n\\n\\n   Girard-Perregaux said easily, \"I wouldn\\'t call Seymour Pond a cloddy.\\n In his position, I am afraid I would do the same thing he has.\"\\n\\n\\n\\n\\n   \"That\\'s nonsense, Hans. Zoroaster! Either you or I would gladly take\\n Pond\\'s place were we capable of performing the duties for which he has\\n been trained. There aren\\'t two men on North America—there aren\\'t two\\n men in the world!—who better realize the urgency of continuing our\\n delving into space.\" Gubelin snapped his fingers. \"Like that, either of\\n us would give our lives to prevent man from completely abandoning the\\n road to his destiny.\"\\n\\n\\n\\n\\n   His friend said drily, \"Either of us could have volunteered for pilot\\n training forty years ago, Lofting. We didn\\'t.\"\\n\\n\\n\\n\\n   \"At that time there wasn\\'t such a blistering percentage of funkers\\n throughout this whole blistering Ultrawelfare State! Who could\\n foresee that eventually our whole program would face ending due to\\n lack of courageous young men willing to take chances, willing to face\\n adventure, willing to react to the stimulus of danger in the manner our\\n ancestors did?\"\\n\\n\\n\\n\\n   Girard-Perregaux grunted his sarcasm and dialed a glass of iced tea\\n and tequila. He said, \"Nevertheless, both you and I conform with the\\n present generation in finding it far more pleasant to follow one\\'s\\n way of life in the comfort of one\\'s home than to be confronted with\\n the unpleasantness of facing nature\\'s dangers in more adventurous\\n pastimes.\"\\n\\n\\n\\n\\n   Gubelin, half angry at his friend\\'s argument, leaned forward to snap\\n rebuttal, but the other was wagging a finger at him negatively. \"Face\\n reality, Lofting. Don\\'t require or expect from Seymour Pond more\\n than is to be found there. He is an average young man. Born in our\\n Ultrawelfare State, he was guaranteed his fundamental womb-to-tomb\\n security by being issued that minimum number of Basic shares in our\\n society that allows him an income sufficient to secure the food,\\n clothing, shelter, medical care and education to sustain a low level\\n of subsistence. Percentages were against his ever being drafted\\n into industry. Automation being what it is, only a fraction of the\\n population is ever called up. But Pond was. His industrial aptitude\\n dossier revealed him a possible candidate for space pilot, and it was\\n you yourself who talked him into taking the training ... pointing out\\n the more pragmatic advantages such as complete retirement after but six\\n trips, added shares of Basic so that he could enjoy a more comfortable\\n life than most and the fame that would accrue to him as one of the\\n very few who still participate in travel to the planets. Very well.\\n He was sold. Took his training, which, of course, required long years\\n of drudgery to him. Then, performing his duties quite competently, he\\n made his six trips. He is now legally eligible for retirement. He was\\n drafted into the working force reserves, served his time, and is now\\n free from toil for the balance of his life. Why should he listen to\\n our pleas for a few more trips?\"\\n\\n\\n\\n\\n   \"But has he no spirit of adventure? Has he no feeling for....\"\\n\\n\\n\\n\\n\\n\\n   Girard-Perregaux was wagging his finger again, a gesture that,\\n seemingly mild though it was, had an astonishing ability to break off\\n the conversation of one who debated with the easy-seeming, quiet spoken\\n man.\\n\\n\\n\\n\\n   He said, \"No, he hasn\\'t. Few there are who have, nowadays. Man has\\n always paid lip service to adventure, hardships and excitement, but in\\n actuality his instincts, like those of any other animal, lead him to\\n the least dangerous path. Today we\\'ve reached the point where no one\\n need face danger—ever. There are few who don\\'t take advantage of the\\n fact. Including you and me, Lofting, and including Seymour Pond.\"\\n\\n\\n\\n\\n   His friend and colleague changed subjects abruptly, impatiently. \"Let\\'s\\n leave this blistering jabber about Pond\\'s motivation and get to the\\n point. The man is the only trained space pilot in the world. It will\\n take months, possibly more than a year, to bring another novitiate\\n pilot to the point where he can safely be trusted to take our next\\n explorer craft out. Appropriations for our expeditions have been\\n increasingly hard to come by—even though in\\n\\n\\n    our\\n\\n\\n   minds, Hans, we are\\n near important breakthroughs, breakthroughs which might possibly so\\n spark the race that a new dream to push man out to the stars will take\\n hold of us. If it is admitted that our organization has degenerated\\n to the point that we haven\\'t a single pilot, then it might well be\\n that the Economic Planning Board, and especially those cloddies\\n on Appropriations, will terminate the whole Department of Space\\n Exploration.\"\\n\\n\\n\\n\\n   \"So....\" Girard-Perregaux said gently.\\n\\n\\n\\n\\n   \"So some way we\\'ve got to bring Seymour Pond out of his retirement!\"\\n\\n\\n\\n\\n   \"Now we are getting to matters.\" Girard-Perregaux nodded his agreement.\\n Looking over the rim of his glass, his eyes narrowed in thought as his\\n face took on an expression of Machiavellianism. \"And do not the ends\\n justify the means?\"\\n\\n\\n\\n\\n   Gubelin blinked at him.\\n\\n\\n\\n\\n   The other chuckled. \"The trouble with you, Lofting, is that you have\\n failed to bring history to bear on our problem. Haven\\'t you ever read\\n of the sailor and his way of life?\"\\n\\n\\n\\n\\n   \"Sailor? What in the name of the living Zoroaster has the sailor got to\\n do with it?\"\\n\\n\\n\\n\\n   \"You must realize, my dear Lofting, that our Si Pond is nothing more\\n than a latter-day sailor, with many of the problems and view-points,\\n tendencies and weaknesses of the voyager of the past. Have you never\\n heard of the seaman who dreamed of returning to the village of his\\n birth and buying a chicken farm or some such? All the long months at\\n sea—and sometimes the tramp freighters or whaling craft would be out\\n for years at a stretch before returning to home port—he would talk\\n of his retirement and his dream. And then? Then in port, it would be\\n one short drink with the boys, before taking his accumulated pay and\\n heading home. The one short drink would lead to another. And morning\\n would find him, drunk, rolled, tattooed and possibly sleeping it off in\\n jail. So back to sea he\\'d have to go.\"\\n\\n\\n\\n\\n   Gubelin grunted bitterly. \"Unfortunately, our present-day sailor\\n can\\'t be separated from his money quite so easily. If he could, I\\'d\\n personally be willing to lure him down some dark alley, knock him over\\n the head and roll him myself. Just to bring him back to his job again.\"\\n\\n\\n\\n\\n   He brought his wallet from his pocket, and flicked it open to his\\n universal credit card. \"The ultimate means of exchange,\" he grunted.\\n \"Nobody can spend your money, but you, yourself. Nobody can steal it,\\n nobody can, ah,\\n\\n\\n    con\\n\\n\\n   you out of it. Just how do you expect to sever\\n our present-day sailor and his accumulated nest egg?\"\\n\\n\\n\\n\\n   The other chuckled again. \"It is simply a matter of finding more modern\\n methods, my dear chap.\"\\n\\n\\n\\n\\n\\n\\n   II\\n\\n\\n\\n\\n   Si Pond was a great believer in the institution of the spree. Any\\n excuse would do. Back when he had finished basic education at the age\\n of twenty-five and was registered for the labor draft, there hadn\\'t\\n been a chance in a hundred that he\\'d have the bad luck to have his\\n name pulled. But when it had been, Si had celebrated.\\n\\n\\n\\n\\n   When he had been informed that his physical and mental qualifications\\n were such that he was eligible for the most dangerous occupation in\\n the Ultrawelfare State and had been pressured into taking training\\n for space pilot, he had celebrated once again. Twenty-two others had\\n taken the training with him, and only he and Rod Cameroon had passed\\n the finals. On this occasion, he and Rod had celebrated together. It\\n had been quite a party. Two weeks later, Rod had burned on a faulty\\n take-off on what should have been a routine Moon run.\\n\\n\\n\\n\\n   Each time Si returned from one of his own runs, he celebrated. A spree,\\n a bust, a bat, a wing-ding, a night on the town. A commemoration of\\n dangers met and passed.\\n\\n\\n\\n\\n   Now it was all over. At the age of thirty he was retired. Law prevented\\n him from ever being called up for contributing to the country\\'s labor\\n needs again. And he most certainly wasn\\'t going to volunteer.\\n\\n\\n\\n\\n   He had taken his schooling much as had his contemporaries. There wasn\\'t\\n any particular reason for trying to excell. You didn\\'t want to get the\\n reputation for being a wise guy, or a cloddy either. Just one of the\\n fellas. You could do the same in life whether you really studied or\\n not. You had your Inalienable Basic stock, didn\\'t you? What else did\\n you need?\\n\\n\\n\\n\\n   It had come as a surprise when he\\'d been drafted for the labor force.\\n\\n\\n\\n\\n   In the early days of the Ultrawelfare State, they had made a mistake\\n in adapting to the automation of the second industrial revolution.\\n They had attempted to give everyone work by reducing the number of\\n working hours in the day, and the number of working days in the week.\\n It finally became ludicrous when employees of industry were working\\n but two days a week, two hours a day. In fact, it got chaotic. It\\n became obvious that it was more practical to have one worker putting in\\n thirty-five hours a week and getting to know his job well, than it was\\n to have a score of employees, each working a few hours a week and none\\n of them ever really becoming efficient.\\n\\n\\n\\n\\n   The only fair thing was to let the technologically unemployed remain\\n unemployed, with their Inalienable Basic stock as the equivalent of\\n unemployment insurance, while the few workers still needed put in a\\n reasonable number of hours a day, a reasonable number of weeks a year\\n and a reasonable number of years in a life time. When new employees\\n were needed, a draft lottery was held.\\n\\n\\n\\n\\n   All persons registered in the labor force participated. If you\\n were drawn, you must need serve. The dissatisfaction those chosen\\n might feel at their poor luck was offset by the fact that they were\\n granted additional Variable Basic shares, according to the tasks\\n they fulfilled. Such shares could be added to their portfolios, the\\n dividends becoming part of their current credit balance, or could be\\n sold for a lump sum on the market.\\n\\n\\n\\n\\n   Yes, but now it was all over. He had his own little place, his own\\n vacuum-tube vehicle and twice the amount of shares of Basic that most\\n of his fellow citizens could boast. Si Pond had it made. A spree was\\n obviously called for.\\n\\n\\n\\n\\n   He was going to do this one right. This was the big one. He\\'d\\n accumulated a lot of dollars these past few months and he intended\\n to blow them, or at least a sizeable number of them. His credit card\\n was burning a hole in his pocket, as the expression went. However, he\\n wasn\\'t going to rush into things. This had to be done correctly.\\n\\n\\n\\n\\n   Too many a spree was played by ear. You started off with a few drinks,\\n fell in with some second rate mopsy and usually wound up in a third\\n rate groggery where you spent just as much as though you\\'d been in the\\n classiest joint in town. Came morning and you had nothing to show for\\n all the dollars that had been spent but a rum-head.\\n\\n\\n\\n\\n   Thus, Si was vaguely aware, it had always been down through the\\n centuries since the Phoenecian sailor, back from his year-long trip to\\n the tin mines of Cornwall, blew his hard earned share of the voyage\\'s\\n profits in a matter of days in the wine shops of Tyre. Nobody gets\\n quite so little for his money as that loneliest of all workers, he who\\n must leave his home for distant lands, returning only periodically and\\n usually with the salary of lengthy, weary periods of time to be spent\\n hurriedly in an attempt to achieve the pleasure and happiness so long\\n denied him.\\n\\n\\n\\n\\n   Si was going to do it differently this time.\\n\\n\\n\\n\\n   Nothing but the best. Wine, women, song, food, entertainment. The\\n works. But nothing but the best.\\n\\n\\n\\n\\n\\n\\n   To start off, he dressed with great care in the honorable\\n retirement-rank suit he had so recently purchased. His space pin he\\n attached carefully to the lapel. That was a good beginning, he decided.\\n A bit of prestige didn\\'t hurt you when you went out on the town. In\\n the Ultrawelfare State hardly one person in a hundred actually ever\\n performed anything of value to society. The efforts of most weren\\'t\\n needed. Those few who did contribute were awarded honors, decorations,\\n titles.\\n\\n\\n\\n\\n   Attired satisfactorily, Si double-checked to see that his credit\\n card was in his pocket. As an after-thought, he went over to the\\n auto-apartment\\'s teevee-phone, flicked it on, held the card to the\\n screen and said, \"Balance check, please.\"\\n\\n\\n\\n\\n   In a moment, the teevee-phone\\'s robot voice reported, \"Ten shares of\\n Inalienable Basic. Twelve shares of Variable Basic, current value, four\\n thousand, two hundred and thirty-three dollars and sixty-two cents\\n apiece. Current cash credit, one thousand and eighty-four dollars.\" The\\n screen went dead.\\n\\n\\n\\n\\n   One thousand and eighty-four dollars. That was plenty. He could safely\\n spend as much as half of it, if the spree got as lively as he hoped it\\n would. His monthly dividends were due in another week or so, and he\\n wouldn\\'t have to worry about current expenses. Yes, indeedy, Si Pond\\n was as solvent as he had ever been in his thirty years.\\n\\n\\n\\n\\n   He opened the small, closet-like door which housed his vacuum-tube\\n two-seater, and wedged himself into the small vehicle. He brought down\\n the canopy, dropped the pressurizer and considered the dial. Only one\\n place really made sense. The big city.\\n\\n\\n\\n\\n   He considered for a moment, decided against the boroughs of Baltimore\\n and Boston, and selected Manhattan instead. He had the resources. He\\n might as well do it up brown.\\n\\n\\n\\n\\n   He dialed Manhattan and felt the sinking sensation that presaged his\\n car\\'s dropping to tube level. While it was being taken up by the robot\\n controls, being shuttled here and there preparatory to the shot to his\\n destination, he dialed the vehicle\\'s teevee-phone for information on\\n the hotels of the island of the Hudson. He selected a swank hostelry\\n he\\'d read about and seen on the teevee casts of society and celebrity\\n gossip reporters, and dialed it on the car\\'s destination dial.\\n\\n\\n\\n\\n   \"Nothing too good for ex-Space Pilot Si Pond,\" he said aloud.\\n\\n\\n\\n\\n   The car hesitated for a moment, that brief hesitation before the\\n shot, and Si took the involuntary breath from which only heroes could\\n refrain. He sank back slowly into the seat. Moments passed, and the\\n direction of the pressure was reversed.\\n\\n\\n\\n\\n   Manhattan. The shuttling began again, and one or two more traversing\\n sub-shots. Finally, the dash threw a green light and Si opened the\\n canopy and stepped into his hotel room.\\n\\n\\n\\n\\n   A voice said gently, \"If the quarters are satisfactory, please present\\n your credit card within ten minutes.\"\\n\\n\\n\\n\\n   Si took his time. Not that he really needed it. It was by far the most\\n swank suite he had ever seen. One wall was a window of whatever size\\n the guest might desire and Si touched the control that dilated it to\\n the full. His view opened in such wise that he could see both the\\n Empire State Building Museum and the Hudson. Beyond the river stretched\\n the all but endless city which was Greater Metropolis.\\n\\n\\n\\n\\n   He didn\\'t take the time to flick on the menu, next to the auto-dining\\n table, nor to check the endless potables on the autobar list. All that,\\n he well knew, would be superlative. Besides, he didn\\'t plan to dine\\n or do much drinking in his suite. He made a mock leer. Not unless he\\n managed to acquire some feminine companionship, that was.\\n\\n\\n\\n\\n   He looked briefly into the swimming pool and bath, then flopped\\n himself happily onto the bed. It wasn\\'t up to the degree of softness\\n he presently desired, and he dialed the thing to the ultimate in that\\n direction so that with a laugh he sank almost out of sight into the\\n mattress.\\n\\n\\n\\n\\n   He came back to his feet, gave his suit a quick patting so that it\\n fell into press and, taking his credit card from his pocket, put it\\n against the teevee-phone screen and pressed the hotel button so that\\n registration could be completed.\\n\\n\\n\\n\\n   For a moment he stood in the center of the floor, in thought. Take it\\n easy, Si Pond, take it all easy, this time. No throwing his dollars\\n around in second-class groggeries, no eating in automated luncheterias.\\n This time, be it the only time in his life, he was going to frolic in\\n the grand manner. No cloddy was Si Pond.\\n\\n\\n\\n\\n   He decided a drink was in order to help him plan his strategy. A drink\\n at the hotel\\'s famous Kudos Room where celebrities were reputed to be a\\n dime a dozen.\\n\\n\\n\\n\\n   He left the suite and stepped into one of the elevators. He said,\\n \"Kudos Room.\"\\n\\n\\n\\n\\n   The auto-elevator murmured politely, \"Yes, sir, the Kudos Room.\"\\n\\n\\n\\n\\n\\n\\n   At the door to the famous rendezvous of the swankiest set, Si paused a\\n moment and looked about. He\\'d never been in a place like this, either.\\n However, he stifled his first instinct to wonder about what this was\\n going to do to his current credit balance with an inner grin and made\\n his way to the bar.\\n\\n\\n\\n\\n   There was actually a bartender.\\n\\n\\n\\n\\n   Si Pond suppressed his astonishment and said, offhand, attempting an\\n air of easy sophistication, \"Slivovitz Sour.\"\\n\\n\\n\\n\\n   \"Yes, sir.\"\\n\\n\\n\\n\\n   The drinks in the Kudos Room might be concocted by hand, but Si noticed\\n they had the routine teevee screens built into the bar for payment.\\n He put his credit card on the screen immediately before him when the\\n drink came, and had to quell his desire to dial for a balance check, so\\n as to be able to figure out what the Sour had cost him.\\n\\n\\n\\n\\n   Well, this was something like it. This was the sort of thing he\\'d\\n dreamed about, out there in the great alone, seated in the confining\\n conning tower of his space craft. He sipped at the drink, finding it up\\n to his highest expectations, and then swiveled slightly on his stool to\\n take a look at the others present.\\n\\n\\n\\n\\n   To his disappointment, there were no recognizable celebrities. None\\n that he placed, at least—top teevee stars, top politicians of the\\n Ultrawelfare State or Sports personalities.\\n\\n\\n\\n\\n   He turned back to his drink and noticed, for the first time, the girl\\n who occupied the stool two down from him. Si Pond blinked. He blinked\\n and then swallowed.\\n\\n\\n\\n\\n   \"\\n\\n\\n    Zo-ro-as-ter\\n\\n\\n   ,\" he breathed.\\n\\n\\n\\n\\n   She was done in the latest style from Shanghai, even to the point of\\n having cosmetically duplicated the Mongolian fold at the corners of her\\n eyes. Every pore, but\\n\\n\\n    every\\n\\n\\n   pore, was in place. She sat with the easy\\n grace of the Orient, so seldom found in the West.\\n\\n\\n\\n\\n   His stare couldn\\'t be ignored.\\n\\n\\n\\n\\n   She looked at him coldly, turned to the bartender and murmured, \"A Far\\n Out Cooler, please, Fredric.\" Then deliberately added, \"I thought the\\n Kudos Room was supposed to be exclusive.\"\\n\\n\\n\\n\\n   There was nothing the bartender could say to that, and he went about\\n building the drink.\\n\\n\\n\\n\\n   Si cleared his throat. \"Hey,\" he said, \"how about letting this one be\\n on me?\"\\n\\n\\n\\n\\n   Her eyebrows, which had been plucked and penciled to carry out her\\n Oriental motif, rose. \"Really!\" she said, drawing it out.\\n\\n\\n\\n\\n   The bartender said hurriedly, \"I beg your pardon, sir....\"\\n\\n\\n\\n\\n   The girl, her voice suddenly subtly changed, said, \"Why, isn\\'t that a\\n space pin?\"\\n\\n\\n\\n\\n   Si, disconcerted by the sudden reversal, said, \"Yeah ... sure.\"\\n\\n\\n\\n\\n   \"Good Heavens, you\\'re a spaceman?\"\\n\\n\\n\\n\\n   \"Sure.\" He pointed at the lapel pin. \"You can\\'t wear one unless you\\n been on at least a Moon run.\"\\n\\n\\n\\n\\n   She was obviously both taken back and impressed. \"Why,\" she said,\\n \"you\\'re Seymour Pond, the pilot. I tuned in on the banquet they gave\\n you.\"\\n\\n\\n\\n\\n   Si, carrying his glass, moved over to the stool next to her. \"Call me\\n Si,\" he said. \"Everybody calls me Si.\"\\n\\n\\n\\n\\n   She said, \"I\\'m Natalie. Natalie Paskov. Just Natalie. Imagine meeting\\n Seymour Pond. Just sitting down next to him at a bar. Just like that.\"\\n\\n\\n\\n\\n   \"Si,\" Si said, gratified. Holy Zoroaster, he\\'d never seen anything\\n like this rarified pulchritude. Maybe on teevee, of course, one of the\\n current sex symbols, but never in person. \"Call me Si,\" he said again.\\n \"I been called Si so long, I don\\'t even know who somebody\\'s talking to\\n if they say Seymour.\"\\n\\n\\n\\n\\n   \"I cried when they gave you that antique watch,\" she said, her tone\\n such that it was obvious she hadn\\'t quite adjusted as yet to having\\n met him.\\n\\n\\n\\n\\n   Si Pond was surprised. \"Cried?\" he said. \"Well, why? I was kind of\\n bored with the whole thing. But old Doc Gubelin, I used to work under\\n him in the Space Exploration department, he was hot for it.\"\\n\\n\\n\\n\\n   \"\\n\\n\\n    Academician\\n\\n\\n   Gubelin?\" she said. \"You just call him\\n\\n\\n    Doc\\n\\n\\n   ?\"\\n\\n\\n\\n\\n   Si was expansive. \"Why, sure. In the Space Department we don\\'t have\\n much time for formality. Everybody\\'s just Si, and Doc, and Jim. Like\\n that. But how come you cried?\"\\n\\n\\n\\n\\n\\n\\n   She looked down into the drink the bartender had placed before her,\\n as though avoiding his face. \"I ... I suppose it was that speech\\n Doctor Girard-Perregaux made. There you stood, so fine and straight in\\n your space-pilot uniform, the veteran of six exploration runs to the\\n planets....\"\\n\\n\\n\\n\\n   \"Well,\" Si said modestly, \"two of my runs were only to the Moon.\"\\n\\n\\n\\n\\n   \"... and he said all those things about man\\'s conquest of space. And\\n the dream of the stars which man has held so long. And then the fact\\n that you were the last of the space pilots. The last man in the whole\\n world trained to pilot a space craft. And here you were, retiring.\"\\n\\n\\n\\n\\n   Si grunted. \"Yeah. That\\'s all part of the Doc\\'s scheme to get me to\\n take on another three runs. They\\'re afraid the whole department\\'ll be\\n dropped by the Appropriations Committee on this here Economic Planning\\n Board. Even if they can find some other patsy to train for the job,\\n it\\'d take maybe a year before you could even send him on a Moon hop.\\n So old man Gubelin, and Girard-Perregaux too, they\\'re both trying to\\n pressure me into more trips. Otherwise they got a Space Exploration\\n Department, with all the expense and all, but nobody to pilot their\\n ships. It\\'s kind of funny, in a way. You know what one of those\\n spaceships costs?\"\\n\\n\\n\\n\\n   \"Funny?\" she said. \"Why, I don\\'t think it\\'s funny at all.\"\\n\\n\\n\\n\\n   Si said, \"Look, how about another drink?\"\\n\\n\\n\\n\\n   Natalie Paskov said, \"Oh, I\\'d love to have a drink with you, Mr....\"\\n\\n\\n\\n\\n\\n\\n\\n\\n   \"Si,\" Si said. He motioned to the bartender with a circular twist of\\n the hand indicating their need for two more of the same. \"How come you\\n know so much about it? You don\\'t meet many people who are interested\\n in space any more. In fact, most people are almost contemptuous, like.\\n Think it\\'s kind of a big boondoggle deal to help use up a lot of\\n materials and all and keep the economy going.\"\\n\\n\\n\\n\\n   Natalie said earnestly, \"Why, I\\'ve been a space fan all my life. I\\'ve\\n read all about it. Have always known the names of all the space pilots\\n and everything about them, ever since I was a child. I suppose you\\'d\\n say I have the dream that Doctor Girard-Perregaux spoke about.\"\\n\\n\\n\\n\\n   Si chuckled. \"A real buff, eh? You know, it\\'s kind of funny. I was\\n never much interested in it. And I got a darn sight less interested\\n after my first run and I found out what space cafard was.\"\\n\\n\\n\\n\\n   She frowned. \"I don\\'t believe I know much about that.\"\\n\\n\\n\\n\\n   Sitting in the Kudos Room with the most beautiful girl to whom he had\\n ever talked, Si could be nonchalant about the subject. \"Old Gubelin\\n keeps that angle mostly hushed up and out of the magazine and newspaper\\n articles. Says there\\'s enough adverse publicity about space exploration\\n already. But at this stage of the game when the whole ship\\'s crammed\\n tight with this automatic scientific apparatus and all, there\\'s\\n precious little room in the conning tower and you\\'re the only man\\n aboard. The Doc says later on when ships are bigger and there\\'s a whole\\n flock of people aboard, there won\\'t be any such thing as space cafard,\\n but....\" Of a sudden the right side of Si Pond\\'s mouth began to tic\\n and he hurriedly took up his drink and knocked it back.\\n\\n\\n\\n\\n\\n\\n  \\n\\n\\n',\n",
       " 'output': 'Training new spacemen is costly and time consuming. They won’t have anyone else ready after him.'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aa0ad8-7a2c-47f3-824e-3acdf4d65fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0b7233-ee80-43eb-b2eb-20c76f86757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "        # cut too long strings because they may slow down tokenization\n",
    "        inputs = [b['input'][:args.input_seq_len * 10] for b in batch]\n",
    "        labels = [b['output'][:args.target_seq_len * 10] for b in batch]\n",
    "        if args.input_prefix:\n",
    "            inputs = [args.input_prefix + inp for inp in inputs]\n",
    "        features = tokenizer.batch_encode_plus(list(inputs), return_tensors='pt', **encode_plus_kwargs)\n",
    "        labels = np.array([labels_map[t] for t in labels])\n",
    "        features['labels'] = torch.from_numpy(labels)\n",
    "        return features\n",
    "\n",
    "else:\n",
    "    raise NotImplementedError('only encoder-decoder models are supported for scrolls datasets or '\n",
    "                              'encoder models only for contract_nli task')\n",
    "\n",
    "# get train dataset\n",
    "if hvd.rank() == 0:\n",
    "    logger.info(f'preparing dataset for: {args.task_name}')\n",
    "dataset = datasets.load_dataset('tau/scrolls', args.task_name)\n",
    "train_dataset = dataset['train']\n",
    "# shuffle train data each epoch (one loop over train_dataset)\n",
    "train_sampler = DistributedSampler(train_dataset, rank=hvd.rank(), num_replicas=hvd.size(), shuffle=True,\n",
    "                                   drop_last=False, seed=args.seed)\n",
    "per_worker_batch_size = args.batch_size * args.gradient_accumulation_steps\n",
    "global_batch_size = per_worker_batch_size * hvd.size()\n",
    "kwargs = {'pin_memory': True, 'num_workers': args.data_n_workers}\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=per_worker_batch_size, sampler=train_sampler,\n",
    "                              collate_fn=collate_fn, **kwargs)\n",
    "# get validation dataset\n",
    "valid_dataloader = None\n",
    "if hvd.rank() == 0:\n",
    "    logger.info(f'preparing validation data from: {args.task_name}')\n",
    "valid_dataset = dataset['validation']\n",
    "valid_sampler = DistributedSampler(valid_dataset, rank=hvd.rank(), num_replicas=hvd.size(), shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=per_worker_batch_size, sampler=valid_sampler,\n",
    "                              collate_fn=collate_fn, **kwargs)\n",
    "if args.valid_interval is None:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db92f8e0-9c70-4057-8f15-08bf8b3d212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.model_type == 'encoder-decoder':\n",
    "    global_attention_first_token = False  # should be True for LED\n",
    "    encode_plus_kwargs = {'truncation': True, 'padding': 'longest', 'pad_to_multiple_of': 1}\n",
    "    # generate_kwargs = {'max_length': args.target_seq_len, 'min_length': args.target_seq_len}\n",
    "    generate_kwargs = {}\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        # cut too long strings because they may slow down tokenization\n",
    "        inputs = [b['input'][:args.input_seq_len * 10] for b in batch]\n",
    "        labels = [b['output'][:args.target_seq_len * 10] for b in batch]\n",
    "        if args.input_prefix:\n",
    "            inputs = [args.input_prefix + inp for inp in inputs]\n",
    "        features = tokenizer.batch_encode_plus(list(inputs), max_length=args.input_seq_len, return_tensors='pt',\n",
    "                                               **encode_plus_kwargs)\n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            labels = tokenizer.batch_encode_plus(list(labels), max_length=args.target_seq_len, return_tensors='pt',\n",
    "                                                 **encode_plus_kwargs).input_ids\n",
    "        labels[labels == tokenizer.pad_token_id] = -100\n",
    "        features['labels'] = labels\n",
    "        if 'global_attention_mask' in features:\n",
    "            raise RuntimeError('What global attention mask for Longformer and LongformerEncoder-Decoder should be?')\n",
    "        return features\n",
    "\n",
    "elif args.model_type == 'encoder' and args.task_name == 'contract_nli':\n",
    "    if args.use_generate_on_valid:\n",
    "        raise RuntimeError('use_generate_on_valid should be set to False for encoder-only models')\n",
    "\n",
    "    encode_plus_kwargs = {'max_length': args.input_seq_len,\n",
    "                          'truncation': True,\n",
    "                          'padding': 'longest',\n",
    "                          'pad_to_multiple_of': 1}\n",
    "    generate_kwargs = {}\n",
    "    labels_map = {'Contradiction': 0, 'Entailment': 1, 'Not mentioned': 2}\n",
    "    num_labels = len(labels_map)\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        # cut too long strings because they may slow down tokenization\n",
    "        inputs = [b['input'][:args.input_seq_len * 10] for b in batch]\n",
    "        labels = [b['output'][:args.target_seq_len * 10] for b in batch]\n",
    "        if args.input_prefix:\n",
    "            inputs = [args.input_prefix + inp for inp in inputs]\n",
    "        features = tokenizer.batch_encode_plus(list(inputs), return_tensors='pt', **encode_plus_kwargs)\n",
    "        labels = np.array([labels_map[t] for t in labels])\n",
    "        features['labels'] = torch.from_numpy(labels)\n",
    "        return features\n",
    "\n",
    "else:\n",
    "    raise NotImplementedError('only encoder-decoder models are supported for scrolls datasets or '\n",
    "                              'encoder models only for contract_nli task')\n",
    "\n",
    "# get train dataset\n",
    "if hvd.rank() == 0:\n",
    "    logger.info(f'preparing dataset for: {args.task_name}')\n",
    "dataset = datasets.load_dataset('tau/scrolls', args.task_name)\n",
    "train_dataset = dataset['train']\n",
    "# shuffle train data each epoch (one loop over train_dataset)\n",
    "train_sampler = DistributedSampler(train_dataset, rank=hvd.rank(), num_replicas=hvd.size(), shuffle=True,\n",
    "                                   drop_last=False, seed=args.seed)\n",
    "per_worker_batch_size = args.batch_size * args.gradient_accumulation_steps\n",
    "global_batch_size = per_worker_batch_size * hvd.size()\n",
    "kwargs = {'pin_memory': True, 'num_workers': args.data_n_workers}\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=per_worker_batch_size, sampler=train_sampler,\n",
    "                              collate_fn=collate_fn, **kwargs)\n",
    "# get validation dataset\n",
    "valid_dataloader = None\n",
    "if hvd.rank() == 0:\n",
    "    logger.info(f'preparing validation data from: {args.task_name}')\n",
    "valid_dataset = dataset['validation']\n",
    "valid_sampler = DistributedSampler(valid_dataset, rank=hvd.rank(), num_replicas=hvd.size(), shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=per_worker_batch_size, sampler=valid_sampler,\n",
    "                              collate_fn=collate_fn, **kwargs)\n",
    "if args.valid_interval is None:\n",
    "    args.valid_interval = args.log_interval\n",
    "\n",
    "# define model\n",
    "model_cls = get_cls_by_name(args.model_cls)\n",
    "if hvd.rank() == 0:\n",
    "    logger.info(f'Using model class: {model_cls}')\n",
    "if not args.from_pretrained:\n",
    "    model_cfg = AutoConfig.from_pretrained(args.model_cfg)\n",
    "    if args.model_type == 'encoder' and args.task_name == 'contract_nli':\n",
    "        model_cfg.num_labels = num_labels\n",
    "    model = model_cls(config=model_cfg)\n",
    "else:\n",
    "    if hvd.rank() == 0:\n",
    "        logger.info(f'Loading pretrained model: {args.from_pretrained}')\n",
    "    if args.model_type == 'encoder-decoder':\n",
    "        model = model_cls.from_pretrained(args.from_pretrained)\n",
    "    elif args.model_type == 'encoder' and args.task_name == 'contract_nli':\n",
    "        model = model_cls.from_pretrained(args.from_pretrained, num_labels=num_labels)\n",
    "\n",
    "# Aydar # Pass memory settings to pretrained model\n",
    "if args.num_mem_tokens is not None:\n",
    "    backbone_cls = get_cls_by_name(args.backbone_cls) if args.backbone_cls is not None else None\n",
    "    model.set_params(num_mem_tokens=args.num_mem_tokens, \n",
    "                input_size=args.input_size,\n",
    "                input_seg_size=args.input_seg_size,\n",
    "                model_attr=args.model_attr,\n",
    "                backbone_cls=backbone_cls,\n",
    "                sum_loss=args.sum_loss,\n",
    "                bptt_depth=args.bptt_depth, \n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                cls_token_id=tokenizer.cls_token_id, \n",
    "                sep_token_id=tokenizer.sep_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id,)\n",
    "\n",
    "if not args.backbone_trainable:\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'classifier' not in name:\n",
    "            print(f'{name} is frozen')\n",
    "            param.requires_grad = False\n",
    "        else:\n",
    "            print(f'{name} remains trainable')\n",
    "\n",
    "# define optimizer\n",
    "optimizer_cls = get_optimizer(args.optimizer)\n",
    "if optimizer_cls is None:\n",
    "    raise RuntimeError(f'{args.optimizer} was not found in optimizers, torch.optim, transformers.optimization')\n",
    "\n",
    "if hvd.rank() == 0:\n",
    "    logger.info(f'Using optimizer class: {optimizer_cls}')\n",
    "\n",
    "# todo: group optimizer params\n",
    "if optimizer_cls in [transformers.optimization.Adafactor, optimizers.Adafactor]:\n",
    "    # https://github.com/huggingface/transformers/pull/9751/files -> transformers 4.3.0\n",
    "    optimizer = optimizer_cls(model.parameters(), lr=args.lr,\n",
    "                              scale_parameter=args.scale_parameter,\n",
    "                              relative_step=args.relative_step,\n",
    "                              warmup_init=args.warmup_init,\n",
    "                              weight_decay=args.weight_decay)\n",
    "else:\n",
    "    optimizer = optimizer_cls(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "# for encoder only classification\n",
    "def keep_for_metrics_fn(batch, output):\n",
    "    # select data from batch and model output that would be used to compute metrics\n",
    "    data = {}\n",
    "    if 'generation_outputs' in output:\n",
    "        data['labels'] = batch['labels']\n",
    "        data['generation_outputs'] = output['generation_outputs']\n",
    "    if args.model_type == 'encoder':\n",
    "        data['labels'] = batch['labels']\n",
    "        data['predictions'] = torch.argmax(output['logits'].detach(), dim=-1)\n",
    "    return data\n",
    "\n",
    "# HF datasets can compute metrics on each gpu process and then aggregate them on process with rank 0\n",
    "# synchronization is done by using temporay files on a shared filesystem\n",
    "# rank and number of workers is set by num_process and process_id params\n",
    "# BUT our Trainer aggregates all prediction from all gpus!\n",
    "#   this will lead to computing metrics for predictions repeated xN_GPUS times\n",
    "# need to try:\n",
    "# - keep_in_memory=True, may lead to OOM for large validation sets, after sync predictions and targets for the full\n",
    "#       validation set would be stored on each GPU -> xN_GPUs RAM\n",
    "#   - implemented currently\n",
    "# - compute metrics on batch lvl\n",
    "# - add support of HF metrics and turn off aggregation in case if metric has .add_batch method\n",
    "scrolls_metric = datasets.load_metric(scrolls_metric_path, args.task_name, keep_in_memory=True)\n",
    "\n",
    "def metrics_fn(data):\n",
    "    # compute metrics based on stored labels, predictions, ...\n",
    "    metrics = {}\n",
    "    y, p = None, None\n",
    "    if args.model_type == 'encoder-decoder' and 'generation_outputs' in data:\n",
    "        # replace -100 with pad token in labels\n",
    "        pad_token_id = tokenizer.pad_token_id\n",
    "        if isinstance(data['labels'], list):\n",
    "            data['labels'] = [[t if t != -100 else pad_token_id for t in labels] for labels in data['labels']]\n",
    "        else:\n",
    "            data['labels'][data['labels'] == -100] = pad_token_id\n",
    "        y = tokenizer.batch_decode(data['labels'], skip_special_tokens=True)\n",
    "        p = tokenizer.batch_decode(data['generation_outputs'], skip_special_tokens=True)\n",
    "        # todo: do we need to better clean P to remove tokens after eos? not remove special tokens only\n",
    "    elif args.model_type == 'encoder':\n",
    "        y, p = data['labels'], data['predictions']\n",
    "\n",
    "    if y is not None and p is not None:\n",
    "        if args.model_type == 'encoder-decoder':\n",
    "            result = scrolls_metric.compute(predictions=p, references=[[_y] for _y in y])\n",
    "            for metric_name in task_to_metric[args.task_name]:\n",
    "                metrics[metric_name] = result[metric_name]\n",
    "        elif args.model_type == 'encoder' and args.task_name == 'contract_nli':\n",
    "            metrics['exact_match'] = accuracy_score(y, p) * 100\n",
    "            metrics['f1_micro'] = f1_score(y, p, average='micro')\n",
    "    return metrics\n",
    "\n",
    "trainer = Trainer(args, model, optimizer, train_dataloader, valid_dataloader, train_sampler,\n",
    "                  keep_for_metrics_fn=keep_for_metrics_fn, metrics_fn=metrics_fn,\n",
    "                  generate_kwargs=generate_kwargs if args.use_generate_on_valid else {})\n",
    "\n",
    "if not args.validate_only:\n",
    "    # train loop\n",
    "    trainer.train()\n",
    "    # make sure all workers are done\n",
    "    hvd.barrier()\n",
    "    # run validation after training\n",
    "    if args.save_best:\n",
    "        best_model_path = str(Path(args.model_path) / 'model_best.pth')\n",
    "        if hvd.rank() == 0:\n",
    "            logger.info(f'Loading best saved model from {best_model_path}')\n",
    "        trainer.load(best_model_path)\n",
    "    if valid_dataloader is not None:\n",
    "        if hvd.rank() == 0:\n",
    "            logger.info('Runnning validation on valid data:')\n",
    "        trainer.validate(valid_dataloader, write_tb=False)\n",
    "else:\n",
    "    # run validation, do not write to tensorboard\n",
    "    if hvd.rank() == 0:\n",
    "        logger.info('Running validation on train set:')\n",
    "    trainer.validate(train_dataloader, write_tb=False)\n",
    "    if valid_dataloader is not None:\n",
    "        if hvd.rank() == 0:\n",
    "            logger.info('Running validation on valid data:')\n",
    "        trainer.validate(valid_dataloader, write_tb=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hvdenv",
   "language": "python",
   "name": "hvdenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
