{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from transformers import PreTrainedModel, AutoModelForSequenceClassification, AutoConfig, T5ForConditionalGeneration, BartForConditionalGeneration\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import math\n",
    "import os\n",
    "import json\n",
    "import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from transformers import BertForSequenceClassification\n",
    "import transformers\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from modeling_rmt import RMTEncoderForSequenceClassification\n",
    "from modeling_rmt_enc_dec import RMTEncoderDecoderForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([1])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = []\n",
    "l += t\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = []\n",
    "l += t\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'facebook/bart-base'\n",
    "\n",
    "# experiment_path = \"/home/bulatov/bulatov/runs/finetune/fix_tok2/qasper/t5-base/lr2e-04_linear_adamw_wd1e-03_1002-1024_mem10_bs32_iters1600_sl/run_1/\"\n",
    "experiment_path = \"/home/bulatov/bulatov/runs/finetune/debug/contract_nli/facebook/bart-base/lr2e-04_constant_with_warmup_adamw_wd1e-03_500_mem10_sum_loss/run_4/\"\n",
    "\n",
    "cpt_path = os.path.join(experiment_path, \"model_best.pth\")\n",
    "config_path = os.path.join(experiment_path, \"config.json\")\n",
    "cpt = torch.load(cpt_path, map_location='cpu')\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    d = json.load(f)\n",
    "\n",
    "base_model = transformers.BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "# rmt = RMTEncoderDecoderForConditionalGeneration.from_pretrained(model_name, num_labels=3)\n",
    "rmt = RMTEncoderDecoderForConditionalGeneration(base_model=base_model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "set_params_kwargs = {k:v for k,v in d.items() if k in rmt.set_params.__code__.co_varnames}\n",
    "set_params_kwargs['backbone_cls'] = None#transformers.T5ForConditionalGeneration\n",
    "set_params_kwargs['segment_ordering'] = 'regular'\n",
    "set_params_kwargs['inter_layer_memory'] = False\n",
    "set_params_kwargs['tokenizer'] = tokenizer        \n",
    "\n",
    "rmt.set_params(**set_params_kwargs)\n",
    "rmt.load_state_dict(cpt['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 't5-base'\n",
    "\n",
    "# # experiment_path = \"/home/bulatov/bulatov/runs/finetune/debug/qasper/t5-base/lr2e-04_linear_adamw_wd1e-03_-1024_bl_bs_iters_sl/run_2\"\n",
    "# experiment_path = \"/home/bulatov/bulatov/runs/finetune/debug/qasper/t5-base/lr2e-04_linear_adamw_wd1e-03_1024-1024_bl_bs_iters_sl/run_2\"\n",
    "\n",
    "# cpt_path = os.path.join(experiment_path, \"model_best.pth\")\n",
    "# config_path = os.path.join(experiment_path, \"config.json\")\n",
    "# cpt = torch.load(cpt_path, map_location='cpu')\n",
    "\n",
    "# with open(config_path, 'r') as f:\n",
    "#     d = json.load(f)\n",
    "\n",
    "# baseline = T5ForConditionalGeneration.from_pretrained(model_name, num_labels=3)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# baseline.load_state_dict(cpt['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Holder:\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq_len = d['input_seq_len']\n",
    "target_seq_len = 1024\n",
    "batch_size = 1\n",
    "\n",
    "args = Holder\n",
    "args.target_seq_len = target_seq_len\n",
    "args.input_seq_len = input_seq_len\n",
    "args.input_prefix = ''\n",
    "\n",
    "\n",
    "device = torch.device(0)\n",
    "\n",
    "global_attention_first_token = False  # should be True for LED\n",
    "encode_plus_kwargs = {'truncation': True, 'padding': 'longest', 'pad_to_multiple_of': 1}\n",
    "# generate_kwargs = {'max_length': args.target_seq_len, 'min_length': args.target_seq_len}\n",
    "generate_kwargs = {}\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # cut too long strings because they may slow down tokenization\n",
    "    inputs = [b['input'][:args.input_seq_len * 10] for b in batch]\n",
    "    if 'outputs' in batch[0]:\n",
    "        # if we have more than 1 label per example (only in valid) take only one of them\n",
    "        # to compute loss on valid\n",
    "        labels = [b['outputs'][0][:args.target_seq_len * 10] for b in batch]\n",
    "    else:\n",
    "        labels = [b['output'][:args.target_seq_len * 10] for b in batch]\n",
    "    if args.input_prefix:\n",
    "        inputs = [args.input_prefix + inp for inp in inputs]\n",
    "    features = tokenizer.batch_encode_plus(list(inputs), max_length=args.input_seq_len, return_tensors='pt',\n",
    "                                           **encode_plus_kwargs)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer.batch_encode_plus(list(labels), max_length=args.target_seq_len, return_tensors='pt',\n",
    "                                             **encode_plus_kwargs).input_ids\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    features['labels'] = labels\n",
    "    features['id'] = [b['id'] for b in batch]\n",
    "    if 'outputs' in batch[0]:\n",
    "        features['target_text'] = [b['outputs'] for b in batch]\n",
    "    else:\n",
    "        features['target_text'] = [b['output'] for b in batch]\n",
    "    if 'global_attention_mask' in features:\n",
    "        raise RuntimeError('What global attention mask for Longformer and LongformerEncoder-Decoder should be?')\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset scrolls (/home/bulatov/.cache/huggingface/datasets/tau___scrolls/qasper/1.0.0/672021d5d8e1edff998a6ea7a5bff35fdfd0ae243e7cf6a8c88a57a04afb46ac)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0ef08a55b74c9dbc32b043bf8e71db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_name = 'qasper'\n",
    "dataset = datasets.load_dataset('tau/scrolls', task_name)\n",
    "train_dataset = dataset['train']\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset,)\n",
    "kwargs = {'pin_memory': True, 'num_workers': 0}\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler,\n",
    "                                collate_fn=collate_fn, **kwargs)\n",
    "\n",
    "valid_dataset = dataset['validation']\n",
    "valid_sampler = RandomSampler(valid_dataset)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, sampler=train_sampler,\n",
    "                                collate_fn=collate_fn, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2567, 1726)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset['pid']), len(valid_dataset['pid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictions from all segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(self, input_ids, return_all_outputs=False, **kwargs):\n",
    "    memory = self.set_memory()\n",
    "    mem_start_ind = 1 if self.bos_token is not None else 0\n",
    "    min_length, max_length = None, None\n",
    "    if 'min_length' in kwargs:\n",
    "        min_length = kwargs.pop('min_length')\n",
    "    if 'max_length' in kwargs:\n",
    "        max_length = kwargs.pop('max_length')\n",
    "\n",
    "    segmented = self.pad_and_segment(input_ids)\n",
    "    segmented = list(zip(*segmented))\n",
    "\n",
    "    if self.segment_ordering in {'regular', 'last_memory_only'}:\n",
    "        pass\n",
    "    elif self.segment_ordering == 'reversed':\n",
    "        segmented = segmented[::-1]\n",
    "    elif self.segment_ordering == 'bidirectional':\n",
    "        segmented = segmented + segmented[::-1][1:]\n",
    "    elif self.segment_ordering == 'repeat_first':\n",
    "        segmented = segmented + segmented[:1]\n",
    "    else:\n",
    "        raise ValueError(f'Unknown segment ordering: {self.segment_ordering}')\n",
    "\n",
    "    outputs = []\n",
    "    for seg_num, segment_data in enumerate(segmented):\n",
    "        input_ids, attention_mask, token_type_ids = segment_data\n",
    "        if memory.ndim == 2:\n",
    "            memory = memory.repeat(input_ids.shape[0], 1, 1)\n",
    "        if (self.bptt_depth > -1) and (len(segmented) - seg_num > self.bptt_depth): \n",
    "            memory = memory.detach()\n",
    "\n",
    "        seg_kwargs = dict(**kwargs)\n",
    "        if self.drop_empty_segments:\n",
    "            non_empty_mask = [not torch.equal(input_ids[i], self.empty) for i in range(len(input_ids))]\n",
    "            if sum(non_empty_mask) == 0:\n",
    "                continue\n",
    "            input_ids = input_ids[non_empty_mask]\n",
    "            attention_mask = attention_mask[non_empty_mask]\n",
    "            token_type_ids = token_type_ids[non_empty_mask]\n",
    "\n",
    "            inputs_embeds = self.embeddings(input_ids)\n",
    "            inputs_embeds[:, mem_start_ind:mem_start_ind+self.num_mem_tokens] = memory[non_empty_mask]\n",
    "\n",
    "        else:\n",
    "            inputs_embeds = self.embeddings(input_ids)\n",
    "            inputs_embeds[:, mem_start_ind:mem_start_ind+self.num_mem_tokens] = memory\n",
    "\n",
    "        seg_kwargs['inputs_embeds'] = inputs_embeds\n",
    "        seg_kwargs['attention_mask'] = attention_mask\n",
    "        if seg_num < len(segmented)-1:\n",
    "            labels = torch.zeros(inputs_embeds.shape[0], inputs_embeds.shape[1], device=inputs_embeds.device, dtype=input_ids.dtype)\n",
    "            gen_out = self.model.generate(**seg_kwargs, output_hidden_states=True, min_length=min_length, max_length=max_length)\n",
    "            outputs.append(gen_out)\n",
    "            out = self.model.forward(**seg_kwargs, output_hidden_states=True, labels=labels)\n",
    "            if self.drop_empty_segments:\n",
    "                memory[non_empty_mask] = out.encoder_hidden_states[-1][:, mem_start_ind:mem_start_ind+self.num_mem_tokens]\n",
    "            else:\n",
    "                memory = out.encoder_hidden_states[-1][:, mem_start_ind:mem_start_ind+self.num_mem_tokens]\n",
    "        else:\n",
    "            out = self.model.generate(**seg_kwargs, output_hidden_states=True, min_length=min_length, max_length=max_length)\n",
    "            outputs.append(out)\n",
    "\n",
    "    if return_all_outputs:\n",
    "        return out, outputs\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def evaluate(output, sample):\n",
    "    labels = sample['labels']\n",
    "    logits = o['logits']\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    correct_mask = preds == labels[output['non_empty_mask']]\n",
    "    return correct_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "def download_metric():\n",
    "    scrolls_metric_path = hf_hub_download(repo_id=\"datasets/tau/scrolls\", filename=\"metrics/scrolls.py\")\n",
    "    updated_scrolls_metric_path = (\n",
    "        os.path.dirname(scrolls_metric_path) + os.path.basename(scrolls_metric_path).replace(\".\", \"_\") + \".py\"\n",
    "    )\n",
    "    shutil.copy(scrolls_metric_path, updated_scrolls_metric_path)\n",
    "    return updated_scrolls_metric_path\n",
    "\n",
    "\n",
    "scrolls_metric_path = download_metric()\n",
    "scrolls_metric = datasets.load_metric(scrolls_metric_path, task_name, keep_in_memory=True)\n",
    "\n",
    "def metrics_fn(labels, generation_outputs, verbose=True):\n",
    "    # compute metrics based on stored labels, predictions, ...\n",
    "        # replace -100 with pad token in labels\n",
    "    y = labels\n",
    "    p = tokenizer.batch_decode(generation_outputs, skip_special_tokens=True)\n",
    "    if verbose:\n",
    "        for i in range(len(y)):\n",
    "            print(f'y: {y[i]}')\n",
    "            print(f'p: {p[i]}')\n",
    "            # print(f'p ids: {generation_outputs[i]}')\n",
    "            print('-' * 50)\n",
    "        # todo: do we need to better clean P to remove tokens after eos? not remove special tokens only\n",
    "    if y is not None and p is not None:\n",
    "        if not isinstance(y[0], list):\n",
    "            y = [[_y] for _y in y]\n",
    "        result = scrolls_metric.compute(predictions=p, references=y)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'pid', 'input', 'output'],\n",
       "    num_rows: 2567\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label_train = dict(zip(train_dataset['id'], train_dataset['output']))\n",
    "id2label_valid = dict(zip(valid_dataset['id'], valid_dataset['output']))\n",
    "\n",
    "id2text_train = dict(zip(train_dataset['id'], train_dataset['input']))\n",
    "id2text_valid = dict(zip(valid_dataset['id'], valid_dataset['input']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%time\n",
    "# it = 0\n",
    "# max_it =  3000\n",
    "\n",
    "# baseline.to(device=device)\n",
    "# sampler = RandomSampler(train_dataset)\n",
    "# dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler,\n",
    "#                                 collate_fn=collate_fn, **kwargs)\n",
    "# # sampler = RandomSampler(valid_dataset)\n",
    "# # dataloader = DataLoader(valid_dataset, batch_size=batch_size, sampler=sampler,\n",
    "# #                                 collate_fn=collate_fn, **kwargs)\n",
    "\n",
    "\n",
    "# it = 0\n",
    "    \n",
    "# res_df = pd.DataFrame()\n",
    "# gen = iter(dataloader)\n",
    "# for sample in gen:\n",
    "#     ids, target_text, labels = sample.pop('id'), sample.pop('target_text'), sample.pop('labels')\n",
    "#     for key in sample:\n",
    "#         sample[key] = sample[key].to(device)\n",
    "    \n",
    "#     # out, outputs = generate(rmt, return_all_outputs=True, **sample)  \n",
    "#     out = baseline.generate(**sample)  \n",
    "\n",
    "#     res_dict = {'ids': ids[0]}\n",
    "\n",
    "#     f1 = metrics_fn(target_text, generation_outputs=out, verbose=False)['f1']\n",
    "#     res_dict[f'f1_seg_1'] = f1\n",
    "\n",
    "#     preds = tokenizer.batch_decode(out, skip_special_tokens=True)\n",
    "#     res_dict['preds'] = preds\n",
    "#     res_dict['preds_tokens'] = str(out[0].cpu().numpy())\n",
    "\n",
    "#     res_dict['target_text'] = target_text[0]\n",
    "#     res_dict['labels'] = str(labels[0].cpu().numpy())\n",
    "\n",
    "#     res_df = res_df.append(pd.DataFrame(res_dict), ignore_index=True)\n",
    "\n",
    "\n",
    "#     it += 1\n",
    "#     if it > max_it:\n",
    "#         break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 500])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,  2264, 42532,    32,   341,   116, 50118, 50118, 46576, 50118,\n",
       "          14563,  9799,  3563, 19850,    36,   487, 11674,    43,    34,  3491,\n",
       "             10,   319,     9,  1503,   682,   528,     7,    63,  6143,  5139,\n",
       "             11,  3563, 19850,  1318,  9499,   194,    12,  1116,    12,   627,\n",
       "             12,  2013,   819,    13,   484, 11991,   163,  8863, 45935,   288,\n",
       "           2156,   163,  8863, 45935,   134,  2156,   163,  8863, 45935,   176,\n",
       "            479,    20,  2731,  9437,     9, 26739,  3563, 19850,  3092,    16,\n",
       "            716,    15,     5,   937,  9689, 15362,    12, 11127, 15362,  1548,\n",
       "            163,  8863, 45935,   246,   479, 44304,  3563, 19850,    16,    41,\n",
       "            253,    12,   560,    12,  1397,  1548,    14, 25269,     7, 46855,\n",
       "           1300, 11305,    88,  7664, 30464,     8, 45182,   209, 30464,    88,\n",
       "          11305,    11,     5,  1002,  2777,     4,  3687,     5,   430, 26739,\n",
       "          14077,  3092,     6,  1503,   337,   234, 11674,   163,  8863, 45935,\n",
       "            306,  2156,   163,  8863, 45935,   245,    34,   555,  1406,   528,\n",
       "              7,    63,  9388,     7,   304,     5,   144,  4249,  1667,     9,\n",
       "              5,  1300,  3645,    23,   349, 19850,  1149,     4,   152,  9388,\n",
       "             67,   817,     5,  1503,   337,  1421, 10295,    11, 33042,  1181,\n",
       "          11305,   163,  8863, 45935,   306,  2156,   163,  8863, 45935,   245,\n",
       "            479, 50118, 40683, 37365, 45935,   134,   924,    41,  1246,     9,\n",
       "            141,  1503,  2939,     5,   144,  4249,  1300,  1617,     7,  5368,\n",
       "             10,  1002,  2136,    23,   349,  1149,     9,     5, 19850,     4,\n",
       "             96,    42,  2225,    52,  1056,    15,  7739,     5, 21623,     9,\n",
       "              5,  2922,  1667,     6,   941,  1200,   147,  1503,    16, 22209,\n",
       "             29,  1794,  6537,    66,   108,    81,  1533,  1300,  1617,   147,\n",
       "             49, 21623,    16,    45,  4378,  4678,     6,   192,     6,   364,\n",
       "              4,   571,   482,    44,    48, 14656,   113,     8,    44,    48,\n",
       "           3341,   113,    11, 17965, 37365, 45935,   134,   479,  1398,     6,\n",
       "             52,  1394,   549,   209,    32,   528,     7,  9126,     9,     5,\n",
       "           1503,  9562,    50,    32,    10, 12762,  3650,     9,     5,  1421,\n",
       "              4, 50118, 11321,     5,  7740,     9,  1503,  3092,    11, 26739,\n",
       "           3563, 19850,   163,  8863, 45935,   306,  1337, 24785,    33,    57,\n",
       "           1850,   163,  8863, 45935,   245,  2156,   163,  8863, 45935,   401,\n",
       "           2156,   163,  8863, 45935,   406,   479,   635,     6,     7,     5,\n",
       "            275,     9,    84,  2655,    89,    16,   117,   892,    14,  1639,\n",
       "             41,  1966,     9,    99,   761,     9, 32242,    16,   145,  4705,\n",
       "             30,  1503,     4,   345,    32,   103,  1364,    14,    33,  1415,\n",
       "              7,  1503,    25,   145,  1122,     7,  2065,  2136, 22432,   163,\n",
       "           8863, 45935,   398,  2156,   163,  8863, 45935,   401,  2156,   163,\n",
       "           8863, 45935,   406,  2156,   163,  8863, 45935,   466,   479,   993,\n",
       "              9,   209,  8369,    67, 37672,    19,  1058,     5,  1503,  1421,\n",
       "            634,  2065, 12432,  2963,   163,  8863, 45935,   398,  2156,   163,\n",
       "           8863, 45935,   406,  2156,   163,  8863, 45935,   466,   479, 16787,\n",
       "            257,    12,   717,    90,  7083,    35,  9029,    35, 18047,  1862,\n",
       "             33,  2343,    14,  1503,   115,    28,   450,    25,    10,   769,\n",
       "          43976,  1421,    25,   157,    25,    41, 22432,  1421,     4, 50118,\n",
       "           1121,    42,  2225,     6,    52,  1056,    15,  3219,     5,  5550,\n",
       "            227,  1503,     8, 22432,     8,    99,    16,   145,  4705,    30,\n",
       "              5,  1503,  9562,    11,   937,     4,    20,  1142,    14,    52,\n",
       "             32,  9998,     7,  1948,   680,    35,  1534,     5,  1503,  1421,\n",
       "            129,  4453,     9, 26471, 22432,   116,   178,   141,  1122,     2]],\n",
       "        device='cuda:0'),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "        device='cuda:0')}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_df.to_csv('tables/qasper-valid-t5-base-1024.csv', index=False)\n",
    "# res_df.to_csv('tables/qasper-train-t5-base-1024.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 20s, sys: 1.51 s, total: 3min 22s\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "it = 0\n",
    "max_it =  3000\n",
    "\n",
    "rmt.to(device=device)\n",
    "rmt.drop_empty_segments = False\n",
    "sampler = RandomSampler(train_dataset)\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler,\n",
    "                                collate_fn=collate_fn, **kwargs)\n",
    "# sampler = RandomSampler(valid_dataset)\n",
    "# dataloader = DataLoader(valid_dataset, batch_size=batch_size, sampler=sampler,\n",
    "#                                 collate_fn=collate_fn, **kwargs)\n",
    "\n",
    "\n",
    "it = 0\n",
    "    \n",
    "res_df = pd.DataFrame()\n",
    "gen = iter(dataloader)\n",
    "for sample in gen:\n",
    "    ids, target_text, labels = sample.pop('id'), sample.pop('target_text'), sample.pop('labels')\n",
    "    for key in sample:\n",
    "        sample[key] = sample[key].to(device)\n",
    "    \n",
    "    out, outputs = generate(rmt, return_all_outputs=True, **sample)  \n",
    "\n",
    "    res_dict = {'ids': ids}\n",
    "    for i, o in enumerate(outputs):\n",
    "        f1 = metrics_fn(target_text, generation_outputs=o, verbose=False)['f1']\n",
    "        res_dict[f'f1_seg_{i}'] = f1\n",
    "        \n",
    "        preds = tokenizer.batch_decode(o, skip_special_tokens=True)\n",
    "        res_dict[f'preds_seg_{i}'] = preds\n",
    "        res_dict[f'preds_seg_{i}_tokens'] = str(o.cpu().numpy())\n",
    "        \n",
    "    res_dict['target_text'] = target_text\n",
    "    res_dict['labels'] = str(labels.cpu().numpy())\n",
    "\n",
    "    res_df = res_df.append(pd.DataFrame(res_dict), ignore_index=True)\n",
    "\n",
    "\n",
    "    it += 1\n",
    "    if it > max_it:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmt.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('tables/qasper-train-rm-bart-500-10-new.csv', index=False)\n",
    "# res_df.to_csv('tables/qasper-valid-rm-bart-500-10-new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 12s, sys: 635 ms, total: 2min 12s\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "it = 0\n",
    "max_it =  3000\n",
    "\n",
    "rmt.to(device=device)\n",
    "rmt.drop_empty_segments = False\n",
    "# sampler = RandomSampler(train_dataset)\n",
    "# dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler,\n",
    "#                                 collate_fn=collate_fn, **kwargs)\n",
    "sampler = RandomSampler(valid_dataset)\n",
    "dataloader = DataLoader(valid_dataset, batch_size=batch_size, sampler=sampler,\n",
    "                                collate_fn=collate_fn, **kwargs)\n",
    "\n",
    "\n",
    "it = 0\n",
    "    \n",
    "res_df = pd.DataFrame()\n",
    "gen = iter(dataloader)\n",
    "for sample in gen:\n",
    "    ids, target_text, labels = sample.pop('id'), sample.pop('target_text'), sample.pop('labels')\n",
    "    for key in sample:\n",
    "        sample[key] = sample[key].to(device)\n",
    "    \n",
    "    out, outputs = generate(rmt, return_all_outputs=True, **sample)  \n",
    "\n",
    "    res_dict = {'ids': ids}\n",
    "    for i, o in enumerate(outputs):\n",
    "        f1 = metrics_fn(target_text, generation_outputs=o, verbose=False)['f1']\n",
    "        res_dict[f'f1_seg_{i}'] = f1\n",
    "        \n",
    "        preds = tokenizer.batch_decode(o, skip_special_tokens=True)\n",
    "        res_dict[f'preds_seg_{i}'] = preds\n",
    "        res_dict[f'preds_seg_{i}_tokens'] = str(o.cpu().numpy())\n",
    "        \n",
    "    res_dict['target_text'] = target_text\n",
    "    res_dict['labels'] = str(labels.cpu().numpy())\n",
    "\n",
    "    res_df = res_df.append(pd.DataFrame(res_dict), ignore_index=True)\n",
    "\n",
    "\n",
    "    it += 1\n",
    "    if it > max_it:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_df.to_csv('tables/qasper-train-rm-bart-500-10-new.csv', index=False)\n",
    "res_df.to_csv('tables/qasper-valid-rm-bart-500-10-new.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmt_df = pd.read_csv('tables/qasper-train-rm-t5-1002-10.csv').sort_values(['ids']).reset_index()\n",
    "rmt_df = pd.read_csv('tables/qasper-train-rm-t5-1002-10-new.csv').sort_values(['ids']).reset_index()\n",
    "rmt_df['input'] = rmt_df.ids.apply(lambda x: id2text_train[x])\n",
    "\n",
    "# baseline_df = pd.read_csv('tables/qasper-train-t5-base-1024.csv').sort_values(['ids']).reset_index()\n",
    "# baseline_df['input'] = baseline_df.ids.apply(lambda x: id2text_train[x])\n",
    "# baseline_df['f1_seg_1'] = baseline_df.f1_seg_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rm-t5-seg-2</th>\n",
       "      <th>rmt-t5-seg-1</th>\n",
       "      <th>t5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rm-t5-seg-2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmt-t5-seg-1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rm-t5-seg-2  rmt-t5-seg-1    t5\n",
       "rm-t5-seg-2          0.00          0.21  0.51\n",
       "rmt-t5-seg-1         0.05          0.00  0.42\n",
       "t5                   0.03          0.06  0.00"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_cols = {'rm-t5-seg-2': rmt_df.f1_seg_1, 'rmt-t5-seg-1': rmt_df.f1_seg_0, 't5': baseline_df.f1_seg_1}\n",
    "comp_df = pd.DataFrame(index = f1_cols.keys(), columns = f1_cols.keys())\n",
    "\n",
    "for better_name, better_f1 in f1_cols.items():\n",
    "    for worse_name, worse_f1 in f1_cols.items():\n",
    "        num_occ = (better_f1 > worse_f1).sum()\n",
    "        comp_df.loc[worse_name, better_name] = num_occ\n",
    "        \n",
    "comp_df = (comp_df / rmt_df.shape[0]).astype(float).round(2)\n",
    "comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmt_df.pred_seg_0.value_counts(), rmt_df.pred_seg_1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd12c149eb0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline_df.f1_seg_2.hist()\n",
    "rmt_df.f1_seg_0.hist()\n",
    "rmt_df.f1_seg_1.hist()\n",
    "plt.legend(['baseline', 'seg 0', 'seg 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6988702765874562"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rmt_df.f1_seg_0 == 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.358234670821972"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rmt_df.f1_seg_1 - rmt_df.f1_seg_0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmt_df[rmt_df.f1_seg_1 >  0].target_text.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmt_df[rmt_df.f1_seg_0 >  0].target_text.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmt_df = pd.read_csv('tables/qasper-valid-rm-t5-1002-10.csv').sort_values(['ids']).reset_index()\n",
    "rmt_df = pd.read_csv('tables/qasper-valid-rm-t5-1002-10-new.csv').sort_values(['ids']).reset_index()\n",
    "rmt_df['input'] = rmt_df.ids.apply(lambda x: id2text_valid[x])\n",
    "\n",
    "baseline_df = pd.read_csv('tables/qasper-valid-t5-base.csv').sort_values(['ids']).reset_index()\n",
    "baseline_df['input'] = baseline_df.ids.apply(lambda x: id2text_valid[x])\n",
    "baseline_df['f1_seg_1'] = baseline_df['f1_seg_2']\n",
    "\n",
    "baseline_df_1024 = pd.read_csv('tables/qasper-valid-t5-base-1024.csv').sort_values(['ids']).reset_index()\n",
    "baseline_df_1024['input'] = baseline_df_1024.ids.apply(lambda x: id2text_valid[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fcc978688b0>"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline_df_1024.f1_seg_1.hist()\n",
    "baseline_df.f1_seg_1.hist()\n",
    "rmt_df.f1_seg_0.hist()\n",
    "rmt_df.f1_seg_1.hist()\n",
    "plt.legend(['t5-1024', 't5-512', 'seg 0', 'seg 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13.940854924681345, 8.407056431054462, 15.213263557358053, 19.504274971031283)"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rmt_df.f1_seg_0).mean(), (rmt_df.f1_seg_1).mean(), (baseline_df.f1_seg_1).mean(), (baseline_df_1024.f1_seg_1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline 1024 VS baseline 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ids</th>\n",
       "      <th>f1_seg_1</th>\n",
       "      <th>preds</th>\n",
       "      <th>preds_tokens</th>\n",
       "      <th>target_text</th>\n",
       "      <th>labels</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>970</td>\n",
       "      <td>003d6f9722ddc2ee13e879fefafc315fb8e87cb9</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>Unanswerable</td>\n",
       "      <td>[   0  597 3247 3321  179    1]</td>\n",
       "      <td>Unanswerable</td>\n",
       "      <td>[ 597 3247 3321  179    1]</td>\n",
       "      <td>What does a node in the network approach repes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>602</td>\n",
       "      <td>003d6f9722ddc2ee13e879fefafc315fb8e87cb9</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>Unanswerable</td>\n",
       "      <td>[   0  597 3247 3321  179    1]</td>\n",
       "      <td>Unanswerable</td>\n",
       "      <td>[ 597 3247 3321  179    1]</td>\n",
       "      <td>What does a node in the network approach repes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>353</td>\n",
       "      <td>01209a3bead7c87bcdc628be2a5a26b41abde9d1</td>\n",
       "      <td>42.1053</td>\n",
       "      <td>SNLI BIBREF22, MultiNLI BIBREF23</td>\n",
       "      <td>[    0     3  8544  8159     3  5972 25582   3...</td>\n",
       "      <td>SNLI BIBREF22 and MultiNLI BIBREF23, Quora Que...</td>\n",
       "      <td>[    3  8544  8159     3  5972 25582   371  28...</td>\n",
       "      <td>Which datasets were used?\\n\\nIntroduction\\nIn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1104</td>\n",
       "      <td>01209a3bead7c87bcdc628be2a5a26b41abde9d1</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>SNLI BIBREF22, MultiNLI BIBREF23</td>\n",
       "      <td>[    0     3  8544  8159     3  5972 25582   3...</td>\n",
       "      <td>SNLI BIBREF22 and MultiNLI BIBREF23 datasets, ...</td>\n",
       "      <td>[    3  8544  8159     3  5972 25582   371  28...</td>\n",
       "      <td>Which datasets were used?\\n\\nIntroduction\\nIn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1286</td>\n",
       "      <td>012b8a89aea27485797373adbcda32f16f9d7b54</td>\n",
       "      <td>21.0526</td>\n",
       "      <td>Hierarchical naive Bayesian and lexicon based ...</td>\n",
       "      <td>[    0  3204  7064  1950     3    29     9   7...</td>\n",
       "      <td>'shallow' naive Bayes, SVM, hierarchical stack...</td>\n",
       "      <td>[    3    31     7   107 18912    31     3    ...</td>\n",
       "      <td>What is the approach of previous work?\\n\\nIntr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>886</td>\n",
       "      <td>fde700d5134a9ae8f7579bea1f1b75f34d7c1c4c</td>\n",
       "      <td>26.6667</td>\n",
       "      <td>an Android application. Each respondent instal...</td>\n",
       "      <td>[   0   46 3054  917    5 1698 3531  295 3029 ...</td>\n",
       "      <td>Android application</td>\n",
       "      <td>[3054  917    1]</td>\n",
       "      <td>how was the speech collected?\\n\\nIntroduction\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>1353</td>\n",
       "      <td>feb448860918ef5b905bb25d7b855ba389117c1f</td>\n",
       "      <td>11.7647</td>\n",
       "      <td>635hrs of audio data for 7 Indian languages co...</td>\n",
       "      <td>[    0   431  2469 18745    13  2931   331    ...</td>\n",
       "      <td>$\\textbf {All India Radio}$ news channel</td>\n",
       "      <td>[1514    2 6327  115   89    3    2 6838 1547 ...</td>\n",
       "      <td>How was the audio data gathered?\\n\\nINTRODUCTI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>1062</td>\n",
       "      <td>ffa7f91d6406da11ddf415ef094aaf28f3c3872d</td>\n",
       "      <td>8.6957</td>\n",
       "      <td>precision and recall of n-grams from the table...</td>\n",
       "      <td>[    0 11723    11  7881    13     3    29    ...</td>\n",
       "      <td>Their average correlation tops the best other ...</td>\n",
       "      <td>[ 2940  1348 18712   420     7     8   200   1...</td>\n",
       "      <td>By how much more does PARENT correlate with hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>254</td>\n",
       "      <td>ffa7f91d6406da11ddf415ef094aaf28f3c3872d</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>precision and recall of n-grams from the table...</td>\n",
       "      <td>[    0 11723    11  7881    13     3    29    ...</td>\n",
       "      <td>Best proposed metric has average correlation w...</td>\n",
       "      <td>[ 1648  4382     3  7959    65  1348 18712    ...</td>\n",
       "      <td>By how much more does PARENT correlate with hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>1677</td>\n",
       "      <td>ffeb67a61ecd09542b1c53c3e4c3abd4da0496a8</td>\n",
       "      <td>88.8889</td>\n",
       "      <td>a labeled graph showing concepts as nodes and ...</td>\n",
       "      <td>[   0    3    9 3783   15   26 8373 2924 6085 ...</td>\n",
       "      <td>concept map BIBREF5 , a labeled graph showing ...</td>\n",
       "      <td>[ 2077  2828     3  5972 25582   371   755    ...</td>\n",
       "      <td>How do the authors define a concept map?\\n\\nIn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                       ids  f1_seg_1  \\\n",
       "2       970  003d6f9722ddc2ee13e879fefafc315fb8e87cb9  100.0000   \n",
       "3       602  003d6f9722ddc2ee13e879fefafc315fb8e87cb9  100.0000   \n",
       "12      353  01209a3bead7c87bcdc628be2a5a26b41abde9d1   42.1053   \n",
       "13     1104  01209a3bead7c87bcdc628be2a5a26b41abde9d1   40.0000   \n",
       "14     1286  012b8a89aea27485797373adbcda32f16f9d7b54   21.0526   \n",
       "...     ...                                       ...       ...   \n",
       "1709    886  fde700d5134a9ae8f7579bea1f1b75f34d7c1c4c   26.6667   \n",
       "1715   1353  feb448860918ef5b905bb25d7b855ba389117c1f   11.7647   \n",
       "1719   1062  ffa7f91d6406da11ddf415ef094aaf28f3c3872d    8.6957   \n",
       "1720    254  ffa7f91d6406da11ddf415ef094aaf28f3c3872d   10.0000   \n",
       "1723   1677  ffeb67a61ecd09542b1c53c3e4c3abd4da0496a8   88.8889   \n",
       "\n",
       "                                                  preds  \\\n",
       "2                                          Unanswerable   \n",
       "3                                          Unanswerable   \n",
       "12                    SNLI BIBREF22, MultiNLI BIBREF23    \n",
       "13                    SNLI BIBREF22, MultiNLI BIBREF23    \n",
       "14    Hierarchical naive Bayesian and lexicon based ...   \n",
       "...                                                 ...   \n",
       "1709  an Android application. Each respondent instal...   \n",
       "1715  635hrs of audio data for 7 Indian languages co...   \n",
       "1719  precision and recall of n-grams from the table...   \n",
       "1720  precision and recall of n-grams from the table...   \n",
       "1723  a labeled graph showing concepts as nodes and ...   \n",
       "\n",
       "                                           preds_tokens  \\\n",
       "2                       [   0  597 3247 3321  179    1]   \n",
       "3                       [   0  597 3247 3321  179    1]   \n",
       "12    [    0     3  8544  8159     3  5972 25582   3...   \n",
       "13    [    0     3  8544  8159     3  5972 25582   3...   \n",
       "14    [    0  3204  7064  1950     3    29     9   7...   \n",
       "...                                                 ...   \n",
       "1709  [   0   46 3054  917    5 1698 3531  295 3029 ...   \n",
       "1715  [    0   431  2469 18745    13  2931   331    ...   \n",
       "1719  [    0 11723    11  7881    13     3    29    ...   \n",
       "1720  [    0 11723    11  7881    13     3    29    ...   \n",
       "1723  [   0    3    9 3783   15   26 8373 2924 6085 ...   \n",
       "\n",
       "                                            target_text  \\\n",
       "2                                          Unanswerable   \n",
       "3                                          Unanswerable   \n",
       "12    SNLI BIBREF22 and MultiNLI BIBREF23, Quora Que...   \n",
       "13    SNLI BIBREF22 and MultiNLI BIBREF23 datasets, ...   \n",
       "14    'shallow' naive Bayes, SVM, hierarchical stack...   \n",
       "...                                                 ...   \n",
       "1709                                Android application   \n",
       "1715           $\\textbf {All India Radio}$ news channel   \n",
       "1719  Their average correlation tops the best other ...   \n",
       "1720  Best proposed metric has average correlation w...   \n",
       "1723  concept map BIBREF5 , a labeled graph showing ...   \n",
       "\n",
       "                                                 labels  \\\n",
       "2                            [ 597 3247 3321  179    1]   \n",
       "3                            [ 597 3247 3321  179    1]   \n",
       "12    [    3  8544  8159     3  5972 25582   371  28...   \n",
       "13    [    3  8544  8159     3  5972 25582   371  28...   \n",
       "14    [    3    31     7   107 18912    31     3    ...   \n",
       "...                                                 ...   \n",
       "1709                                   [3054  917    1]   \n",
       "1715  [1514    2 6327  115   89    3    2 6838 1547 ...   \n",
       "1719  [ 2940  1348 18712   420     7     8   200   1...   \n",
       "1720  [ 1648  4382     3  7959    65  1348 18712    ...   \n",
       "1723  [ 2077  2828     3  5972 25582   371   755    ...   \n",
       "\n",
       "                                                  input  \n",
       "2     What does a node in the network approach repes...  \n",
       "3     What does a node in the network approach repes...  \n",
       "12    Which datasets were used?\\n\\nIntroduction\\nIn ...  \n",
       "13    Which datasets were used?\\n\\nIntroduction\\nIn ...  \n",
       "14    What is the approach of previous work?\\n\\nIntr...  \n",
       "...                                                 ...  \n",
       "1709  how was the speech collected?\\n\\nIntroduction\\...  \n",
       "1715  How was the audio data gathered?\\n\\nINTRODUCTI...  \n",
       "1719  By how much more does PARENT correlate with hu...  \n",
       "1720  By how much more does PARENT correlate with hu...  \n",
       "1723  How do the authors define a concept map?\\n\\nIn...  \n",
       "\n",
       "[522 rows x 8 columns]"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_df_1024[baseline_df.f1_seg_1 < baseline_df_1024.f1_seg_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ids</th>\n",
       "      <th>f1_seg_1</th>\n",
       "      <th>preds</th>\n",
       "      <th>preds_tokens</th>\n",
       "      <th>target_text</th>\n",
       "      <th>labels</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1445</td>\n",
       "      <td>012b8a89aea27485797373adbcda32f16f9d7b54</td>\n",
       "      <td>13.8889</td>\n",
       "      <td>Hierarchical naive Bayesian and lexicon based ...</td>\n",
       "      <td>[    0  3204  7064  1950     3    29     9   7...</td>\n",
       "      <td>BIBREF11 that uses a character level n-gram la...</td>\n",
       "      <td>[    3  5972 25582   371  2596    24  2284    ...</td>\n",
       "      <td>What is the approach of previous work?\\n\\nIntr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>799</td>\n",
       "      <td>01f4a0a19467947a8f3bdd7ec9fac75b5222d710</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>[   0  377  536 2604    1]</td>\n",
       "      <td>INLINEFORM0 scores</td>\n",
       "      <td>[ 3388 20006 24030   632  7586     1]</td>\n",
       "      <td>what were the evaluation metrics?\\n\\nIntroduct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>252</td>\n",
       "      <td>022c365a14fdec406c7a945a1a18e7e79df37f08</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>MT-28K</td>\n",
       "      <td>[   0    3 7323   18 2577  439    1]</td>\n",
       "      <td>the model is pre-trained on CTC-based ASR task...</td>\n",
       "      <td>[    8   825    19   554    18    17 10761    ...</td>\n",
       "      <td>What is the attention module pretrained on?\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>519</td>\n",
       "      <td>04bde1d2b445f971e97bb46ade2d0290981c7a32</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>The meta network is used to extract the shared...</td>\n",
       "      <td>[    0    37 10531  1229    19   261    12  58...</td>\n",
       "      <td>Unanswerable</td>\n",
       "      <td>[ 597 3247 3321  179    1]</td>\n",
       "      <td>What is the meta knowledge specifically?\\n\\nIn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>630</td>\n",
       "      <td>051df74dc643498e95d16e58851701628fdfd43e</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>We extracted conversation threads among users ...</td>\n",
       "      <td>[    0   101 21527  3634  4546     7   859  11...</td>\n",
       "      <td>crawling and pre-processing an OSG web forum</td>\n",
       "      <td>[18639    53    11   554    18 15056    53    ...</td>\n",
       "      <td>How did they obtain the OSG dataset?\\n\\nIntrod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>59</td>\n",
       "      <td>fd0a3e9c210163a55d3ed791e95ae3875184b8f8</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1000h of audio files</td>\n",
       "      <td>[   0 5580  107   13 2931 2073    1]</td>\n",
       "      <td>WSJ-SI84, WSJ-SI284</td>\n",
       "      <td>[   3 8439  683   18  134  196 4608    6    3 ...</td>\n",
       "      <td>Which dataset do they use?\\n\\nIntroduction\\nCo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>1165</td>\n",
       "      <td>fd753ab5177d7bd27db0e0afc12411876ee607df</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Unanswerable</td>\n",
       "      <td>[   0  597 3247 3321  179    1]</td>\n",
       "      <td>The baseline system for the SLC task is a very...</td>\n",
       "      <td>[   37 20726   358    21     8   180  6480  24...</td>\n",
       "      <td>What was the baseline for this task?\\n\\nIntrod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>392</td>\n",
       "      <td>fd753ab5177d7bd27db0e0afc12411876ee607df</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Unanswerable</td>\n",
       "      <td>[   0  597 3247 3321  179    1]</td>\n",
       "      <td>SLC task is a very simple logistic regression ...</td>\n",
       "      <td>[  180  6480  2491    19     3     9   182   6...</td>\n",
       "      <td>What was the baseline for this task?\\n\\nIntrod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>1228</td>\n",
       "      <td>ffde866b1203a01580eb33237a0bb9da71c75ecf</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>708 hours of French (Fr), German (De), Dutch (...</td>\n",
       "      <td>[    0   489  4018   716    13  2379    41   3...</td>\n",
       "      <td>Unanswerable</td>\n",
       "      <td>[ 597 3247 3321  179    1]</td>\n",
       "      <td>How big is Augmented LibriSpeech dataset?\\n\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>128</td>\n",
       "      <td>ffde866b1203a01580eb33237a0bb9da71c75ecf</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>708 hours of French (Fr), German (De), Dutch (...</td>\n",
       "      <td>[    0   489  4018   716    13  2379    41   3...</td>\n",
       "      <td>Unanswerable</td>\n",
       "      <td>[ 597 3247 3321  179    1]</td>\n",
       "      <td>How big is Augmented LibriSpeech dataset?\\n\\nI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                       ids  f1_seg_1  \\\n",
       "15     1445  012b8a89aea27485797373adbcda32f16f9d7b54   13.8889   \n",
       "21      799  01f4a0a19467947a8f3bdd7ec9fac75b5222d710    0.0000   \n",
       "23      252  022c365a14fdec406c7a945a1a18e7e79df37f08    0.0000   \n",
       "33      519  04bde1d2b445f971e97bb46ade2d0290981c7a32    0.0000   \n",
       "36      630  051df74dc643498e95d16e58851701628fdfd43e    0.0000   \n",
       "...     ...                                       ...       ...   \n",
       "1700     59  fd0a3e9c210163a55d3ed791e95ae3875184b8f8    0.0000   \n",
       "1704   1165  fd753ab5177d7bd27db0e0afc12411876ee607df    0.0000   \n",
       "1705    392  fd753ab5177d7bd27db0e0afc12411876ee607df    0.0000   \n",
       "1721   1228  ffde866b1203a01580eb33237a0bb9da71c75ecf    0.0000   \n",
       "1722    128  ffde866b1203a01580eb33237a0bb9da71c75ecf    0.0000   \n",
       "\n",
       "                                                  preds  \\\n",
       "15    Hierarchical naive Bayesian and lexicon based ...   \n",
       "21                                             F1 score   \n",
       "23                                               MT-28K   \n",
       "33    The meta network is used to extract the shared...   \n",
       "36    We extracted conversation threads among users ...   \n",
       "...                                                 ...   \n",
       "1700                               1000h of audio files   \n",
       "1704                                       Unanswerable   \n",
       "1705                                       Unanswerable   \n",
       "1721  708 hours of French (Fr), German (De), Dutch (...   \n",
       "1722  708 hours of French (Fr), German (De), Dutch (...   \n",
       "\n",
       "                                           preds_tokens  \\\n",
       "15    [    0  3204  7064  1950     3    29     9   7...   \n",
       "21                           [   0  377  536 2604    1]   \n",
       "23                 [   0    3 7323   18 2577  439    1]   \n",
       "33    [    0    37 10531  1229    19   261    12  58...   \n",
       "36    [    0   101 21527  3634  4546     7   859  11...   \n",
       "...                                                 ...   \n",
       "1700               [   0 5580  107   13 2931 2073    1]   \n",
       "1704                    [   0  597 3247 3321  179    1]   \n",
       "1705                    [   0  597 3247 3321  179    1]   \n",
       "1721  [    0   489  4018   716    13  2379    41   3...   \n",
       "1722  [    0   489  4018   716    13  2379    41   3...   \n",
       "\n",
       "                                            target_text  \\\n",
       "15    BIBREF11 that uses a character level n-gram la...   \n",
       "21                                   INLINEFORM0 scores   \n",
       "23    the model is pre-trained on CTC-based ASR task...   \n",
       "33                                         Unanswerable   \n",
       "36         crawling and pre-processing an OSG web forum   \n",
       "...                                                 ...   \n",
       "1700                                WSJ-SI84, WSJ-SI284   \n",
       "1704  The baseline system for the SLC task is a very...   \n",
       "1705  SLC task is a very simple logistic regression ...   \n",
       "1721                                       Unanswerable   \n",
       "1722                                       Unanswerable   \n",
       "\n",
       "                                                 labels  \\\n",
       "15    [    3  5972 25582   371  2596    24  2284    ...   \n",
       "21                [ 3388 20006 24030   632  7586     1]   \n",
       "23    [    8   825    19   554    18    17 10761    ...   \n",
       "33                           [ 597 3247 3321  179    1]   \n",
       "36    [18639    53    11   554    18 15056    53    ...   \n",
       "...                                                 ...   \n",
       "1700  [   3 8439  683   18  134  196 4608    6    3 ...   \n",
       "1704  [   37 20726   358    21     8   180  6480  24...   \n",
       "1705  [  180  6480  2491    19     3     9   182   6...   \n",
       "1721                         [ 597 3247 3321  179    1]   \n",
       "1722                         [ 597 3247 3321  179    1]   \n",
       "\n",
       "                                                  input  \n",
       "15    What is the approach of previous work?\\n\\nIntr...  \n",
       "21    what were the evaluation metrics?\\n\\nIntroduct...  \n",
       "23    What is the attention module pretrained on?\\n\\...  \n",
       "33    What is the meta knowledge specifically?\\n\\nIn...  \n",
       "36    How did they obtain the OSG dataset?\\n\\nIntrod...  \n",
       "...                                                 ...  \n",
       "1700  Which dataset do they use?\\n\\nIntroduction\\nCo...  \n",
       "1704  What was the baseline for this task?\\n\\nIntrod...  \n",
       "1705  What was the baseline for this task?\\n\\nIntrod...  \n",
       "1721  How big is Augmented LibriSpeech dataset?\\n\\nI...  \n",
       "1722  How big is Augmented LibriSpeech dataset?\\n\\nI...  \n",
       "\n",
       "[336 rows x 8 columns]"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_df_1024[baseline_df.f1_seg_1 > baseline_df_1024.f1_seg_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unanswerable                                                                                             56\n",
       "FastText, LexVec, LexVec Unsupervised                                                                     3\n",
       "40,000                                                                                                    1\n",
       "MEDDOCAN: Medical Document Anonymization shared task dataset BIBREF3 and                                  1\n",
       "a supervised learning model that can be used to train a crowd-based AI system                             1\n",
       "a total of 335,698 blogs                                                                                  1\n",
       "BLEU score                                                                                                1\n",
       "No                                                                                                        1\n",
       "a supervised learning system that automatically learns the number of answers for each visual question     1\n",
       "Name: preds_seg_1, dtype: int64"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmt_df[(rmt_df.f1_seg_1 - rmt_df.f1_seg_0) > 0].preds_seg_1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_segments = 2\n",
    "def split(text, n_segments=n_segments):\n",
    "    premise = text.split('?')[0]\n",
    "    encoded = tokenizer.encode(text, **encode_plus_kwargs, add_special_tokens=False)\n",
    "    segments = np.split(np.array(encoded), n_segments)    \n",
    "    texts = [tokenizer.decode(s) for s in segments]\n",
    "    \n",
    "    \n",
    "    return [premise] + texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_i = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analysis table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rm-t5-seg-2</th>\n",
       "      <th>rmt-t5-seg-1</th>\n",
       "      <th>t5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rm-t5-seg-2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmt-t5-seg-1</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rm-t5-seg-2  rmt-t5-seg-1    t5\n",
       "rm-t5-seg-2          0.00          0.18  0.42\n",
       "rmt-t5-seg-1         0.04          0.00  0.35\n",
       "t5                   0.06          0.13  0.00"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_cols = {'rm-t5-seg-2': rmt_df.f1_seg_1, 'rmt-t5-seg-1': rmt_df.f1_seg_0, 't5': baseline_df.f1_seg_1}\n",
    "comp_df = pd.DataFrame(index = f1_cols.keys(), columns = f1_cols.keys())\n",
    "\n",
    "for better_name, better_f1 in f1_cols.items():\n",
    "    for worse_name, worse_f1 in f1_cols.items():\n",
    "        num_occ = (better_f1 > worse_f1).sum()\n",
    "        comp_df.loc[worse_name, better_name] = num_occ\n",
    "        \n",
    "comp_df = (comp_df / rmt_df.shape[0]).astype(float).round(2)\n",
    "comp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look at texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unanswerable                                                                                             0.848485\n",
       "FastText, LexVec, LexVec Unsupervised                                                                    0.045455\n",
       "a supervised learning model that can be used to train a crowd-based AI system                            0.015152\n",
       "No                                                                                                       0.015152\n",
       "40,000                                                                                                   0.015152\n",
       "BLEU score                                                                                               0.015152\n",
       "a total of 335,698 blogs                                                                                 0.015152\n",
       "MEDDOCAN: Medical Document Anonymization shared task dataset BIBREF3 and                                 0.015152\n",
       "a supervised learning system that automatically learns the number of answers for each visual question    0.015152\n",
       "Name: preds_seg_1, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmt_df[rmt_df.f1_seg_1 > rmt_df.f1_seg_0].preds_seg_1.value_counts() / sum(rmt_df.f1_seg_1 > rmt_df.f1_seg_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment 1 better than segment 0: 66\n",
      "\n",
      "\n",
      "Is SemCor3.0 reflective of English language data in general\n",
      "\n",
      "Is SemCor3.0 reflective of English language data in general? Introduction Word Sense Disambiguation (WSD) is a fundamental task and long-standing challenge in Natural Language Processing (NLP), which aims to find the exact sense of an ambiguous word in a particular context BIBREF0. Previous WSD approaches can be grouped into two main categories: knowledge-based and supervised methods. Knowledge-based WSD methods rely on lexical resources like WordNet BIBREF1 and usually exploit two kinds of lexical knowledge. The gloss, which defines a word sense meaning, is first utilized in Lesk algorithm BIBREF2 and then widely taken into account in many other approaches BIBREF3, BIBREF4. Besides, structural properties of semantic graphs are mainly used in graph-based algorithms BIBREF5, BIBREF6. Traditional supervised WSD methods BIBREF7, BIBREF8, BIBREF9 focus on extracting manually designed features and then train a dedicated classifier (word expert) for every target lemma. Although word expert supervised WSD methods perform better, they are less\n",
      "\n",
      "flexible than knowledge-based methods in the all-words WSD task BIBREF10. Recent neural-based methods are devoted to dealing with this problem. BIBREF11 present a supervised classifier based on Bi-LSTM, which shares parameters among all word types except the last layer. BIBREF10 convert WSD task to a sequence labeling task, thus building a unified model for all polysemous words. However, neither of them can totally beat the best word expert supervised methods. More recently, BIBREF12 propose to leverage the gloss information from WordNet and model the semantic relationship between the context and gloss in an improved memory network. Similarly, BIBREF13 introduce a (hierarchical) co-attention mechanism to generate co-dependent representations for the context and gloss. Their attempts prove that incorporating gloss knowledge into supervised WSD approach is helpful, but they still have not achieved much improvement, because they may not make full use of gloss knowledge. In this paper, we focus on how to better leverage gloss information in a supervised neural WSD system. Recently, the pre-trained language models, such as ELMo\n",
      "seg_0: No,\n",
      "seg_1: Unanswerable\n",
      "target: Unanswerable\n",
      "\n",
      "\n",
      "Do the errors of the model reflect linguistic similarity between different L1s\n",
      "\n",
      "Do the errors of the model reflect linguistic similarity between different L1s? Introduction Several learner corpora have been compiled for English, such as the International Corpus of Learner English BIBREF0. The importance of such resources has been increasingly recognized across a variety of research areas, from Second Language Acquisition to Natural Language Processing. Recently, we have seen substantial growth in this area and new corpora for languages other than English have appeared. For Romance languages, there are a several corpora and resources for French, Spanish BIBREF1, and Italian BIBREF2. Portuguese has also received attention in the compilation of learner corpora. There are two corpora compiled at the School of Arts and Humanities of the University of Lisbon: the corpus Recolha de dados de Aprendizagem do Português L<unk>ngua Estrangeira (hereafter, Leiria corpus), with 470 texts and 70,500 tokens, and the Learner Corpus of Portuguese as Second/Foreign Language, COPLE2 BIBREF3, with 1,058 texts and\n",
      "\n",
      "201,921 tokens. The Corpus de Produç<unk>es Escritas de Aprendentes de PL2, PEAPL2 compiled at the University of Coimbra, contains 516 texts and 119,381 tokens. Finally, the Corpus de Aquisiç<unk>o de L2, CAL2, compiled at the New University of Lisbon, contains 1,380 texts and 281,301 words, and it includes texts produced by adults and children, as well as a spoken subset. The aforementioned Portuguese learner corpora contain very useful data for research, particularly for Native Language Identification (NLI), a task that has received much attention in recent years. NLI is the task of determining the native language (L1) of an author based on their second language (L2) linguistic productions BIBREF4. NLI works by identifying language use patterns that are common to groups of speakers of the same native language. This process is underpinned by the presupposition that an author’s L1 disposes them towards certain language production patterns in their L2, as influenced by their mother tongue. A major motivation for NLI is\n",
      "seg_0: No,\n",
      "seg_1: Unanswerable\n",
      "target: Unanswerable\n",
      "\n",
      "\n",
      "Did they use a crowdsourcing platform for annotations\n",
      "\n",
      "Did they use a crowdsourcing platform for annotations? Introduction The focus of the word sense disambiguation (WSD) task is polysemy, i.e. words having several substantially different meanings. Two common examples are bank (riverside or financial institution) and bass (fish or musical instrument), but usually the meanings of a word are closely related, e.g. class may refer to: (a) a group of students, (b) the period when they meet to study or (c) a room where such meetings occur. Readers deal with this problem by using a word's context and in WSD we aim at doing it automatically. The most effective solution, called supervised WSD, is to use a large number of sense-annotated occurrences of the target word to build a machine learning model to label test cases. However, this approach suffers from a knowledge acquisition bottleneck. The annotation of a separate training corpus for every target word demands a considerable amount of human labour. Therefore, this approach is unusable in applications that require WSD across a wide vocabulary, such as open-domain question answering BIBREF\n",
      "\n",
      "0. The method of monosemous relatives, which is the focus of this work, bypasses the bottleneck by gathering occurences of words related to the target word, but free from ambiguity, and treating them as training cases of the respective senses. Human labour is eliminated at the expense of accuracy, as the context of each relative only approximately matches the context of the target word sense. Monosemous relatives have been employed multiple times (see Section 2), but results remain unsatisfactory. The aim of my study is to explore the limitations of this technique by implementing and evaluating such a tool for Polish. Firstly, the method is expanded by waiving the requirement of monosemy and proposing several new sources of relatives. These previously unexplored sources are based on wordnet data and help gather many training cases from the corpus. Secondly, a well-known problem of uneven yet unknown distribution of word senses is alleviated by modifying a na<unk>ve Bayesian classifier. Thanks to this correction, the classifier is no longer biased towards senses that have more training data. Finally, a very large corpus (\n",
      "seg_0: Yes,\n",
      "seg_1: Unanswerable\n",
      "target: Unanswerable\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# max_i = 10\n",
    "print(f'Segment 1 better than segment 0: {sum((rmt_df.f1_seg_1 - rmt_df.f1_seg_0) > 0)}\\n\\n')\n",
    "slice = rmt_df[(rmt_df.f1_seg_1 - rmt_df.f1_seg_0) > 0].reset_index()\n",
    "for i, row in slice.iterrows():\n",
    "    inp = row['input']\n",
    "    spl = '\\n\\n'.join(split(row['input']))\n",
    "    print(f\"{spl}\\nseg_0: {row['preds_seg_0']},\\nseg_1: {row['preds_seg_1']}\\ntarget: {row['target_text']}\\n\\n\")\n",
    "          \n",
    "    if i > max_i:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes                                                                                                                           0.140984\n",
       "No                                                                                                                            0.127869\n",
       "English                                                                                                                       0.049180\n",
       "Unanswerable                                                                                                                  0.049180\n",
       "LSTM-based model                                                                                                              0.016393\n",
       "                                                                                                                                ...   \n",
       "gendered words                                                                                                                0.003279\n",
       "bifocal attention                                                                                                             0.003279\n",
       "a supervised learning model                                                                                                   0.003279\n",
       "a conversational search, conversational question answering, conversational recommendation, conversational natural language    0.003279\n",
       "Using a set of semantically relevant chains as input, we select the chain that contains                                       0.003279\n",
       "Name: preds_seg_0, Length: 129, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmt_df[rmt_df.f1_seg_1 < rmt_df.f1_seg_0].preds_seg_0.value_counts() / sum(rmt_df.f1_seg_1 < rmt_df.f1_seg_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment 0 better than segment 1: 305\n",
      "\n",
      "\n",
      "How do they split text to obtain sentence levels\n",
      "\n",
      "How do they split text to obtain sentence levels? Introduction Many machine learning models in question answering tasks often involve matching mechanism. For example, in factoid question answering such as SQuAD BIBREF1, one needs to match between query and corpus in order to find out the most possible fragment as answer. In multiple choice question answering, such as MC Test BIBREF2, matching mechanism can also help make the correct decision. The easiest way of matching is to calculate the cosine similarity between two vectors. It is generally done by two step: First, encode text into word vectors, sentence vectors or paragraph vectors. Second, simply calculate the cosine similarity between target vectors. This method performs well when applied to word-level matching. However, as for matching between sentences or paragraphs, a single vector is not sufficient to encode all the important information. In order to solve this problem, Wang and Jiang proposed a “compare-aggregate” BIBREF3 framework that performs word-level matching using multiple techniques followed by aggregation with convolutional neural network. In their work, they show that compare-aggregate framework can effectively\n",
      "\n",
      "match two sequences through a wide range. Although \"compare-aggregate\" matching mechanism performs well on multiple question answering tasks, it has two deficiencies. First, it tends to aggregate passively through the sequence rather than take the importance of each element into account. That is, \"compare aggregate\" model considers all the sequential contents equally. Second, \"compare aggregate\" can only take few neighboring elements into account at the same time because of the limitation of CNN kernel size. In this paper, we propose Query-based Attention CNN (QACNN) to deal with the deficiencies above. First, we add query-based attention mechanism into original \"compare aggregate\" model. Moreover, We re-design the aggregation mechanism in \"compare aggregate\" to a two-staged CNN architecture which comprises word-level aggregation and sentence-level aggregation. In this way, QACNN can efficiently extract features cross sentences. Our model consists of three components: 1) The similarity mapping layer which converts the input passage, query and choice into feature representation and perform a similarity operation to each other. 2) The attention-based CNN matching network composed of a\n",
      "seg_0: Unanswerable,\n",
      "seg_1: No\n",
      "target: Unanswerable\n",
      "\n",
      "\n",
      "what were the evaluation metrics\n",
      "\n",
      "what were the evaluation metrics? Introduction Grammar induction is the task of inducing hierarchical syntactic structure from data. Statistical approaches to grammar induction require specifying a probabilistic grammar (e.g. formalism, number and shape of rules), and fitting its parameters through optimization. Early work found that it was difficult to induce probabilistic context-free grammars (PCFG) from natural language data through direct methods, such as optimizing the log likelihood with the EM algorithm BIBREF0, BIBREF1. While the reasons for the failure are manifold and not completely understood, two major potential causes are the ill-behaved optimization landscape and the overly strict independence assumptions of PCFGs. More successful approaches to grammar induction have thus resorted to carefully-crafted auxiliary objectives BIBREF2, priors or non-parametric models BIBREF3, BIBREF4, BIBREF5, BIBREF6, and manually-engineered features BIBREF7, BIBREF8 to encourage the desired structures to emerge. We revisit these aforementioned issues in light\n",
      "\n",
      "of advances in model parameterization and inference. First, contrary to common wisdom, we find that parameterizing a PCFG's rule probabilities with neural networks over distributed representations makes it possible to induce linguistically meaningful grammars by simply optimizing log likelihood. While the optimization problem remains non-convex, recent work suggests that there are optimization benefits afforded by over-parameterized models BIBREF9, BIBREF10, BIBREF11, and we indeed find that this neural PCFG is significantly easier to optimize than the traditional PCFG. Second, this factored parameterization makes it straightforward to incorporate side information into rule probabilities through a sentence-level continuous latent vector, which effectively allows different contexts in a derivation to coordinate. In this compound PCFG—continuous mixture of PCFGs—the context-free assumptions hold conditioned on the latent vector but not unconditionally, thereby obtaining longer-range dependencies within a tree-based generative process. To utilize this approach, we need to efficiently optimize the log marginal likelihood of observed sentences. While compound PCFGs break efficient inference, if the latent vector\n",
      "seg_0: BLEU scores,\n",
      "seg_1: Unanswerable\n",
      "target: INLINEFORM0 scores\n",
      "\n",
      "\n",
      "What is the meta knowledge specifically\n",
      "\n",
      "What is the meta knowledge specifically? Introduction Learning the distributed representation for long spans of text from its constituents has been a key step for various natural language processing (NLP) tasks, such as text classification BIBREF0, BIBREF1, semantic matching BIBREF2, BIBREF3, and machine translation BIBREF4. Existing deep learning approaches take a compositional function with different forms to compose word vectors recursively until obtaining a sentential representation. Typically, these compositional functions involve recurrent neural networks BIBREF5, BIBREF6, convolutional neural networks BIBREF7, BIBREF8, and tree-structured neural networks BIBREF9, BIBREF10. Among these methods, tree-structured neural networks (Tree-NNs) show theirs superior performance in many NLP tasks BIBREF11, BIBREF12. Following the syntactic tree structure, Tree-NNs assign a fixed-length vector to each word at the leaves of the tree, and\n",
      "\n",
      "combine word and phrase pairs recursively to create intermediate node vectors, eventually obtaining one final vector to represent the whole sentence. However, these models have a major limitation in their inability to fully capture the richness of compositionality BIBREF13. The same parameters are used for all kinds of semantic compositions, even though the compositions have different characteristics in nature. For example, the composition of the adjective and the noun differs significantly from the composition of the verb and the noun. Moreover, many semantic phenomena, such as semantic idiomaticity or transparency, call for more powerful compositional mechanisms BIBREF14. Therefore, Tree-NNs suffer from the underfitting problem. To alleviate this problem, some researchers propose to use multiple compositional functions, which are arranged beforehand according to some partition criterion BIBREF11, BIBREF13, BIBREF15. Intuitively, using different parameters for different types of compositions has the potential to greatly reduce underfitting. BIBREF13 [ BIBREF13 ] defined different compositional functions in terms of syntactic categories, and\n",
      "seg_0: Unanswerable,\n",
      "seg_1: No\n",
      "target: Unanswerable\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# max_i = 10\n",
    "print(f'Segment 0 better than segment 1: {sum((rmt_df.f1_seg_1 - rmt_df.f1_seg_0) < 0)}\\n\\n')\n",
    "slice = rmt_df[(rmt_df.f1_seg_1 - rmt_df.f1_seg_0) < 0].reset_index()\n",
    "for i, row in slice.iterrows():\n",
    "    inp = row['input']\n",
    "    spl = '\\n\\n'.join(split(row['input']))\n",
    "    print(f\"{spl}\\nseg_0: {row['preds_seg_0']},\\nseg_1: {row['preds_seg_1']}\\ntarget: {row['target_text']}\\n\\n\")\n",
    "          \n",
    "    if i > max_i:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes                                                                                               0.071031\n",
       "No                                                                                                0.062674\n",
       "Unanswerable                                                                                      0.019499\n",
       "English                                                                                           0.015320\n",
       "profanity, insult, and abuse                                                                      0.005571\n",
       "                                                                                                    ...   \n",
       "Annotation of a target with or without affiliation to a political party                           0.001393\n",
       "BiLSTM+CNN+CRF, Stanford CRF, BiLSTM+C                                                            0.001393\n",
       "probes from BIBREF1                                                                               0.001393\n",
       "using the BLEU scale                                                                              0.001393\n",
       "The data collected for the news broadcast domain and the role of annotator is used to evaluate    0.001393\n",
       "Name: preds, Length: 396, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rmt_df[baseline_df.f1_seg_1 > rmt_df.f1_seg_0].preds_seg_1.value_counts() / sum(baseline_df.f1_seg_1 > rmt_df.f1_seg_0)\n",
    "baseline_df[baseline_df.f1_seg_1 > rmt_df.f1_seg_1].preds.value_counts() / sum(baseline_df.f1_seg_1 > rmt_df.f1_seg_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment 0 better than baseline: 223\n",
      "\n",
      "\n",
      "How do they split text to obtain sentence levels\n",
      "\n",
      "How do they split text to obtain sentence levels? Introduction Many machine learning models in question answering tasks often involve matching mechanism. For example, in factoid question answering such as SQuAD BIBREF1, one needs to match between query and corpus in order to find out the most possible fragment as answer. In multiple choice question answering, such as MC Test BIBREF2, matching mechanism can also help make the correct decision. The easiest way of matching is to calculate the cosine similarity between two vectors. It is generally done by two step: First, encode text into word vectors, sentence vectors or paragraph vectors. Second, simply calculate the cosine similarity between target vectors. This method performs well when applied to word-level matching. However, as for matching between sentences or paragraphs, a single vector is not sufficient to encode all the important information. In order to solve this problem, Wang and Jiang proposed a “compare-aggregate” BIBREF3 framework that performs word-level matching using multiple techniques followed by aggregation with convolutional neural network. In their work, they show that compare-aggregate framework can effectively\n",
      "\n",
      "match two sequences through a wide range. Although \"compare-aggregate\" matching mechanism performs well on multiple question answering tasks, it has two deficiencies. First, it tends to aggregate passively through the sequence rather than take the importance of each element into account. That is, \"compare aggregate\" model considers all the sequential contents equally. Second, \"compare aggregate\" can only take few neighboring elements into account at the same time because of the limitation of CNN kernel size. In this paper, we propose Query-based Attention CNN (QACNN) to deal with the deficiencies above. First, we add query-based attention mechanism into original \"compare aggregate\" model. Moreover, We re-design the aggregation mechanism in \"compare aggregate\" to a two-staged CNN architecture which comprises word-level aggregation and sentence-level aggregation. In this way, QACNN can efficiently extract features cross sentences. Our model consists of three components: 1) The similarity mapping layer which converts the input passage, query and choice into feature representation and perform a similarity operation to each other. 2) The attention-based CNN matching network composed of a\n",
      "seg_0: Unanswerable,\n",
      "seg_1: No\n",
      "baseline: They encode text into word vectors, sentence vectors or paragraph vectors and then convert them\n",
      "target: Unanswerable\n",
      "\n",
      "\n",
      "what were the evaluation metrics\n",
      "\n",
      "what were the evaluation metrics? Introduction Grammar induction is the task of inducing hierarchical syntactic structure from data. Statistical approaches to grammar induction require specifying a probabilistic grammar (e.g. formalism, number and shape of rules), and fitting its parameters through optimization. Early work found that it was difficult to induce probabilistic context-free grammars (PCFG) from natural language data through direct methods, such as optimizing the log likelihood with the EM algorithm BIBREF0, BIBREF1. While the reasons for the failure are manifold and not completely understood, two major potential causes are the ill-behaved optimization landscape and the overly strict independence assumptions of PCFGs. More successful approaches to grammar induction have thus resorted to carefully-crafted auxiliary objectives BIBREF2, priors or non-parametric models BIBREF3, BIBREF4, BIBREF5, BIBREF6, and manually-engineered features BIBREF7, BIBREF8 to encourage the desired structures to emerge. We revisit these aforementioned issues in light\n",
      "\n",
      "of advances in model parameterization and inference. First, contrary to common wisdom, we find that parameterizing a PCFG's rule probabilities with neural networks over distributed representations makes it possible to induce linguistically meaningful grammars by simply optimizing log likelihood. While the optimization problem remains non-convex, recent work suggests that there are optimization benefits afforded by over-parameterized models BIBREF9, BIBREF10, BIBREF11, and we indeed find that this neural PCFG is significantly easier to optimize than the traditional PCFG. Second, this factored parameterization makes it straightforward to incorporate side information into rule probabilities through a sentence-level continuous latent vector, which effectively allows different contexts in a derivation to coordinate. In this compound PCFG—continuous mixture of PCFGs—the context-free assumptions hold conditioned on the latent vector but not unconditionally, thereby obtaining longer-range dependencies within a tree-based generative process. To utilize this approach, we need to efficiently optimize the log marginal likelihood of observed sentences. While compound PCFGs break efficient inference, if the latent vector\n",
      "seg_0: BLEU scores,\n",
      "seg_1: Unanswerable\n",
      "baseline: F1 score\n",
      "target: INLINEFORM0 scores\n",
      "\n",
      "\n",
      "What is the meta knowledge specifically\n",
      "\n",
      "What is the meta knowledge specifically? Introduction Learning the distributed representation for long spans of text from its constituents has been a key step for various natural language processing (NLP) tasks, such as text classification BIBREF0, BIBREF1, semantic matching BIBREF2, BIBREF3, and machine translation BIBREF4. Existing deep learning approaches take a compositional function with different forms to compose word vectors recursively until obtaining a sentential representation. Typically, these compositional functions involve recurrent neural networks BIBREF5, BIBREF6, convolutional neural networks BIBREF7, BIBREF8, and tree-structured neural networks BIBREF9, BIBREF10. Among these methods, tree-structured neural networks (Tree-NNs) show theirs superior performance in many NLP tasks BIBREF11, BIBREF12. Following the syntactic tree structure, Tree-NNs assign a fixed-length vector to each word at the leaves of the tree, and\n",
      "\n",
      "combine word and phrase pairs recursively to create intermediate node vectors, eventually obtaining one final vector to represent the whole sentence. However, these models have a major limitation in their inability to fully capture the richness of compositionality BIBREF13. The same parameters are used for all kinds of semantic compositions, even though the compositions have different characteristics in nature. For example, the composition of the adjective and the noun differs significantly from the composition of the verb and the noun. Moreover, many semantic phenomena, such as semantic idiomaticity or transparency, call for more powerful compositional mechanisms BIBREF14. Therefore, Tree-NNs suffer from the underfitting problem. To alleviate this problem, some researchers propose to use multiple compositional functions, which are arranged beforehand according to some partition criterion BIBREF11, BIBREF13, BIBREF15. Intuitively, using different parameters for different types of compositions has the potential to greatly reduce underfitting. BIBREF13 [ BIBREF13 ] defined different compositional functions in terms of syntactic categories, and\n",
      "seg_0: Unanswerable,\n",
      "seg_1: No\n",
      "baseline: The meta network is used to extract the shared meta-knowledge across different compositional rules and\n",
      "target: Unanswerable\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# max_i = 10\n",
    "mask = (rmt_df.f1_seg_0 - baseline_df.f1_seg_1) > 0\n",
    "print(f'Segment 0 better than baseline: {sum(mask)}\\n\\n')\n",
    "slice = rmt_df[mask].reset_index()\n",
    "slice_bl = baseline_df[mask].reset_index()\n",
    "for i, row in slice.iterrows():\n",
    "    inp = row['input']\n",
    "    spl = '\\n\\n'.join(split(row['input']))\n",
    "    # bl_pred = baseline_df[baseline_df.ids == row['ids']].preds.iloc[0]\n",
    "    bl_pred = slice_bl.iloc[i].preds\n",
    "    # print(slice.iloc[i])\n",
    "    # print(slice_bl.iloc[i])\n",
    "    print(f\"{spl}\\nseg_0: {row['preds_seg_0']},\\nseg_1: {row['preds_seg_1']}\\nbaseline: {bl_pred}\\ntarget: {row['target_text']}\\n\\n\")\n",
    "          \n",
    "    if i > max_i:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment 0 worse than baseline: 610\n",
      "\n",
      "\n",
      "Is SemCor3.0 reflective of English language data in general\n",
      "\n",
      "Is SemCor3.0 reflective of English language data in general? Introduction Word Sense Disambiguation (WSD) is a fundamental task and long-standing challenge in Natural Language Processing (NLP), which aims to find the exact sense of an ambiguous word in a particular context BIBREF0. Previous WSD approaches can be grouped into two main categories: knowledge-based and supervised methods. Knowledge-based WSD methods rely on lexical resources like WordNet BIBREF1 and usually exploit two kinds of lexical knowledge. The gloss, which defines a word sense meaning, is first utilized in Lesk algorithm BIBREF2 and then widely taken into account in many other approaches BIBREF3, BIBREF4. Besides, structural properties of semantic graphs are mainly used in graph-based algorithms BIBREF5, BIBREF6. Traditional supervised WSD methods BIBREF7, BIBREF8, BIBREF9 focus on extracting manually designed features and then train a dedicated classifier (word expert) for every target lemma. Although word expert supervised WSD methods perform better, they are less\n",
      "\n",
      "flexible than knowledge-based methods in the all-words WSD task BIBREF10. Recent neural-based methods are devoted to dealing with this problem. BIBREF11 present a supervised classifier based on Bi-LSTM, which shares parameters among all word types except the last layer. BIBREF10 convert WSD task to a sequence labeling task, thus building a unified model for all polysemous words. However, neither of them can totally beat the best word expert supervised methods. More recently, BIBREF12 propose to leverage the gloss information from WordNet and model the semantic relationship between the context and gloss in an improved memory network. Similarly, BIBREF13 introduce a (hierarchical) co-attention mechanism to generate co-dependent representations for the context and gloss. Their attempts prove that incorporating gloss knowledge into supervised WSD approach is helpful, but they still have not achieved much improvement, because they may not make full use of gloss knowledge. In this paper, we focus on how to better leverage gloss information in a supervised neural WSD system. Recently, the pre-trained language models, such as ELMo\n",
      "seg_0: No,\n",
      "seg_1: Unanswerable\n",
      "baseline: Yes\n",
      "target: Yes\n",
      "\n",
      "\n",
      "What model is used as a baseline\n",
      "\n",
      "What model is used as a baseline? Introduction Reading Comprehension (RC) has become a central task in natural language processing, with great practical value in various industries. In recent years, many large-scale RC datasets in English BIBREF0, BIBREF1, BIBREF2, BIBREF3, BIBREF4, BIBREF5, BIBREF6 have nourished the development of numerous powerful and diverse RC models BIBREF7, BIBREF8, BIBREF9, BIBREF10, BIBREF11. The state-of-the-art model BIBREF12 on SQuAD, one of the most widely used RC benchmarks, even surpasses human-level performance. Nonetheless, RC on languages other than English has been limited due to the absence of sufficient training data. Although some efforts have been made to create RC datasets for Chinese BIBREF13, BIBREF14 and Korean BIBREF15, it is not feasible to collect RC datasets for every language since annotation efforts to collect a new RC dataset are often far from trivial. Therefore, the\n",
      "\n",
      "setup of transfer learning, especially zero-shot learning, is of extraordinary importance. Existing methods BIBREF16 of cross-lingual transfer learning on RC datasets often count on machine translation (MT) to translate data from source language into target language, or vice versa. These methods may not require a well-annotated RC dataset for the target language, whereas a high-quality MT model is needed as a trade-off, which might not be available when it comes to low-resource languages. In this paper, we leverage pre-trained multilingual language representation, for example, BERT learned from multilingual un-annotated sentences (multi-BERT), in cross-lingual zero-shot RC. We fine-tune multi-BERT on the training set in source language, then test the model in target language, with a number of combinations of source-target language pair to explore the cross-lingual ability of multi-BERT. Surprisingly, we find that the models have the ability to transfer between low lexical similarity language pair, such as English and Chinese. Recent studies BIBREF17, BIBREF12, BI\n",
      "seg_0: BIBREF16, BIBREF17, BIBREF18,\n",
      "seg_1: Unanswerable\n",
      "baseline: BERT\n",
      "target: QANet , BIBREF14,  fine-tuned a BERT model\n",
      "\n",
      "\n",
      "Do they evaluate only on English datasets\n",
      "\n",
      "Do they evaluate only on English datasets? Introduction In recent years, there has been a movement to leverage social medial data to detect, estimate, and track the change in prevalence of disease. For example, eating disorders in Spanish language Twitter tweets BIBREF0 and influenza surveillance BIBREF1. More recently, social media has been leveraged to monitor social risks such as prescription drug and smoking behaviors BIBREF2, BIBREF3, BIBREF4 as well as a variety of mental health disorders including suicidal ideation BIBREF5, attention deficient hyperactivity disorder BIBREF6 and major depressive disorder BIBREF7. In the case of major depressive disorder, recent efforts range from characterizing linguistic phenomena associated with depression BIBREF8 and its subtypes e.g., postpartum depression BIBREF5, to identifying specific depressive symptoms BIBREF9, BIBREF10 e.g., depressed mood. However, more research is needed to better understand the predictive power of supervised machine learning classifiers and the influence of feature groups and\n",
      "\n",
      "feature sets for efficiently classifying depression-related tweets to support mental health monitoring at the population-level BIBREF11. This paper builds upon related works toward classifying Twitter tweets representing symptoms of major depressive disorder by assessing the contribution of lexical features (e.g., unigrams) and emotion (e.g., strongly negative) to classification performance, and by applying methods to eliminate low-value features. METHODS Specifically, we conducted a feature ablation study to assess the informativeness of each feature group and a feature elimination study to determine the optimal feature sets for classifying Twitter tweets. We leveraged an existing, annotated Twitter dataset that was constructed based on a hierarchical model of depression-related symptoms BIBREF12, BIBREF13. The dataset contains 9,473 annotations for 9,300 tweets. Each tweet is annotated as no evidence of depression (e.g., “Citizens fear an economic depression\") or evidence of depression (e.g., “depressed over disappointment\"). If a tweet is annotated evidence of depression, then it is further annot\n",
      "seg_0: No,\n",
      "seg_1: Unanswerable\n",
      "baseline: Yes\n",
      "target: Yes\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_i = 1\n",
    "mask = (rmt_df.f1_seg_0 - baseline_df.f1_seg_1) < 0\n",
    "print(f'Segment 0 worse than baseline: {sum(mask)}\\n\\n')\n",
    "slice = rmt_df[mask].reset_index()\n",
    "for i, row in slice.iterrows():\n",
    "    inp = row['input']\n",
    "    spl = '\\n\\n'.join(split(row['input']))\n",
    "    bl_pred = baseline_df[baseline_df.ids == row['ids']].preds.iloc[0]\n",
    "    # bl_pred = baseline_df[baseline_df.ids == row['ids']].preds\n",
    "    print(f\"{spl}\\nseg_0: {row['preds_seg_0']},\\nseg_1: {row['preds_seg_1']}\\nbaseline: {bl_pred}\\ntarget: {row['target_text']}\\n\\n\")\n",
    "          \n",
    "    if i > max_i:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment 1 better than baseline: 101\n",
      "\n",
      "\n",
      "Is SemCor3.0 reflective of English language data in general\n",
      "\n",
      "Is SemCor3.0 reflective of English language data in general? Introduction Word Sense Disambiguation (WSD) is a fundamental task and long-standing challenge in Natural Language Processing (NLP), which aims to find the exact sense of an ambiguous word in a particular context BIBREF0. Previous WSD approaches can be grouped into two main categories: knowledge-based and supervised methods. Knowledge-based WSD methods rely on lexical resources like WordNet BIBREF1 and usually exploit two kinds of lexical knowledge. The gloss, which defines a word sense meaning, is first utilized in Lesk algorithm BIBREF2 and then widely taken into account in many other approaches BIBREF3, BIBREF4. Besides, structural properties of semantic graphs are mainly used in graph-based algorithms BIBREF5, BIBREF6. Traditional supervised WSD methods BIBREF7, BIBREF8, BIBREF9 focus on extracting manually designed features and then train a dedicated classifier (word expert) for every target lemma. Although word expert supervised WSD methods perform better, they are less\n",
      "\n",
      "flexible than knowledge-based methods in the all-words WSD task BIBREF10. Recent neural-based methods are devoted to dealing with this problem. BIBREF11 present a supervised classifier based on Bi-LSTM, which shares parameters among all word types except the last layer. BIBREF10 convert WSD task to a sequence labeling task, thus building a unified model for all polysemous words. However, neither of them can totally beat the best word expert supervised methods. More recently, BIBREF12 propose to leverage the gloss information from WordNet and model the semantic relationship between the context and gloss in an improved memory network. Similarly, BIBREF13 introduce a (hierarchical) co-attention mechanism to generate co-dependent representations for the context and gloss. Their attempts prove that incorporating gloss knowledge into supervised WSD approach is helpful, but they still have not achieved much improvement, because they may not make full use of gloss knowledge. In this paper, we focus on how to better leverage gloss information in a supervised neural WSD system. Recently, the pre-trained language models, such as ELMo\n",
      "seg_0: No,\n",
      "seg_1: Unanswerable\n",
      "baseline: Yes\n",
      "target: Unanswerable\n",
      "\n",
      "\n",
      "Do the errors of the model reflect linguistic similarity between different L1s\n",
      "\n",
      "Do the errors of the model reflect linguistic similarity between different L1s? Introduction Several learner corpora have been compiled for English, such as the International Corpus of Learner English BIBREF0. The importance of such resources has been increasingly recognized across a variety of research areas, from Second Language Acquisition to Natural Language Processing. Recently, we have seen substantial growth in this area and new corpora for languages other than English have appeared. For Romance languages, there are a several corpora and resources for French, Spanish BIBREF1, and Italian BIBREF2. Portuguese has also received attention in the compilation of learner corpora. There are two corpora compiled at the School of Arts and Humanities of the University of Lisbon: the corpus Recolha de dados de Aprendizagem do Português L<unk>ngua Estrangeira (hereafter, Leiria corpus), with 470 texts and 70,500 tokens, and the Learner Corpus of Portuguese as Second/Foreign Language, COPLE2 BIBREF3, with 1,058 texts and\n",
      "\n",
      "201,921 tokens. The Corpus de Produç<unk>es Escritas de Aprendentes de PL2, PEAPL2 compiled at the University of Coimbra, contains 516 texts and 119,381 tokens. Finally, the Corpus de Aquisiç<unk>o de L2, CAL2, compiled at the New University of Lisbon, contains 1,380 texts and 281,301 words, and it includes texts produced by adults and children, as well as a spoken subset. The aforementioned Portuguese learner corpora contain very useful data for research, particularly for Native Language Identification (NLI), a task that has received much attention in recent years. NLI is the task of determining the native language (L1) of an author based on their second language (L2) linguistic productions BIBREF4. NLI works by identifying language use patterns that are common to groups of speakers of the same native language. This process is underpinned by the presupposition that an author’s L1 disposes them towards certain language production patterns in their L2, as influenced by their mother tongue. A major motivation for NLI is\n",
      "seg_0: No,\n",
      "seg_1: Unanswerable\n",
      "baseline: No\n",
      "target: Unanswerable\n",
      "\n",
      "\n",
      "Did they use a crowdsourcing platform for annotations\n",
      "\n",
      "Did they use a crowdsourcing platform for annotations? Introduction The focus of the word sense disambiguation (WSD) task is polysemy, i.e. words having several substantially different meanings. Two common examples are bank (riverside or financial institution) and bass (fish or musical instrument), but usually the meanings of a word are closely related, e.g. class may refer to: (a) a group of students, (b) the period when they meet to study or (c) a room where such meetings occur. Readers deal with this problem by using a word's context and in WSD we aim at doing it automatically. The most effective solution, called supervised WSD, is to use a large number of sense-annotated occurrences of the target word to build a machine learning model to label test cases. However, this approach suffers from a knowledge acquisition bottleneck. The annotation of a separate training corpus for every target word demands a considerable amount of human labour. Therefore, this approach is unusable in applications that require WSD across a wide vocabulary, such as open-domain question answering BIBREF\n",
      "\n",
      "0. The method of monosemous relatives, which is the focus of this work, bypasses the bottleneck by gathering occurences of words related to the target word, but free from ambiguity, and treating them as training cases of the respective senses. Human labour is eliminated at the expense of accuracy, as the context of each relative only approximately matches the context of the target word sense. Monosemous relatives have been employed multiple times (see Section 2), but results remain unsatisfactory. The aim of my study is to explore the limitations of this technique by implementing and evaluating such a tool for Polish. Firstly, the method is expanded by waiving the requirement of monosemy and proposing several new sources of relatives. These previously unexplored sources are based on wordnet data and help gather many training cases from the corpus. Secondly, a well-known problem of uneven yet unknown distribution of word senses is alleviated by modifying a na<unk>ve Bayesian classifier. Thanks to this correction, the classifier is no longer biased towards senses that have more training data. Finally, a very large corpus (\n",
      "seg_0: Yes,\n",
      "seg_1: Unanswerable\n",
      "baseline: Yes\n",
      "target: Unanswerable\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_i = 1\n",
    "mask = (rmt_df.f1_seg_1 - baseline_df.f1_seg_1) > 0\n",
    "print(f'Segment 1 better than baseline: {sum(mask)}\\n\\n')\n",
    "slice = rmt_df[mask].reset_index()\n",
    "for i, row in slice.iterrows():\n",
    "    inp = row['input']\n",
    "    spl = '\\n\\n'.join(split(row['input']))\n",
    "    bl_pred = baseline_df[baseline_df.ids == row['ids']].preds.iloc[0]\n",
    "    print(f\"{spl}\\nseg_0: {row['preds_seg_0']},\\nseg_1: {row['preds_seg_1']}\\nbaseline: {bl_pred}\\ntarget: {row['target_text']}\\n\\n\")\n",
    "          \n",
    "    if i > max_i:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unanswerable                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              0.861386\n",
       "Yes                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       0.039604\n",
       "BERT remains only 0.3 F1-score points behind, and would have achieved the second position among all the MEDDOCAN shared task competitors. Taking into account that only 3% of the gold labels remain incorrectly annotated,  Table                                                                                                                                                                                                                                                                                        0.009901\n",
       "density of users, gender distribution                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     0.009901\n",
       "“Intelligence Squared Debates” (IQ2 for short)                                                                                                                                                                                                                                                                                                                                                                                                                                                                            0.009901\n",
       "random forest, The question is encoded with a 1024-dimensional LSTM model that takes in a one-hot descriptor of each word in the question. The image is described with the 4096-dimensional output from the last fully connected layer of the Convolutional Neural Network (CNN), VGG16 BIBREF25 . The system performs an element-wise multiplication of the image and question features, after linearly transforming the image descriptor to 1024 dimensions. The final layer of the architecture is a softmax layer.    0.009901\n",
       "No                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        0.009901\n",
       "simple n-grams (like fastText) and unsupervised morphemes                                                                                                                                                                                                                                                                                                                                                                                                                                                                 0.009901\n",
       "LSTM to encode the question, VGG16 to extract visual features. The outputs of LSTM and VGG16 are multiplied element-wise and sent to a softmax layer.                                                                                                                                                                                                                                                                                                                                                                     0.009901\n",
       "The LexVec BIBREF7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        0.009901\n",
       "n-gram subwords, unsupervised morphemes identified using Morfessor BIBREF11 to learn whether more linguistically motivated subwords                                                                                                                                                                                                                                                                                                                                                                                       0.009901\n",
       "Bert + Unanswerable                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       0.009901\n",
       "Name: target_text, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmt_df[mask].target_text.value_counts() / sum(mask)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15ebdd31b1273fe4d2b1fe1822219a570cf61693f7cab545dbe286c10cf9691f"
  },
  "kernelspec": {
   "display_name": "hvdenv",
   "language": "python",
   "name": "hvdenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
