{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from transformers import PreTrainedModel, AutoModelForSequenceClassification\n",
    "\n",
    "import math\n",
    "\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from transformers import BertForSequenceClassification\n",
    "import transformers\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "# from modeling_rmt import RMTEncoderForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import types\n",
    "\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPastAndCrossAttentions\n",
    "\n",
    "def encoder_memory_forward(\n",
    "    self,\n",
    "    hidden_states: torch.Tensor,\n",
    "    attention_mask: Optional[torch.FloatTensor] = None,\n",
    "    head_mask: Optional[torch.FloatTensor] = None,\n",
    "    encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
    "    encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
    "    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "    use_cache: Optional[bool] = None,\n",
    "    output_attentions: Optional[bool] = False,\n",
    "    output_hidden_states: Optional[bool] = False,\n",
    "    return_dict: Optional[bool] = True,\n",
    "    memory_storage = None\n",
    ") -> Union[Tuple[torch.Tensor], BaseModelOutputWithPastAndCrossAttentions]:\n",
    "    '''\n",
    "    Copy-pasted from BERT encoder\n",
    "    '''\n",
    "    all_hidden_states = () if output_hidden_states else None\n",
    "    all_self_attentions = () if output_attentions else None\n",
    "    all_cross_attentions = () if output_attentions and self.config.add_cross_attention else None\n",
    "\n",
    "    next_decoder_cache = () if use_cache else None\n",
    "    for i, layer_module in enumerate(self.layer):\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "        layer_head_mask = head_mask[i] if head_mask is not None else None\n",
    "        past_key_value = past_key_values[i] if past_key_values is not None else None\n",
    "\n",
    "        if self.gradient_checkpointing and self.training:\n",
    "\n",
    "            # TBD: load logger \n",
    "            # if use_cache:\n",
    "            #     logger.warning(\n",
    "            #         \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\"\n",
    "            #     )\n",
    "            #     use_cache = False\n",
    "\n",
    "            def create_custom_forward(module):\n",
    "                def custom_forward(*inputs):\n",
    "                    return module(*inputs, past_key_value, output_attentions)\n",
    "\n",
    "                return custom_forward\n",
    "\n",
    "            layer_outputs = torch.utils.checkpoint.checkpoint(\n",
    "                create_custom_forward(layer_module),\n",
    "                hidden_states,\n",
    "                attention_mask,\n",
    "                layer_head_mask,\n",
    "                encoder_hidden_states,\n",
    "                encoder_attention_mask,\n",
    "            )\n",
    "        else:\n",
    "            num_mem = memory_storage['num_mem_tokens']\n",
    "            if (i in memory_storage) and (i > 0):\n",
    "                layer_memory = memory_storage[i]\n",
    "                for j, h in enumerate(hidden_states):\n",
    "                    hidden_states[j][:layer_memory[j].shape[0]] = layer_memory[j]\n",
    "\n",
    "            # print(f'hidden states shape: {len(hidden_states), hidden_states[0].shape}\\n memory storage:{memory_storage.keys()}')\n",
    "            layer_outputs = layer_module(\n",
    "                hidden_states,\n",
    "                attention_mask,\n",
    "                layer_head_mask,\n",
    "                encoder_hidden_states,\n",
    "                encoder_attention_mask,\n",
    "                past_key_value,\n",
    "                output_attentions,\n",
    "            )\n",
    "            \n",
    "        hidden_states = layer_outputs[0]\n",
    "        if i in memory_storage:\n",
    "            # print(f'replacing ms[i] {memory_storage[i][0][0][:10]}... to {[h[:num_mem] for h in hidden_states][0][0][:10]}')\n",
    "            memory_storage[i] = [h[:num_mem] for h in hidden_states]\n",
    "\n",
    "        # print(f'Overrided method message: hidden states shape: {len(hidden_states), hidden_states[0].shape}\\n memory storage:{memory_storage}')\n",
    "        if use_cache:\n",
    "            next_decoder_cache += (layer_outputs[-1],)\n",
    "        if output_attentions:\n",
    "            all_self_attentions = all_self_attentions + (layer_outputs[1],)\n",
    "            if self.config.add_cross_attention:\n",
    "                all_cross_attentions = all_cross_attentions + (layer_outputs[2],)\n",
    "\n",
    "    if output_hidden_states:\n",
    "        all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "    if not return_dict:\n",
    "        return tuple(\n",
    "            v\n",
    "            for v in [\n",
    "                hidden_states,\n",
    "                next_decoder_cache,\n",
    "                all_hidden_states,\n",
    "                all_self_attentions,\n",
    "                all_cross_attentions,\n",
    "            ]\n",
    "            if v is not None\n",
    "        )\n",
    "    return BaseModelOutputWithPastAndCrossAttentions(\n",
    "        last_hidden_state=hidden_states,\n",
    "        past_key_values=next_decoder_cache,\n",
    "        hidden_states=all_hidden_states,\n",
    "        attentions=all_self_attentions,\n",
    "        cross_attentions=all_cross_attentions,\n",
    "    )\n",
    "\n",
    "\n",
    "class RMTEncoderForSequenceClassification():\n",
    "    '''\n",
    "    Usage\n",
    "    \n",
    "    Way 1: from config\n",
    "    rmt = RMTEncoderForSequenceClassification(config=config)\n",
    "\n",
    "    Way 2: from HF model name\n",
    "    model_name = \"bert-base-cased\"\n",
    "    rmt = RMTEncoderForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    Way 3: from instance of HF model\n",
    "    model = AutoModelForSequenceClassification(\"bert-base-cased\") \n",
    "    rmt = RMTEncoderForSequenceClassification(base_model=model)\n",
    "\n",
    "    '''\n",
    "    def __init__(self, config=None, base_model=None, **kwargs):\n",
    "        if config is not None:\n",
    "            self.model = AutoModelForSequenceClassification(config, **kwargs)\n",
    "        \n",
    "        if base_model is not None:\n",
    "            self.model = base_model\n",
    "\n",
    "\n",
    "    def from_pretrained(from_pretrained, **kwargs):\n",
    "        base_model = AutoModelForSequenceClassification.from_pretrained(from_pretrained, **kwargs)\n",
    "        rmt = RMTEncoderForSequenceClassification(base_model=base_model)\n",
    "        return rmt\n",
    "        \n",
    "\n",
    "    def set_params(self, \n",
    "                backbone_cls=None,\n",
    "                num_mem_tokens=0, \n",
    "                inter_layer_memory=False,\n",
    "                segment_ordering='regular',\n",
    "                input_size=None, \n",
    "                input_seg_size=None, \n",
    "                bptt_depth=-1, \n",
    "                drop_empty_segments=True,\n",
    "                sum_loss=False,\n",
    "                # special_tokens=None,\n",
    "                tokenizer=None\n",
    "                  ):\n",
    "        \n",
    "        if input_size is not None:\n",
    "            self.input_size = input_size\n",
    "        else:\n",
    "            self.input_size =  self.base_model.embeddings.position_embeddings.weight.shape[0]\n",
    "        self.input_seg_size = input_seg_size\n",
    "\n",
    "        # print('\\n\\n\\n', special_tokens)\n",
    "        \n",
    "        self.bptt_depth = bptt_depth\n",
    "        # self.pad_token_id = special_tokens['pad_token_id']\n",
    "        # self.cls_token = torch.tensor([special_tokens['cls_token_id']])\n",
    "        # self.sep_token = torch.tensor([special_tokens['sep_token_id']])\n",
    "        self.pad_token_id = tokenizer.pad_token_id\n",
    "        self.cls_token = torch.tensor([tokenizer.cls_token_id])\n",
    "        self.sep_token = torch.tensor([tokenizer.sep_token_id])\n",
    "        \n",
    "        self.num_mem_tokens = num_mem_tokens\n",
    "        self.segment_ordering = segment_ordering\n",
    "        self.drop_empty_segments = drop_empty_segments\n",
    "        self.sum_loss = sum_loss\n",
    "        self.extend_word_embeddings()\n",
    "\n",
    "        if inter_layer_memory:\n",
    "            self.override_encoder_forward()\n",
    "\n",
    "\n",
    "    def set_memory(self, memory=None):\n",
    "        if memory is None:\n",
    "            mem_token_ids = self.mem_token_ids.to(device=self.device)\n",
    "            memory = self.base_model.embeddings.word_embeddings(mem_token_ids)\n",
    "        return memory\n",
    "    \n",
    "    def extend_word_embeddings(self):\n",
    "        vocab_size = self.base_model.embeddings.word_embeddings.weight.shape[0]\n",
    "        extended_vocab_size = vocab_size + self.num_mem_tokens\n",
    "        self.mem_token_ids = torch.arange(vocab_size, vocab_size + self.num_mem_tokens)\n",
    "        self.base_model.resize_token_embeddings(extended_vocab_size)\n",
    "    \n",
    "    def override_encoder_forward(self):\n",
    "        self.memory_storage = {'num_mem_tokens': self.num_mem_tokens}\n",
    "        memory_forward = lambda *args, **kwargs: encoder_memory_forward(*args, **kwargs, memory_storage=self.memory_storage)\n",
    "        self.base_model.encoder.forward = types.MethodType(memory_forward, self.base_model.encoder)\n",
    "\n",
    "\n",
    "    def __call__(self, input_ids, **kwargs):\n",
    "        memory = self.set_memory()\n",
    "        segmented = self.pad_and_segment(input_ids)\n",
    "        segmented = list(zip(*segmented))\n",
    "\n",
    "        if self.segment_ordering in {'regular', 'last_memory_only'}:\n",
    "            pass\n",
    "        elif self.segment_ordering == 'reversed':\n",
    "            segmented == segmented[::-1]\n",
    "        elif self.segment_ordering == 'bidirectional':\n",
    "            segmented == segmented + segmented[::-1][1:]\n",
    "        elif self.segment_ordering == 'repeat_first':\n",
    "            segmented == segmented + segmented[:1]\n",
    "        else:\n",
    "            raise ValueError(f'Unknown segment ordering: {segment_ordering}')\n",
    "\n",
    "        self.memory_storage = {'num_mem_tokens': self.num_mem_tokens}\n",
    "        outputs = []\n",
    "        for seg_num, segment_data in enumerate(segmented):\n",
    "            input_ids, attention_mask, token_type_ids = segment_data\n",
    "            if memory.ndim == 2:\n",
    "                memory = memory.repeat(input_ids.shape[0], 1, 1)\n",
    "            if (self.bptt_depth > -1) and (len(segmented) - seg_num > self.bptt_depth): \n",
    "                memory = memory.detach()\n",
    "\n",
    "            seg_kwargs = dict(**kwargs)\n",
    "            if self.drop_empty_segments:\n",
    "                non_empty_mask = [not torch.equal(input_ids[i], self.empty) for i in range(len(input_ids))]\n",
    "                if sum(non_empty_mask) == 0:\n",
    "                    continue\n",
    "                input_ids = input_ids[non_empty_mask]\n",
    "                attention_mask = attention_mask[non_empty_mask]\n",
    "                token_type_ids = token_type_ids[non_empty_mask]\n",
    "                seg_kwargs['labels'] = seg_kwargs['labels'][non_empty_mask]\n",
    "\n",
    "                inputs_embeds = self.base_model.embeddings.word_embeddings(input_ids)\n",
    "                inputs_embeds[:, 1:1+self.num_mem_tokens] = memory[non_empty_mask]\n",
    "            else:\n",
    "                inputs_embeds = self.base_model.embeddings.word_embeddings(input_ids)\n",
    "                inputs_embeds[:, 1:1+self.num_mem_tokens] = memory\n",
    "\n",
    "            seg_kwargs['inputs_embeds'] = inputs_embeds\n",
    "            seg_kwargs['attention_mask'] = attention_mask\n",
    "            seg_kwargs['token_type_ids'] = token_type_ids\n",
    "            \n",
    "            out = self.model.forward(**seg_kwargs, output_hidden_states=True)\n",
    "            outputs.append(out)\n",
    "\n",
    "            if self.drop_empty_segments:\n",
    "                memory[non_empty_mask] = out.hidden_states[-1][:, :self.num_mem_tokens]\n",
    "            else:\n",
    "                memory = out.hidden_states[-1][:, :self.num_mem_tokens]\n",
    "\n",
    "        for i, o in enumerate(outputs):\n",
    "            out[f'loss_{i}'] = o['loss'].mean()\n",
    "\n",
    "        if self.sum_loss:\n",
    "            out['loss'] = torch.stack([o['loss'] for o in outputs]).sum(dim=-1)\n",
    "            \n",
    "        return out\n",
    "\n",
    "    def pad_and_segment(self, input_ids):\n",
    "        \n",
    "        sequence_len = input_ids.shape[1]\n",
    "        input_seg_size = self.input_size - self.num_mem_tokens - 3 \n",
    "        if self.input_seg_size is not None and self.input_seg_size < input_seg_size:\n",
    "            input_seg_size = self.input_seg_size\n",
    "            \n",
    "        n_segments = math.ceil(sequence_len / input_seg_size)\n",
    "\n",
    "        augmented_inputs = []\n",
    "        for input in input_ids:\n",
    "            input = input[input != self.pad_token_id][1:-1]\n",
    "\n",
    "            seg_sep_inds = [0] + list(range(len(input), 0, -input_seg_size))[::-1] # chunk so that first segment has various size\n",
    "            input_segments = [input[s:e] for s, e in zip(seg_sep_inds, seg_sep_inds[1:])]\n",
    "\n",
    "            def pad_add_special_tokens(tensor, seg_size):\n",
    "                tensor = torch.cat([self.cls_token.to(device=self.device),\n",
    "                                    self.mem_token_ids.to(device=self.device),\n",
    "                                    self.sep_token.to(device=self.device),\n",
    "                                    tensor.to(device=self.device),\n",
    "                                    self.sep_token.to(device=self.device)])\n",
    "                pad_size = seg_size - tensor.shape[0]\n",
    "                if pad_size > 0:\n",
    "                    tensor = F.pad(tensor, (0, pad_size))\n",
    "                return tensor\n",
    "\n",
    "            input_segments = [pad_add_special_tokens(t, self.input_size) for t in input_segments]\n",
    "            empty = torch.Tensor([]).int()\n",
    "            self.empty = pad_add_special_tokens(empty, self.input_size)\n",
    "            empty_segments = [self.empty for i in range(n_segments - len(input_segments))]\n",
    "            input_segments = empty_segments + input_segments\n",
    "\n",
    "            augmented_input = torch.cat(input_segments)\n",
    "            augmented_inputs.append(augmented_input)\n",
    "            \n",
    "        augmented_inputs = torch.stack(augmented_inputs)\n",
    "        attention_mask = torch.ones_like(augmented_inputs)\n",
    "        attention_mask[augmented_inputs == self.pad_token_id] = 0\n",
    "\n",
    "        token_type_ids = torch.zeros_like(attention_mask)\n",
    "\n",
    "        input_segments = torch.chunk(augmented_inputs, n_segments, dim=1)\n",
    "        attention_mask = torch.chunk(attention_mask, n_segments, dim=1)\n",
    "        token_type_ids = torch.chunk(token_type_ids, n_segments, dim=1)\n",
    "    \n",
    "        return input_segments, attention_mask, token_type_ids\n",
    "\n",
    "\n",
    "    def to(self, device):\n",
    "        self.model = self.model.to(device)\n",
    "        \n",
    "    \n",
    "    def cuda(self):\n",
    "        self.model.cuda()\n",
    "\n",
    "\n",
    "    def __getattr__(self, attribute):\n",
    "        return getattr(self.model, attribute)\n",
    "\n",
    "\n",
    "    def parameters(self, **kwargs):\n",
    "        return self.model.parameters(**kwargs)\n",
    "\n",
    "    def named_parameters(self, **kwargs):\n",
    "        return self.model.named_parameters(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/bert_uncased_L-4_H-256_A-4\"\n",
    "# model_name = 'google/electra-base-discriminator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephfs/home/bulatov/bulatov/hvdenv/lib/python3.8/site-packages/cryptography/hazmat/backends/openssl/x509.py:14: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_segments = 2\n",
    "num_mem_tokens = 10\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenizer.model_max_length  = (tokenizer.model_max_length - num_mem_tokens) * num_segments\n",
    "tokenizer.padding_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-4_H-256_A-4 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "rmt = RMTEncoderForSequenceClassification.from_pretrained(model_name, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmt.set_params(\n",
    "                drop_empty_segments=True,\n",
    "                sum_loss=False,\n",
    "                input_size=None, \n",
    "                input_seg_size=None, \n",
    "                backbone_cls=None,\n",
    "                inter_layer_memory=False,\n",
    "                segment_ordering='repeat_first',\n",
    "                num_mem_tokens=0, \n",
    "                bptt_depth=-1, \n",
    "                tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq_len = 512\n",
    "target_seq_len = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_plus_kwargs = {'max_length': input_seq_len,\n",
    "                              'truncation': True,\n",
    "                              'padding': 'longest',\n",
    "                              'pad_to_multiple_of': 64}\n",
    "generate_kwargs = {}\n",
    "labels_map = {'Contradiction': 0, 'Entailment': 1, 'Not mentioned': 2}\n",
    "num_labels = len(labels_map)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # cut too long strings because they may slow down tokenization\n",
    "    inputs = [b['input'][:input_seq_len * 10] for b in batch]\n",
    "    labels = [b['output'][:target_seq_len * 10] for b in batch]\n",
    "    features = tokenizer.batch_encode_plus(list(inputs), return_tensors='pt', **encode_plus_kwargs)\n",
    "    labels = np.array([labels_map[t] for t in labels])\n",
    "    features['labels'] = torch.from_numpy(labels)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephfs/home/bulatov/bulatov/hvdenv/lib/python3.8/site-packages/cryptography/hazmat/backends/openssl/x509.py:14: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  warnings.warn(\n",
      "Reusing dataset scrolls (/home/bulatov/.cache/huggingface/datasets/tau___scrolls/contract_nli/1.0.0/672021d5d8e1edff998a6ea7a5bff35fdfd0ae243e7cf6a8c88a57a04afb46ac)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f83c29879af40858d0fb313b8dd3453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "dataset = datasets.load_dataset('tau/scrolls', 'contract_nli')\n",
    "train_dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = RandomSampler(train_dataset,)\n",
    "kwargs = {'pin_memory': True, 'num_workers': 0}\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=3, sampler=train_sampler,\n",
    "                                collate_fn=collate_fn, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = iter(train_dataloader)\n",
    "sample = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = sample.copy()\n",
    "self = rmt\n",
    "# kwargs\n",
    "input_ids = kwargs.pop('input_ids')\n",
    "\n",
    "memory = self.set_memory()\n",
    "segmented = self.pad_and_segment(input_ids)\n",
    "\n",
    "outputs = []\n",
    "for seg_num, segment_data in enumerate(zip(*segmented)):\n",
    "    input_ids, attention_mask, token_type_ids = segment_data\n",
    "    if memory.ndim == 2:\n",
    "        memory = memory.repeat(input_ids.shape[0], 1, 1)\n",
    "    if (self.bptt_depth > -1) and (len(segmented) - seg_num > self.bptt_depth): \n",
    "        memory = memory.detach()\n",
    "\n",
    "    seg_kwargs = dict(**kwargs)\n",
    "    if self.drop_empty_segments:\n",
    "\n",
    "        non_empty_mask = [not torch.equal(input_ids[i], self.empty) for i in range(len(input_ids))]\n",
    "        if sum(non_empty_mask) == 0:\n",
    "            continue\n",
    "        input_ids = input_ids[non_empty_mask]\n",
    "        attention_mask = attention_mask[non_empty_mask]\n",
    "        token_type_ids = token_type_ids[non_empty_mask]\n",
    "        seg_kwargs['labels'] = seg_kwargs['labels'][non_empty_mask]\n",
    "\n",
    "        inputs_embeds = self.base_model.embeddings.word_embeddings(input_ids)\n",
    "        inputs_embeds[:, 1:1+self.num_mem_tokens] = memory[non_empty_mask]\n",
    "    else:\n",
    "        inputs_embeds = self.base_model.embeddings.word_embeddings(input_ids)\n",
    "        inputs_embeds[:, 1:1+self.num_mem_tokens] = memory\n",
    "\n",
    "    seg_kwargs['inputs_embeds'] = inputs_embeds\n",
    "    seg_kwargs['attention_mask'] = attention_mask\n",
    "    seg_kwargs['token_type_ids'] = token_type_ids\n",
    "    \n",
    "    out = self.model.forward(**seg_kwargs, output_hidden_states=True, return_dict=True, )\n",
    "    outputs.append(out)\n",
    "\n",
    "    if self.drop_empty_segments:\n",
    "        memory[non_empty_mask] = out.hidden_states[-1][:, :self.num_mem_tokens]\n",
    "    else:\n",
    "        memory = out.hidden_states[-1][:, :self.num_mem_tokens]\n",
    "\n",
    "if self.sum_loss:\n",
    "    out['loss'] = torch.stack([o['loss'] for o in outputs]).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 2])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.3037,  0.2728, -0.1070],\n",
       "         [-0.3630,  0.3620, -0.0418],\n",
       "         [-0.3037,  0.2728, -0.1070]], grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.1574, -0.0191,  0.0029],\n",
       "         [-0.1814,  0.0206, -0.0564],\n",
       "         [-0.2045,  0.0097, -0.1661]], grad_fn=<AddmmBackward>)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o.logits for o in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_logits = torch.stack([o.logits for o in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2502, 0.4453, 0.3046],\n",
       "         [0.2250, 0.4646, 0.3103],\n",
       "         [0.2502, 0.4453, 0.3046]],\n",
       "\n",
       "        [[0.3010, 0.3457, 0.3533],\n",
       "         [0.2979, 0.3646, 0.3375],\n",
       "         [0.3051, 0.3779, 0.3170]]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean logits\n",
    "averaged_logits = stacked_logits.mean(dim=0)\n",
    "probs = F.softmax(averaged_logits, dim=1)\n",
    "preds = probs.argmax(dim=1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# majority vote\n",
    "probs = F.softmax(stacked_logits, dim=2)\n",
    "preds = probs.argmax(dim=2).mode(dim=0).values\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most confident vote\n",
    "probs = F.softmax(stacked_logits, dim=2)\n",
    "most_confident_inds = probs.max(dim=2).values.argmax(dim=0)\n",
    "new_probs = torch.stack([probs[ind, i] for i, ind in enumerate(most_confident_inds)])\n",
    "preds = new_probs.argmax(dim=1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2502, 0.4453, 0.3046],\n",
       "         [0.2250, 0.4646, 0.3103],\n",
       "         [0.2502, 0.4453, 0.3046]],\n",
       "\n",
       "        [[0.3010, 0.3457, 0.3533],\n",
       "         [0.2979, 0.3646, 0.3375],\n",
       "         [0.3051, 0.3779, 0.3170]]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = F.softmax(stacked_logits, dim=2)\n",
    "most_sure_seg_inds = probs.max(dim=2).values.argmax(dim=0)\n",
    "# new_probs = torch.stack([probs[ind, i] for i, ind in enumerate(most_sure_seg_inds)])\n",
    "# preds = new_probs.argmax(dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2502, 0.4453, 0.3046],\n",
       "         [0.2250, 0.4646, 0.3103],\n",
       "         [0.2502, 0.4453, 0.3046]],\n",
       "\n",
       "        [[0.3010, 0.3457, 0.3533],\n",
       "         [0.2979, 0.3646, 0.3375],\n",
       "         [0.3051, 0.3779, 0.3170]]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_sure_seg_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2502, 0.4453, 0.3046],\n",
       "         [0.2250, 0.4646, 0.3103],\n",
       "         [0.2502, 0.4453, 0.3046]]], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = None\n",
    "if labels is not None:\n",
    "    if self.config.problem_type is None:\n",
    "        if self.num_labels == 1:\n",
    "            self.config.problem_type = \"regression\"\n",
    "        elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "            self.config.problem_type = \"single_label_classification\"\n",
    "        else:\n",
    "            self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "    if self.config.problem_type == \"regression\":\n",
    "        loss_fct = MSELoss()\n",
    "        if self.num_labels == 1:\n",
    "            loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "        else:\n",
    "            loss = loss_fct(logits, labels)\n",
    "    elif self.config.problem_type == \"single_label_classification\":\n",
    "        loss_fct = CrossEntropyLoss()\n",
    "        loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "    elif self.config.problem_type == \"multi_label_classification\":\n",
    "        loss_fct = BCEWithLogitsLoss()\n",
    "        loss = loss_fct(logits, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Override forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import types\n",
    "self = rmt\n",
    "\n",
    "memory_storage = {'num_mem_tokens': 10}\n",
    "self.base_model.encoder.forward = types.MethodType(lambda *args, **kwargs: _forward(*args, **kwargs, memory_storage=memory_storage), self.base_model.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  4909,  2283,  ...,  1017,  1012,   102],\n",
       "         [  101,  2070, 14422,  ...,  2025,  3024,   102]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1]]),\n",
       " 'labels': tensor([1, 2])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pin_memory': True, 'num_workers': 0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = sample.copy()\n",
    "# kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states shape: (2, torch.Size([512, 256]))\n",
      " memory storage:dict_keys(['num_mem_tokens'])\n",
      "hidden states shape: (2, torch.Size([512, 256]))\n",
      " memory storage:dict_keys(['num_mem_tokens', 0])\n",
      "hidden states shape: (2, torch.Size([512, 256]))\n",
      " memory storage:dict_keys(['num_mem_tokens', 0, 1])\n",
      "hidden states shape: (2, torch.Size([512, 256]))\n",
      " memory storage:dict_keys(['num_mem_tokens', 0, 1, 2])\n",
      "hidden states shape: (2, torch.Size([512, 256]))\n",
      " memory storage:dict_keys(['num_mem_tokens', 0, 1, 2, 3])\n",
      "replacing ms[i] tensor([ 0.4910, -0.3252,  0.6379,  0.4366,  0.9436,  0.3721, -0.4503,  0.2484,\n",
      "        -5.6303,  0.0416], grad_fn=<SliceBackward>)... to tensor([ 0.5875, -0.4431,  0.4703,  0.1823,  0.2762, -0.0980, -0.7847, -0.3769,\n",
      "        -4.0026, -0.0786], grad_fn=<SliceBackward>)\n",
      "hidden states shape: (2, torch.Size([512, 256]))\n",
      " memory storage:dict_keys(['num_mem_tokens', 0, 1, 2, 3])\n",
      "replacing ms[i] tensor([ 0.4131, -0.2734,  0.5131,  0.4519,  0.8615, -0.4164, -0.4695,  0.1083,\n",
      "        -7.1332,  0.2477], grad_fn=<SliceBackward>)... to tensor([ 0.4684, -0.1915,  0.3924,  0.3985,  0.8635, -0.7359, -0.1106,  0.1712,\n",
      "        -8.9686,  0.3769], grad_fn=<SliceBackward>)\n",
      "hidden states shape: (2, torch.Size([512, 256]))\n",
      " memory storage:dict_keys(['num_mem_tokens', 0, 1, 2, 3])\n",
      "replacing ms[i] tensor([ 0.2953, -0.1400,  0.4266,  0.0419,  0.8344, -0.2630, -0.7411, -0.0187,\n",
      "        -3.9098, -0.2587], grad_fn=<SliceBackward>)... to tensor([-0.7230,  0.0042,  0.3788, -0.5297,  1.0977,  0.0802, -1.1541, -0.1407,\n",
      "        -2.3975, -0.3298], grad_fn=<SliceBackward>)\n",
      "hidden states shape: (2, torch.Size([512, 256]))\n",
      " memory storage:dict_keys(['num_mem_tokens', 0, 1, 2, 3])\n",
      "replacing ms[i] tensor([ 0.4336, -0.2249, -0.2261, -0.3031,  1.1261, -0.1303, -0.8440,  0.6503,\n",
      "        -3.5424,  0.2903], grad_fn=<SliceBackward>)... to tensor([ 0.4518, -0.6125,  0.3085, -0.5292,  1.3546, -0.4337, -0.9142,  0.5836,\n",
      "        -2.3023, -0.2561], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "kwargs = sample.copy()\n",
    "# kwargs\n",
    "input_ids = kwargs.pop('input_ids')\n",
    "\n",
    "memory = self.set_memory()\n",
    "segmented = self.pad_and_segment(input_ids)\n",
    "\n",
    "outputs = []\n",
    "for seg_num, segment_data in enumerate(zip(*segmented)):\n",
    "    input_ids, attention_mask, token_type_ids = segment_data\n",
    "    if memory.ndim == 2:\n",
    "        memory = memory.repeat(input_ids.shape[0], 1, 1)\n",
    "    if (self.bptt_depth > -1) and (len(segmented) - seg_num > self.bptt_depth): \n",
    "        memory = memory.detach()\n",
    "\n",
    "    seg_kwargs = dict(**kwargs)\n",
    "    if self.drop_empty_segments:\n",
    "\n",
    "        non_empty_mask = [not torch.equal(input_ids[i], self.empty) for i in range(len(input_ids))]\n",
    "        if sum(non_empty_mask) == 0:\n",
    "            continue\n",
    "        input_ids = input_ids[non_empty_mask]\n",
    "        attention_mask = attention_mask[non_empty_mask]\n",
    "        token_type_ids = token_type_ids[non_empty_mask]\n",
    "        seg_kwargs['labels'] = seg_kwargs['labels'][non_empty_mask]\n",
    "\n",
    "        inputs_embeds = self.base_model.embeddings.word_embeddings(input_ids)\n",
    "        inputs_embeds[:, 1:1+self.num_mem_tokens] = memory[non_empty_mask]\n",
    "    else:\n",
    "        inputs_embeds = self.base_model.embeddings.word_embeddings(input_ids)\n",
    "        inputs_embeds[:, 1:1+self.num_mem_tokens] = memory\n",
    "\n",
    "    seg_kwargs['inputs_embeds'] = inputs_embeds\n",
    "    seg_kwargs['attention_mask'] = attention_mask\n",
    "    seg_kwargs['token_type_ids'] = token_type_ids\n",
    "    \n",
    "    out = self.model.forward(**seg_kwargs, output_hidden_states=True)\n",
    "    outputs.append(out)\n",
    "\n",
    "    if self.drop_empty_segments:\n",
    "        memory[non_empty_mask] = out.hidden_states[-1][:, :self.num_mem_tokens]\n",
    "    else:\n",
    "        memory = out.hidden_states[-1][:, :self.num_mem_tokens]\n",
    "\n",
    "if self.sum_loss:\n",
    "    out['loss'] = torch.stack([o['loss'] for o in outputs]).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = self.model.forward(**seg_kwargs, output_hidden_states=True)\n",
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out['hidden_states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'logits', 'hidden_states'])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = forward(self.model, **seg_kwargs, output_hidden_states=True, use_cache=True)\n",
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(per_device_train_batch_size=3, per_device_eval_batch_size=1, output_dir=\"test_trainer\", evaluation_strategy=\"epoch\", no_cuda=True, max_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented_inputs = np.load('augmented_inputs.npy', allow_pickle=True)\n",
    "# attn_masks = np.load('attention_masks.npy', allow_pickle=True)\n",
    "# tokenizer.decode(augmented_inputs[0][512:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=rmt,\n",
    "#     # model=classic_bert,\n",
    "#     args=training_args,\n",
    "#     train_dataset=small_train_dataset,\n",
    "#     eval_dataset=small_eval_dataset,\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = SequentialSampler(small_train_dataset)\n",
    "dl = DataLoader(small_train_dataset, sampler=sampler, \n",
    "                h_size=4)\n",
    "gen = dl.__iter__()\n",
    "s = next(gen)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15ebdd31b1273fe4d2b1fe1822219a570cf61693f7cab545dbe286c10cf9691f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
