{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/booydar/Desktop/MIPT/memory_experiments/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from transformers import PreTrainedModel, AutoModelForSequenceClassification\n",
    "\n",
    "import math\n",
    "\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from transformers import BertForSequenceClassification\n",
    "import transformers\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/bert_uncased_L-4_H-256_A-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_segments = 2\n",
    "num_mem_tokens = 10\n",
    "\n",
    "tokenizer.model_max_length  = (tokenizer.model_max_length - num_mem_tokens) * num_segments\n",
    "tokenizer.padding_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(examples[\"input\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "# small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen = iter(small_eval_dataset)\n",
    "# src = next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "# from modeling_rmt import RMTEncoderForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class RMTEncoderForSequenceClassification():\n",
    "    def __init__(self, config=None, base_model=None, **kwargs):\n",
    "        if config is not None:\n",
    "            self.model = AutoModelForSequenceClassification(config, **kwargs)\n",
    "        \n",
    "        if base_model is not None:\n",
    "            self.model = base_model\n",
    "\n",
    "\n",
    "    def from_pretrained(from_pretrained, **kwargs):\n",
    "        base_model = AutoModelForSequenceClassification.from_pretrained(from_pretrained, **kwargs)\n",
    "        rmt = RMTEncoderForSequenceClassification(base_model=base_model)\n",
    "        return rmt\n",
    "        \n",
    "\n",
    "    def set_params(self, \n",
    "                drop_empty_segments=True,\n",
    "                sum_loss=False,\n",
    "                input_size=None, \n",
    "                input_seg_size=None, \n",
    "                backbone_cls=None,\n",
    "                num_mem_tokens=0, \n",
    "                bptt_depth=-1, \n",
    "                pad_token_id=0, \n",
    "                eos_token_id=1,\n",
    "                cls_token_id=101, \n",
    "                sep_token_id=102):\n",
    "        if input_size is not None:\n",
    "            self.input_size = input_size\n",
    "        else:\n",
    "            self.input_size =  self.base_model.embeddings.position_embeddings.weight.shape[0]\n",
    "        self.input_seg_size = input_seg_size\n",
    "\n",
    "        self.bptt_depth = bptt_depth\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.cls_token = torch.tensor([cls_token_id])\n",
    "        self.sep_token = torch.tensor([sep_token_id])\n",
    "        self.num_mem_tokens = num_mem_tokens\n",
    "        self.drop_empty_segments = drop_empty_segments\n",
    "        self.sum_loss = sum_loss\n",
    "        self.extend_word_embeddings()\n",
    "\n",
    "\n",
    "    def set_memory(self, memory=None):\n",
    "        if memory is None:\n",
    "            mem_token_ids = self.mem_token_ids.to(device=self.device)\n",
    "            memory = self.base_model.embeddings.word_embeddings(mem_token_ids)\n",
    "        return memory\n",
    "    \n",
    "    def extend_word_embeddings(self):\n",
    "        vocab_size = self.base_model.embeddings.word_embeddings.weight.shape[0]\n",
    "        extended_vocab_size = vocab_size + self.num_mem_tokens\n",
    "        self.mem_token_ids = torch.arange(vocab_size, vocab_size + self.num_mem_tokens)\n",
    "        self.base_model.resize_token_embeddings(extended_vocab_size)\n",
    "\n",
    "\n",
    "    def __call__(self, input_ids, **kwargs):\n",
    "        memory = self.set_memory()\n",
    "        segmented = self.pad_and_segment(input_ids)\n",
    "\n",
    "        outputs = []\n",
    "        for seg_num, segment_data in enumerate(zip(*segmented)):\n",
    "            input_ids, attention_mask, token_type_ids = segment_data\n",
    "            if memory.ndim == 2:\n",
    "                memory = memory.repeat(input_ids.shape[0], 1, 1)\n",
    "            if (self.bptt_depth > -1) and (len(segmented) - seg_num > self.bptt_depth): \n",
    "                memory = memory.detach()\n",
    "\n",
    "            seg_kwargs = dict(**kwargs)\n",
    "            if self.drop_empty_segments:\n",
    "\n",
    "                non_empty_mask = [not torch.equal(input_ids[i], self.empty) for i in range(len(input_ids))]\n",
    "                if sum(non_empty_mask) == 0:\n",
    "                    continue\n",
    "                input_ids = input_ids[non_empty_mask]\n",
    "                attention_mask = attention_mask[non_empty_mask]\n",
    "                token_type_ids = token_type_ids[non_empty_mask]\n",
    "                seg_kwargs['labels'] = seg_kwargs['labels'][non_empty_mask]\n",
    "\n",
    "                inputs_embeds = self.base_model.embeddings.word_embeddings(input_ids)\n",
    "                inputs_embeds[:, 1:1+self.num_mem_tokens] = memory[non_empty_mask]\n",
    "            else:\n",
    "                inputs_embeds = self.base_model.embeddings.word_embeddings(input_ids)\n",
    "                inputs_embeds[:, 1:1+self.num_mem_tokens] = memory\n",
    "\n",
    "            seg_kwargs['inputs_embeds'] = inputs_embeds\n",
    "            seg_kwargs['attention_mask'] = attention_mask\n",
    "            seg_kwargs['token_type_ids'] = token_type_ids\n",
    "            \n",
    "            out = self.model.forward(**seg_kwargs, output_hidden_states=True)\n",
    "            outputs.append(out)\n",
    "\n",
    "            if self.drop_empty_segments:\n",
    "                memory[non_empty_mask] = out.hidden_states[-1][:, :self.num_mem_tokens]\n",
    "            else:\n",
    "                memory = out.hidden_states[-1][:, :self.num_mem_tokens]\n",
    "\n",
    "        if self.sum_loss:\n",
    "            out['loss'] = torch.stack([o['loss'] for o in outputs]).sum(dim=-1)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def pad_and_segment(self, input_ids):\n",
    "        \n",
    "        sequence_len = input_ids.shape[1]\n",
    "        input_seg_size = self.input_size - self.num_mem_tokens - 3 \n",
    "        if self.input_seg_size is not None and self.input_seg_size < input_seg_size:\n",
    "            input_seg_size = self.input_seg_size\n",
    "            \n",
    "        n_segments = math.ceil(sequence_len / input_seg_size)\n",
    "\n",
    "        augmented_inputs = []\n",
    "        for input in input_ids:\n",
    "            input = input[input != self.pad_token_id][1:-1]\n",
    "\n",
    "            seg_sep_inds = [0] + list(range(len(input), 0, -input_seg_size))[::-1] # chunk so that first segment has various size\n",
    "            input_segments = [input[s:e] for s, e in zip(seg_sep_inds, seg_sep_inds[1:])]\n",
    "\n",
    "            def pad_add_special_tokens(tensor, seg_size):\n",
    "                tensor = torch.cat([self.cls_token.to(device=self.device),\n",
    "                                    self.mem_token_ids.to(device=self.device),\n",
    "                                    self.sep_token.to(device=self.device),\n",
    "                                    tensor.to(device=self.device),\n",
    "                                    self.sep_token.to(device=self.device)])\n",
    "                pad_size = seg_size - tensor.shape[0]\n",
    "                if pad_size > 0:\n",
    "                    tensor = F.pad(tensor, (0, pad_size))\n",
    "                return tensor\n",
    "\n",
    "            input_segments = [pad_add_special_tokens(t, self.input_size) for t in input_segments]\n",
    "            empty = torch.Tensor([]).int()\n",
    "            self.empty = pad_add_special_tokens(empty, self.input_size)\n",
    "            empty_segments = [self.empty for i in range(n_segments - len(input_segments))]\n",
    "            input_segments = empty_segments + input_segments\n",
    "\n",
    "            augmented_input = torch.cat(input_segments)\n",
    "            augmented_inputs.append(augmented_input)\n",
    "            \n",
    "        augmented_inputs = torch.stack(augmented_inputs)\n",
    "        attention_mask = torch.ones_like(augmented_inputs)\n",
    "        attention_mask[augmented_inputs == self.pad_token_id] = 0\n",
    "\n",
    "        token_type_ids = torch.zeros_like(attention_mask)\n",
    "\n",
    "        input_segments = torch.chunk(augmented_inputs, n_segments, dim=1)\n",
    "        attention_mask = torch.chunk(attention_mask, n_segments, dim=1)\n",
    "        token_type_ids = torch.chunk(token_type_ids, n_segments, dim=1)\n",
    "    \n",
    "        return input_segments, attention_mask, token_type_ids\n",
    "\n",
    "\n",
    "    def to(self, device):\n",
    "        self.model = self.model.to(device)\n",
    "        \n",
    "    \n",
    "    def cuda(self):\n",
    "        self.model.cuda()\n",
    "\n",
    "\n",
    "    def __getattr__(self, attribute):\n",
    "        return getattr(self.model, attribute)\n",
    "\n",
    "\n",
    "    def parameters(self, **kwargs):\n",
    "        return self.model.parameters(**kwargs)\n",
    "\n",
    "    def named_parameters(self, **kwargs):\n",
    "        return self.model.named_parameters(**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-4_H-256_A-4 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# pretrained_model = AutoModelForSequenceClassification.from_pretrained(\"google/electra-base-discriminator\", num_labels=5, output_hidden_states=True)\n",
    "# rmt = RMTEncoderForSequenceClassification.from_pretrained('google/electra-base-discriminator', num_labels=3)\n",
    "rmt = RMTEncoderForSequenceClassification.from_pretrained('google/bert_uncased_L-4_H-256_A-4', num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmt.set_params(\n",
    "                drop_empty_segments=True,\n",
    "                sum_loss=False,\n",
    "                input_size=None, \n",
    "                input_seg_size=None, \n",
    "                backbone_cls=None,\n",
    "                num_mem_tokens=0, \n",
    "                bptt_depth=-1, \n",
    "                pad_token_id=0, \n",
    "                eos_token_id=1,\n",
    "                cls_token_id=101, \n",
    "                sep_token_id=102)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq_len = 512\n",
    "target_seq_len = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_plus_kwargs = {'max_length': input_seq_len,\n",
    "                              'truncation': True,\n",
    "                              'padding': 'longest',\n",
    "                              'pad_to_multiple_of': 64}\n",
    "generate_kwargs = {}\n",
    "labels_map = {'Contradiction': 0, 'Entailment': 1, 'Not mentioned': 2}\n",
    "num_labels = len(labels_map)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # cut too long strings because they may slow down tokenization\n",
    "    inputs = [b['input'][:input_seq_len * 10] for b in batch]\n",
    "    labels = [b['output'][:target_seq_len * 10] for b in batch]\n",
    "    features = tokenizer.batch_encode_plus(list(inputs), return_tensors='pt', **encode_plus_kwargs)\n",
    "    labels = np.array([labels_map[t] for t in labels])\n",
    "    features['labels'] = torch.from_numpy(labels)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset scrolls (/home/booydar/.cache/huggingface/datasets/tau___scrolls/contract_nli/1.0.0/672021d5d8e1edff998a6ea7a5bff35fdfd0ae243e7cf6a8c88a57a04afb46ac)\n",
      "100%|██████████| 3/3 [00:00<00:00, 67.71it/s]\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "dataset = datasets.load_dataset('tau/scrolls', 'contract_nli')\n",
    "train_dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle train data each epoch (one loop over train_dataset)\n",
    "train_sampler = RandomSampler(train_dataset,)\n",
    "# per_worker_batch_size = args.batch_size * args.gradient_accumulation_steps\n",
    "# global_batch_size = per_worker_batch_size * hvd.size()\n",
    "kwargs = {'pin_memory': True, 'num_workers': 0}\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, sampler=train_sampler,\n",
    "                                collate_fn=collate_fn, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "gen = iter(train_dataloader)\n",
    "sample = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 18777,  2592,  ...,  2515,  2025,   102],\n",
       "        [  101,  4909,  2283,  ..., 20141,  1025,   102]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([1, 2])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmt.model.config.use_cache, rmt.model.config.is_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = rmt(**sample)#, use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 18777,  2592,  ...,  2515,  2025,   102],\n",
       "        [  101,  4909,  2283,  ..., 20141,  1025,   102]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs = sample.copy()\n",
    "kwargs.pop('input_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "\n",
    "# def forward(\n",
    "#     self_,\n",
    "#     input_ids: Optional[torch.LongTensor] = None,\n",
    "#     attention_mask: Optional[torch.FloatTensor] = None,\n",
    "#     token_type_ids: Optional[torch.LongTensor] = None,\n",
    "#     position_ids: Optional[torch.LongTensor] = None,\n",
    "#     head_mask: Optional[torch.FloatTensor] = None,\n",
    "#     inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "#     labels: Optional[torch.LongTensor] = None,\n",
    "#     output_attentions: Optional[bool] = None,\n",
    "#     output_hidden_states: Optional[bool] = None,\n",
    "#     return_dict: Optional[bool] = None,\n",
    "# ) -> Union[Tuple[torch.Tensor], SequenceClassifierOutput]:\n",
    "#     r\"\"\"\n",
    "#     labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "#         Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "#         config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "#         `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "#     \"\"\"\n",
    "#     return_dict = return_dict if return_dict is not None else self_.config.use_return_dict\n",
    "\n",
    "#     outputs = self_.base_model(\n",
    "#         input_ids,\n",
    "#         attention_mask=attention_mask,\n",
    "#         token_type_ids=token_type_ids,\n",
    "#         position_ids=position_ids,\n",
    "#         head_mask=head_mask,\n",
    "#         inputs_embeds=inputs_embeds,\n",
    "#         output_attentions=output_attentions,\n",
    "#         output_hidden_states=output_hidden_states,\n",
    "#         return_dict=return_dict,\n",
    "#     )\n",
    "#     sequence_output = outputs[0]\n",
    "#     logits = self_.classifier(sequence_output)\n",
    "\n",
    "#     loss = None\n",
    "#     if labels is not None:\n",
    "#         if self_.config.problem_type is None:\n",
    "#             if self_.num_labels == 1:\n",
    "#                 self_.config.problem_type = \"regression\"\n",
    "#             elif self_.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "#                 self_.config.problem_type = \"single_label_classification\"\n",
    "#             else:\n",
    "#                 self_.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "#         if self_.config.problem_type == \"regression\":\n",
    "#             loss_fct = MSELoss()\n",
    "#             if self_.num_labels == 1:\n",
    "#                 loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "#             else:\n",
    "#                 loss = loss_fct(logits, labels)\n",
    "#         elif self_.config.problem_type == \"single_label_classification\":\n",
    "#             loss_fct = CrossEntropyLoss()\n",
    "#             loss = loss_fct(logits.view(-1, self_.num_labels), labels.view(-1))\n",
    "#         elif self_.config.problem_type == \"multi_label_classification\":\n",
    "#             loss_fct = BCEWithLogitsLoss()\n",
    "#             loss = loss_fct(logits, labels)\n",
    "\n",
    "#     if not return_dict:\n",
    "#         output = (logits,) + outputs[2:]\n",
    "#         return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "#     return SequenceClassifierOutput(\n",
    "#         loss=loss,\n",
    "#         logits=logits,\n",
    "#         hidden_states=outputs.hidden_states,\n",
    "#         attentions=outputs.attentions,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = rmt\n",
    "input_ids = sample['input_ids']\n",
    "\n",
    "memory = self.set_memory()\n",
    "segmented = self.pad_and_segment(input_ids)\n",
    "\n",
    "outputs = []\n",
    "for seg_num, segment_data in enumerate(zip(*segmented)):\n",
    "    input_ids, attention_mask, token_type_ids = segment_data\n",
    "    if memory.ndim == 2:\n",
    "        memory = memory.repeat(input_ids.shape[0], 1, 1)\n",
    "    if (self.bptt_depth > -1) and (len(segmented) - seg_num > self.bptt_depth): \n",
    "        memory = memory.detach()\n",
    "\n",
    "    seg_kwargs = dict(**kwargs)\n",
    "    if self.drop_empty_segments:\n",
    "\n",
    "        non_empty_mask = [not torch.equal(input_ids[i], self.empty) for i in range(len(input_ids))]\n",
    "        if sum(non_empty_mask) == 0:\n",
    "            continue\n",
    "        input_ids = input_ids[non_empty_mask]\n",
    "        attention_mask = attention_mask[non_empty_mask]\n",
    "        token_type_ids = token_type_ids[non_empty_mask]\n",
    "        seg_kwargs['labels'] = seg_kwargs['labels'][non_empty_mask]\n",
    "\n",
    "        inputs_embeds = self.base_model.embeddings.word_embeddings(input_ids)\n",
    "        inputs_embeds[:, 1:1+self.num_mem_tokens] = memory[non_empty_mask]\n",
    "    else:\n",
    "        inputs_embeds = self.base_model.embeddings.word_embeddings(input_ids)\n",
    "        inputs_embeds[:, 1:1+self.num_mem_tokens] = memory\n",
    "\n",
    "    seg_kwargs['inputs_embeds'] = inputs_embeds\n",
    "    seg_kwargs['attention_mask'] = attention_mask\n",
    "    seg_kwargs['token_type_ids'] = token_type_ids\n",
    "    \n",
    "    out = self.model.forward(**seg_kwargs, output_hidden_states=True)\n",
    "    outputs.append(out)\n",
    "\n",
    "    if self.drop_empty_segments:\n",
    "        memory[non_empty_mask] = out.hidden_states[-1][:, :self.num_mem_tokens]\n",
    "    else:\n",
    "        memory = out.hidden_states[-1][:, :self.num_mem_tokens]\n",
    "\n",
    "if self.sum_loss:\n",
    "    out['loss'] = torch.stack([o['loss'] for o in outputs]).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = self.model.forward(**seg_kwargs, output_hidden_states=True)\n",
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "\n",
    "def forward(\n",
    "    self,\n",
    "    input_ids: Optional[torch.Tensor] = None,\n",
    "    attention_mask: Optional[torch.Tensor] = None,\n",
    "    token_type_ids: Optional[torch.Tensor] = None,\n",
    "    position_ids: Optional[torch.Tensor] = None,\n",
    "    head_mask: Optional[torch.Tensor] = None,\n",
    "    inputs_embeds: Optional[torch.Tensor] = None,\n",
    "    labels: Optional[torch.Tensor] = None,\n",
    "    output_attentions: Optional[bool] = None,\n",
    "    output_hidden_states: Optional[bool] = None,\n",
    "    return_dict: Optional[bool] = None,\n",
    "    **base_model_forward_kwargs\n",
    ") -> Union[Tuple[torch.Tensor], SequenceClassifierOutput]:\n",
    "    r\"\"\"\n",
    "    labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "        Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "        config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "        `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "    \"\"\"\n",
    "    return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "    print('base_model_forward_kwargs', base_model_forward_kwargs)\n",
    "\n",
    "    outputs = self.base_model(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        token_type_ids=token_type_ids,\n",
    "        position_ids=position_ids,\n",
    "        head_mask=head_mask,\n",
    "        inputs_embeds=inputs_embeds,\n",
    "        output_attentions=output_attentions,\n",
    "        output_hidden_states=output_hidden_states,\n",
    "        return_dict=return_dict,\n",
    "        **base_model_forward_kwargs\n",
    "    )\n",
    "\n",
    "    pooled_output = outputs[1]\n",
    "\n",
    "    pooled_output = self.dropout(pooled_output)\n",
    "    logits = self.classifier(pooled_output)\n",
    "\n",
    "    loss = None\n",
    "    if labels is not None:\n",
    "        if self.config.problem_type is None:\n",
    "            if self.num_labels == 1:\n",
    "                self.config.problem_type = \"regression\"\n",
    "            elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                self.config.problem_type = \"single_label_classification\"\n",
    "            else:\n",
    "                self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "        if self.config.problem_type == \"regression\":\n",
    "            loss_fct = MSELoss()\n",
    "            if self.num_labels == 1:\n",
    "                loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "            else:\n",
    "                loss = loss_fct(logits, labels)\n",
    "        elif self.config.problem_type == \"single_label_classification\":\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        elif self.config.problem_type == \"multi_label_classification\":\n",
    "            loss_fct = BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "    if not return_dict:\n",
    "        output = (logits,) + outputs[2:]\n",
    "        return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "    return SequenceClassifierOutput(\n",
    "        loss=loss,\n",
    "        logits=logits,\n",
    "        hidden_states=outputs.hidden_states,\n",
    "        attentions=outputs.attentions,\n",
    "    ), outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.model.base_model.config.is_decoder = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model_forward_kwargs {'use_cache': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(odict_keys(['loss', 'logits', 'hidden_states']),\n",
       " odict_keys(['last_hidden_state', 'pooler_output', 'hidden_states', 'past_key_values']))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out, base_model_outputs = forward(self.model, **seg_kwargs, use_cache=True, output_hidden_states=True)\n",
    "out.keys(), base_model_outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOOF\n",
      "WoOoOoF!!\n"
     ]
    }
   ],
   "source": [
    "import types\n",
    "\n",
    "class Dog:\n",
    "    def bark(self):\n",
    "        print (\"WOOF\")\n",
    "\n",
    "boby = Dog()\n",
    "boby.bark() # WOOF\n",
    "\n",
    "def _bark(self):\n",
    "    print (\"WoOoOoF!!\")\n",
    "\n",
    "boby.bark = types.MethodType(_bark, boby)\n",
    "\n",
    "boby.bark() # WoOoOoF!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0021,  0.1765,  0.0537,  ..., -0.0698,  0.0719, -0.0218],\n",
      "        [ 0.0611, -0.0031,  0.1003,  ...,  0.0282,  0.0014, -0.1518],\n",
      "        [ 0.0477, -0.1658,  0.0351,  ..., -0.0924,  0.0100,  0.1146],\n",
      "        ...,\n",
      "        [ 0.0381,  0.0771, -0.0435,  ..., -0.0303,  0.0879, -0.0117],\n",
      "        [-0.1050,  0.1055,  0.0615,  ...,  0.1040, -0.0787, -0.0220],\n",
      "        [-0.0092,  0.0971, -0.0594,  ...,  0.0132,  0.0357, -0.0016]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1300,  0.2067,  0.0079, -0.1088, -0.2239, -0.0473,  0.1249,  0.0819,\n",
      "        -0.0583,  0.1661,  0.0429,  0.1532, -0.0517,  0.1935, -0.0403, -0.0074,\n",
      "        -0.0473,  0.2197, -0.1637,  0.1842, -0.0364, -0.0465,  0.0167, -0.0109,\n",
      "         0.0175, -0.1185,  0.2708, -0.1017, -0.0512, -0.0443,  0.0510,  0.1929,\n",
      "        -0.0983, -0.1915, -0.0105,  0.1452, -0.2056,  0.0810, -0.0385,  0.0729,\n",
      "        -0.3731, -0.0409,  0.0393,  0.1148,  0.1744,  0.2859,  0.0982, -0.0658,\n",
      "         0.1262, -0.0335, -0.0228, -0.0896, -0.0756, -0.0015,  0.0342, -0.1722,\n",
      "        -0.2237,  0.3384,  0.1200, -0.1702,  0.2137, -0.0979,  0.0621, -0.1311,\n",
      "         0.0723,  0.2735,  0.0038,  0.3370, -0.2897, -0.2767,  0.1427, -0.1486,\n",
      "        -0.3317, -0.0521,  0.0520, -0.2016, -0.2468,  0.4527,  0.1152,  0.1407,\n",
      "        -0.0155, -0.0546,  0.0968, -0.0079,  0.2687, -0.2539, -0.2840, -0.2048,\n",
      "        -0.2682,  0.0821, -0.0406,  0.1010, -0.3456,  0.3418, -0.2525,  0.0386,\n",
      "        -0.2355, -0.3891,  0.3126,  0.0140, -0.1613, -0.0121,  0.2219, -0.1934,\n",
      "         0.2846, -0.0717, -0.2818,  0.1204,  0.0637,  0.0362,  0.1841, -0.0632,\n",
      "         0.1381, -0.0493, -0.2365, -0.2322,  0.2670,  0.2639, -0.3733,  0.4653,\n",
      "        -0.2180,  0.1917,  0.3475, -0.2296,  0.1834,  0.2712,  0.0575,  0.0632,\n",
      "         0.0587,  0.0885, -0.2080,  0.0640, -0.0446,  0.0484,  0.1465, -0.0018,\n",
      "         0.0215,  0.0044,  0.0363,  0.2169, -0.0366, -0.0984,  0.0169, -0.0886,\n",
      "         0.1144, -0.1014,  0.0036, -0.0702, -0.1942, -0.1489, -0.0126, -0.1206,\n",
      "        -0.3554,  0.0716, -0.1158, -0.1562, -0.0856, -0.2295, -0.2438,  0.2623,\n",
      "         0.0700,  0.2275, -0.0456, -0.1667, -0.0532, -0.1401,  0.2595, -0.1988,\n",
      "         0.0327,  0.1150,  0.1367, -0.0020,  0.0217, -0.0666,  0.1268, -0.0192,\n",
      "         0.2661, -0.0023, -0.0385, -0.0443,  0.1903, -0.2243, -0.0042,  0.0771,\n",
      "         0.2863, -0.0747, -0.0524,  0.0911,  0.0721,  0.1101, -0.1203,  0.0330,\n",
      "        -0.0408, -0.0753, -0.2004, -0.0511,  0.1083,  0.0514, -0.0194, -0.0361,\n",
      "        -0.0548,  0.0261, -0.1740,  0.0957,  0.1812, -0.1930,  0.0280, -0.0068,\n",
      "         0.1553,  0.0794,  0.0389,  0.1657,  0.0341, -0.0168,  0.0145,  0.0990,\n",
      "        -0.0066, -0.0351, -0.0140,  0.0179, -0.0015, -0.0604,  0.0624,  0.1920,\n",
      "         0.0586, -0.1100, -0.1602, -0.1137,  0.1995,  0.0132,  0.0757, -0.1920,\n",
      "         0.1066, -0.0378,  0.0416,  0.0014, -0.0376, -0.0395,  0.0089,  0.1270,\n",
      "        -0.0211, -0.1396, -0.0147,  0.1142, -0.1348, -0.0113, -0.0058, -0.1442,\n",
      "         0.1146, -0.0536,  0.1520, -0.0666,  0.1682, -0.0903,  0.1386, -0.0274],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0883,  0.0805,  0.0302,  ...,  0.0100,  0.0931, -0.0059],\n",
      "        [-0.0083, -0.0366,  0.0239,  ...,  0.0362,  0.0351,  0.0874],\n",
      "        [-0.0390, -0.0359,  0.0056,  ..., -0.0251, -0.0195,  0.0159],\n",
      "        ...,\n",
      "        [ 0.0443,  0.0079,  0.0086,  ..., -0.0602, -0.0358,  0.0202],\n",
      "        [-0.0975, -0.1028, -0.1039,  ..., -0.0965,  0.0605,  0.0577],\n",
      "        [ 0.0244,  0.0300,  0.0654,  ...,  0.0198,  0.0196,  0.0230]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-5.9965e-02,  3.5599e-03, -1.7316e-02,  3.2085e-02,  9.6485e-04,\n",
      "        -1.6380e-02, -9.3742e-03,  3.2191e-02,  5.5783e-03, -7.8743e-03,\n",
      "         3.4262e-02, -5.0174e-03,  1.6515e-02,  2.8688e-02,  1.8480e-03,\n",
      "        -6.4201e-03, -1.4238e-02, -2.3853e-02,  3.7221e-02,  8.4729e-03,\n",
      "         2.3091e-02,  9.2872e-03,  2.9630e-02, -4.7666e-02,  1.4526e-02,\n",
      "         1.1867e-02,  1.8506e-03, -4.0195e-02, -3.7850e-02, -9.1353e-03,\n",
      "         1.1657e-03, -1.7236e-03,  5.0206e-03,  5.2007e-02, -2.3201e-02,\n",
      "         1.0159e-02, -1.9979e-02, -5.7453e-03, -1.1383e-02, -2.6764e-02,\n",
      "         2.5868e-02,  3.8741e-02,  4.2453e-03, -4.0547e-02, -1.0887e-02,\n",
      "        -1.7269e-02,  2.0717e-02,  3.7990e-02, -3.0040e-02, -1.5713e-02,\n",
      "        -3.1292e-03,  1.4578e-02,  4.5177e-03, -4.1941e-02,  1.1028e-02,\n",
      "         3.5914e-02,  2.7577e-02,  1.0155e-02, -2.3186e-02, -4.2967e-02,\n",
      "         3.2919e-02, -2.0884e-02, -3.9316e-03, -2.5100e-02,  7.2645e-02,\n",
      "        -4.9568e-02, -4.7460e-02, -8.6789e-02,  3.0504e-02,  2.2309e-02,\n",
      "        -2.0284e-02,  7.5913e-02,  3.2793e-02, -2.5987e-02, -5.9021e-03,\n",
      "         2.9151e-02,  3.8380e-02,  4.8089e-04, -6.2774e-02,  4.0100e-02,\n",
      "        -7.8718e-04, -2.9998e-02,  1.8896e-02,  3.3801e-05,  4.2411e-02,\n",
      "        -8.9322e-03, -4.5987e-02,  4.9820e-02, -1.1573e-02, -3.2690e-02,\n",
      "        -4.1575e-03, -7.2662e-02,  3.9384e-03, -1.6834e-02, -9.1851e-02,\n",
      "        -8.2726e-02, -1.7206e-02,  6.7307e-02, -2.5556e-02, -3.8938e-02,\n",
      "        -2.0585e-02,  1.5095e-02,  6.1516e-02, -8.3082e-02, -3.5036e-02,\n",
      "        -2.8960e-02,  1.3529e-02, -2.2241e-02, -5.4286e-02, -6.3957e-02,\n",
      "         2.0651e-02, -3.7592e-02,  4.3166e-02, -5.2265e-02, -1.2796e-02,\n",
      "         3.1308e-02,  2.4920e-03,  1.7986e-02, -2.5595e-04, -3.8957e-02,\n",
      "        -2.3587e-02,  6.8395e-03, -6.7629e-02, -3.2883e-02, -2.2056e-02,\n",
      "         3.0689e-02,  3.8214e-03,  7.3822e-04,  3.9774e-02, -4.8612e-02,\n",
      "        -3.6707e-02, -1.2634e-02, -1.5539e-02,  2.9505e-03, -1.2618e-02,\n",
      "        -5.2626e-02,  3.9946e-02,  5.1961e-02, -1.3082e-02,  3.4655e-02,\n",
      "        -4.0291e-03, -1.0251e-01, -2.9122e-02,  2.2795e-02,  1.6672e-02,\n",
      "        -6.9541e-02,  3.0072e-02, -4.0135e-02, -3.0763e-02, -3.7628e-02,\n",
      "        -2.3640e-02,  5.7039e-02, -5.4292e-02, -1.3380e-02, -7.2813e-02,\n",
      "        -3.3889e-02, -5.1214e-02, -1.1269e-02, -3.1327e-02,  8.4543e-02,\n",
      "        -1.2978e-02,  3.7755e-03,  7.8819e-03,  3.4127e-02,  4.5169e-02,\n",
      "        -6.7287e-03,  3.8048e-02, -6.6448e-02, -5.1509e-02,  4.3804e-02,\n",
      "        -4.0242e-02,  4.0118e-02, -2.7343e-02,  1.0446e-02,  1.6076e-02,\n",
      "         2.8175e-02,  5.2006e-05, -6.8938e-02,  9.7180e-02, -4.5579e-02,\n",
      "        -5.5686e-02,  5.5597e-03, -7.5507e-02,  1.9456e-02,  6.4294e-02,\n",
      "         5.4242e-04, -2.8931e-02, -4.1285e-02, -2.1777e-02,  4.2471e-02,\n",
      "         6.0777e-02,  1.2730e-02, -2.4850e-02, -1.7365e-02,  4.0264e-02,\n",
      "         2.1542e-02,  1.2548e-02,  3.8573e-02,  6.3311e-02, -1.4287e-02,\n",
      "        -4.8139e-02,  1.8181e-02,  1.3290e-02, -5.8238e-02, -7.0985e-02,\n",
      "         4.1016e-02, -2.5835e-02,  2.2467e-02,  2.0982e-02,  4.0115e-02,\n",
      "        -3.0802e-02, -2.7788e-02, -1.8970e-02,  7.0799e-03, -3.6188e-02,\n",
      "        -4.4134e-02, -2.4768e-02, -1.3027e-02,  1.5791e-02,  8.7819e-03,\n",
      "         4.9852e-02,  6.0472e-02, -4.1070e-02,  2.9107e-02, -3.9939e-02,\n",
      "         7.5318e-02,  3.2445e-02, -7.6200e-03,  1.4728e-02, -4.4298e-03,\n",
      "         1.3811e-02, -6.0145e-02, -1.0782e-02,  4.4476e-02, -2.7859e-02,\n",
      "        -2.0916e-02, -2.1481e-02,  5.3303e-02,  8.0490e-03,  1.3052e-02,\n",
      "        -5.4175e-03, -2.3556e-02,  1.4883e-02, -2.5201e-02, -2.9589e-02,\n",
      "        -1.2818e-02,  3.3976e-02, -2.4270e-03, -1.3824e-02, -8.5767e-03,\n",
      "        -6.9345e-02, -1.1385e-02, -1.4028e-02, -5.2728e-03, -5.3059e-03,\n",
      "        -1.4794e-02], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0095,  0.0033, -0.0545,  ...,  0.0001,  0.0025, -0.0048],\n",
      "        [ 0.0606,  0.0346,  0.0883,  ...,  0.0865,  0.0772, -0.0063],\n",
      "        [-0.0252,  0.0071, -0.0209,  ...,  0.0769,  0.0062,  0.0288],\n",
      "        ...,\n",
      "        [ 0.0089,  0.0006,  0.0382,  ...,  0.0940,  0.0043,  0.1152],\n",
      "        [ 0.0082, -0.0191, -0.0091,  ..., -0.0257, -0.0013,  0.0309],\n",
      "        [-0.0229, -0.0387, -0.0229,  ..., -0.0451, -0.0155, -0.0234]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 5.7081e-02,  9.4937e-03,  3.5897e-02,  1.4474e-02,  1.3301e-01,\n",
      "         2.0946e-02,  3.6110e-02, -8.8684e-02,  1.0560e-01,  2.3787e-02,\n",
      "         9.9262e-02, -2.4800e-02,  4.5690e-02,  1.0250e-01,  3.5068e-02,\n",
      "         4.7452e-02,  2.1509e-02, -3.6727e-02,  1.0738e-01,  3.2325e-02,\n",
      "        -7.5153e-02,  5.2168e-02,  1.2967e-01, -1.9652e-02, -2.7555e-02,\n",
      "         1.0363e-02, -1.9085e-01,  5.1898e-02,  2.0515e-01, -1.4763e-01,\n",
      "        -1.2942e-02, -6.4122e-03, -1.0290e-01,  2.8669e-02, -8.4169e-02,\n",
      "        -2.2843e-02, -7.7607e-02, -3.0601e-04, -5.0402e-02, -6.4374e-02,\n",
      "        -6.1647e-02,  9.9798e-03,  2.9228e-02,  6.9525e-02, -5.7876e-02,\n",
      "        -7.3952e-02,  4.5120e-02, -5.2590e-02,  3.6819e-02, -1.1175e-01,\n",
      "        -1.2727e-02,  1.2599e-02, -6.8612e-02, -9.1917e-03,  2.8068e-02,\n",
      "         9.6692e-02,  5.9238e-02, -1.4443e-02,  9.8171e-02, -9.6165e-02,\n",
      "         1.4564e-02,  1.9130e-02, -6.5820e-02, -2.4323e-02, -8.2505e-03,\n",
      "         3.6887e-02, -2.4257e-02,  3.6032e-03, -1.0044e-01, -2.9334e-03,\n",
      "         1.0295e-01, -4.3942e-02, -2.8504e-02,  6.2604e-02,  4.0818e-02,\n",
      "        -1.1207e-01, -1.2886e-02,  1.0591e-01, -3.3758e-02, -2.8162e-03,\n",
      "        -2.3838e-03,  6.2849e-02,  6.9128e-02,  1.2690e-02, -3.6520e-02,\n",
      "        -7.0050e-02, -3.7986e-02,  1.7877e-02, -2.5728e-02,  6.1773e-02,\n",
      "         8.8719e-04, -6.3860e-02, -4.3316e-02,  5.2971e-02, -2.0861e-02,\n",
      "         3.4871e-02, -2.5905e-02, -2.6135e-02, -2.6415e-02, -2.0638e-02,\n",
      "         3.1073e-02,  4.0766e-02, -2.8423e-02, -1.5066e-02, -5.0364e-02,\n",
      "         2.7177e-02, -7.4552e-03, -1.6424e-02, -3.3048e-02,  3.5804e-02,\n",
      "         3.1816e-02, -2.5093e-03,  4.6999e-02, -5.4877e-02,  2.4852e-02,\n",
      "        -4.2608e-02,  1.9005e-02,  1.3923e-02,  1.4300e-02, -2.3209e-02,\n",
      "        -3.0864e-02,  4.2287e-02,  3.0059e-03,  4.7146e-02,  1.8681e-02,\n",
      "        -1.9342e-02, -1.8914e-02,  4.7616e-02, -2.5480e-02, -4.9967e-03,\n",
      "         1.8863e-02, -4.5842e-03,  8.1558e-03, -7.2849e-03,  2.8047e-02,\n",
      "         7.9245e-03,  1.8512e-02, -3.0919e-02,  1.6409e-02, -2.0280e-04,\n",
      "         4.6122e-03,  1.7237e-02, -3.4531e-02, -2.2442e-02, -2.2896e-02,\n",
      "        -1.3506e-02, -9.2417e-03, -2.1803e-02,  1.1940e-02,  1.7791e-02,\n",
      "         4.7101e-03, -1.1840e-02, -1.2249e-02, -1.4090e-02,  2.1850e-02,\n",
      "        -5.9211e-02,  4.6583e-03, -1.1778e-02,  4.8396e-02, -8.3826e-03,\n",
      "         5.3193e-02, -2.8588e-02, -7.9075e-03, -1.3335e-02,  5.9257e-03,\n",
      "        -5.0272e-03, -3.3288e-03, -1.7633e-02, -3.7154e-02, -4.9918e-03,\n",
      "         3.5306e-02,  1.9146e-02,  3.4348e-03,  3.5244e-02, -2.5024e-02,\n",
      "         3.6640e-02,  7.3565e-03, -3.9231e-03,  8.3616e-03, -5.3305e-03,\n",
      "        -2.9103e-03,  6.2276e-02,  1.3758e-02,  2.2477e-02,  3.0594e-02,\n",
      "         8.7246e-03, -1.3255e-02,  4.4243e-03,  2.6328e-02,  5.4816e-03,\n",
      "        -1.3906e-02,  1.4269e-02,  1.0715e-02,  1.5987e-02, -8.1874e-04,\n",
      "         8.5060e-03, -1.1040e-02, -7.5252e-03,  1.1402e-03, -5.1505e-03,\n",
      "         1.9377e-02,  8.9368e-03,  3.3971e-03, -7.6917e-03, -6.0815e-03,\n",
      "         2.1351e-02, -5.4652e-03,  6.5676e-03, -1.4365e-03,  2.2109e-04,\n",
      "        -6.4752e-03, -9.9563e-03,  1.7844e-02, -1.8169e-03, -6.9571e-03,\n",
      "         4.4144e-03, -3.7466e-04,  5.4835e-03, -1.4380e-02, -1.4165e-02,\n",
      "        -1.3476e-02,  1.0891e-03, -9.8000e-03, -2.0895e-04, -5.3043e-03,\n",
      "        -4.5516e-03, -2.3132e-02,  7.5912e-03,  1.8460e-03, -6.3854e-03,\n",
      "        -3.0776e-03,  1.2673e-02,  1.8086e-04,  5.6240e-03,  3.3281e-03,\n",
      "        -5.0759e-03, -7.9064e-03,  8.2673e-03, -6.6281e-03,  7.8256e-03,\n",
      "        -8.0182e-04, -5.6278e-04, -3.2918e-03, -1.6335e-03, -2.8802e-03,\n",
      "         8.3424e-03,  5.2096e-03,  1.1017e-02,  3.1739e-03, -4.8125e-03,\n",
      "        -5.1349e-03,  3.5008e-03, -5.2715e-04,  1.6172e-02,  6.6958e-03,\n",
      "        -2.9319e-03], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0365,  0.0144, -0.0984,  ..., -0.0362, -0.0142,  0.0788],\n",
      "        [-0.0213,  0.0630,  0.0320,  ..., -0.0901,  0.0355, -0.0129],\n",
      "        [ 0.0708,  0.0277, -0.0339,  ..., -0.0178, -0.0898,  0.0369],\n",
      "        ...,\n",
      "        [ 0.0196,  0.0595,  0.0527,  ..., -0.0979, -0.0471, -0.0202],\n",
      "        [ 0.0158,  0.0350, -0.0382,  ...,  0.0582, -0.0572,  0.0741],\n",
      "        [ 0.0438, -0.0757, -0.0666,  ...,  0.0047,  0.0177,  0.0099]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0470,  0.0917, -0.0952, -0.0236,  0.0115, -0.0198,  0.0180, -0.1088,\n",
      "         0.0913, -0.1209,  0.0020,  0.1646, -0.0418,  0.1669,  0.0869, -0.0344,\n",
      "        -0.0460,  0.0120,  0.1084, -0.0241,  0.0902, -0.0654, -0.0796,  0.1079,\n",
      "        -0.0919, -0.0473, -0.0414, -0.0663, -0.0428,  0.0824,  0.0875, -0.0229,\n",
      "        -0.0687, -0.0395, -0.0877, -0.0056,  0.0018,  0.0199, -0.0768,  0.0395,\n",
      "         0.0595, -0.0120,  0.0181,  0.1167,  0.0371, -0.1013,  0.0608, -0.0202,\n",
      "        -0.0964, -0.0774, -0.0060, -0.1279, -0.0124, -0.1421, -0.0183, -0.0648,\n",
      "        -0.0514, -0.0290, -0.0243, -0.0097,  0.0694, -0.0172,  0.0393,  0.1332,\n",
      "        -0.0406, -0.1424, -0.0452,  0.0459,  0.1027, -0.1512,  0.0629, -0.0860,\n",
      "         0.0786, -0.0769, -0.0443,  0.0930, -0.0105,  0.1300,  0.1581, -0.0349,\n",
      "        -0.0522,  0.0088, -0.0249,  0.0108, -0.0103,  0.0563, -0.1308, -0.0358,\n",
      "        -0.0366,  0.0578,  0.0284, -0.1274,  0.0403, -0.0776,  0.0606, -0.0033,\n",
      "        -0.0025,  0.0668,  0.0557, -0.0462, -0.0283,  0.0783,  0.0549,  0.0477,\n",
      "        -0.2148,  0.1278,  0.0656,  0.0157,  0.0794,  0.0310, -0.0237,  0.0962,\n",
      "         0.0365,  0.0770, -0.1384,  0.0935,  0.1233,  0.1000, -0.1374,  0.0675,\n",
      "        -0.0032,  0.0468,  0.1053,  0.0021, -0.1026, -0.0717,  0.0397, -0.0003,\n",
      "         0.0283, -0.0059,  0.0577,  0.0499, -0.0142,  0.0494, -0.1275, -0.0314,\n",
      "         0.0075,  0.0035, -0.0134,  0.0741, -0.1256,  0.0412,  0.0858, -0.0607,\n",
      "        -0.1330, -0.1417, -0.0403, -0.0666, -0.0122,  0.0113, -0.1371, -0.0986,\n",
      "         0.0478, -0.0902,  0.0296, -0.0752, -0.0007,  0.1340,  0.0232,  0.0381,\n",
      "        -0.0499, -0.0760,  0.0326,  0.0423,  0.0413,  0.0696,  0.0046,  0.0267,\n",
      "         0.1147, -0.0203, -0.1773,  0.0032, -0.1281,  0.0323,  0.0450, -0.0226,\n",
      "        -0.1207,  0.0514, -0.0535,  0.0394, -0.0548, -0.0687,  0.0778,  0.1231,\n",
      "        -0.0325, -0.1337, -0.0203, -0.0011, -0.0131,  0.0496,  0.0538, -0.0713,\n",
      "        -0.0672,  0.0915,  0.0326, -0.0926, -0.0679,  0.0455, -0.0411,  0.0443,\n",
      "         0.1859,  0.0723,  0.0304, -0.0353, -0.1175, -0.2778, -0.1158, -0.1274,\n",
      "         0.0426, -0.0057,  0.0986, -0.0456,  0.0936,  0.0452, -0.0344,  0.0258,\n",
      "         0.0199, -0.0367, -0.0791, -0.0786,  0.0401,  0.0094,  0.0497,  0.1356,\n",
      "         0.1412, -0.0661, -0.1103, -0.0127,  0.0079, -0.0113,  0.1220, -0.0372,\n",
      "        -0.0324,  0.1048,  0.0764, -0.0029,  0.0866,  0.1532, -0.0325, -0.1038,\n",
      "        -0.0500, -0.0495,  0.0534,  0.0551,  0.0908, -0.0467,  0.0945,  0.0423,\n",
      "        -0.0353, -0.0125,  0.0321, -0.0364,  0.0037,  0.0950, -0.0049,  0.1200],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.9607, 1.0502, 0.9988, 0.9521, 0.9793, 1.0255, 1.0617, 1.0152, 1.4039,\n",
      "        1.0079, 0.9923, 0.9886, 1.1517, 0.9975, 1.0054, 0.9899, 1.0177, 0.9627,\n",
      "        1.0045, 1.0089, 0.9943, 1.0012, 0.9646, 1.0134, 0.9295, 1.0189, 0.9872,\n",
      "        0.9707, 0.9866, 1.0103, 1.0196, 1.0106, 0.9482, 1.0066, 0.9800, 0.9593,\n",
      "        0.9603, 1.1182, 1.0825, 1.0276, 1.0258, 1.0028, 0.9770, 0.9842, 0.9804,\n",
      "        0.9638, 1.0270, 0.9729, 1.2676, 0.9731, 0.9555, 1.0221, 1.0250, 1.1522,\n",
      "        0.9981, 1.0266, 0.9538, 0.9894, 1.0827, 0.9731, 0.9683, 1.0361, 0.9929,\n",
      "        0.9826, 0.9617, 1.0581, 0.9743, 1.0113, 1.0482, 0.9948, 0.9511, 1.0034,\n",
      "        0.9789, 0.9615, 0.9127, 1.0080, 1.0705, 1.0052, 1.0626, 0.9780, 1.0547,\n",
      "        0.9804, 0.9950, 0.9604, 1.0012, 1.0608, 0.9549, 1.0168, 1.0515, 1.0200,\n",
      "        0.9933, 1.0798, 0.9720, 1.0831, 0.9691, 0.9845, 1.0036, 0.9877, 0.9989,\n",
      "        0.9760, 0.9886, 1.0383, 1.0682, 0.9732, 0.9294, 1.0077, 1.0088, 0.9417,\n",
      "        1.0067, 1.0838, 0.9800, 1.0208, 1.0100, 0.9988, 1.2782, 1.0035, 1.0067,\n",
      "        1.0145, 1.0174, 0.9751, 0.9814, 1.0565, 0.9745, 1.0071, 1.0142, 1.0049,\n",
      "        1.0300, 0.9360, 0.9922, 0.9825, 0.9918, 0.9844, 1.0664, 0.9815, 1.0685,\n",
      "        1.0009, 1.0363, 1.0089, 1.1136, 1.0732, 1.2010, 1.0170, 1.0413, 0.9960,\n",
      "        0.9711, 1.0322, 1.0089, 1.0223, 0.9737, 1.0034, 0.9674, 0.9912, 0.9995,\n",
      "        1.0193, 1.1204, 1.0375, 1.0706, 0.9908, 1.0011, 1.0067, 1.0212, 1.0333,\n",
      "        1.0533, 1.0963, 0.9880, 1.0035, 0.9490, 1.0106, 1.0009, 0.9691, 1.0091,\n",
      "        1.0218, 1.6151, 0.9387, 0.9946, 0.9859, 1.1203, 0.9606, 0.9922, 1.0086,\n",
      "        0.9625, 1.0208, 0.9950, 0.9828, 0.9921, 1.0003, 0.9674, 0.9653, 0.9879,\n",
      "        0.9509, 1.2152, 1.0090, 1.0604, 1.0678, 0.9889, 1.0232, 0.9790, 0.9561,\n",
      "        0.9916, 1.0215, 1.0452, 1.0083, 0.9292, 0.9801, 1.0359, 1.3229, 0.9763,\n",
      "        0.9967, 0.9499, 0.9676, 1.0198, 1.0015, 1.0148, 0.9435, 0.9334, 0.9827,\n",
      "        0.9967, 1.0236, 0.9756, 0.9905, 0.9618, 1.0327, 1.0120, 1.0134, 1.0198,\n",
      "        0.9870, 1.0329, 1.0270, 0.9909, 0.9985, 0.9923, 0.9944, 0.9519, 0.9980,\n",
      "        0.9608, 0.9873, 0.9985, 1.0141, 0.9975, 1.0095, 1.0609, 0.9858, 0.9851,\n",
      "        1.2695, 0.9938, 1.0002, 1.0065, 1.0125, 1.0624, 0.9683, 1.0417, 1.0235,\n",
      "        1.0079, 1.0094, 0.9790, 0.9928], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 3.0630e-02,  2.3460e-01, -5.1730e-04, -4.9329e-02,  4.7556e-03,\n",
      "         1.7750e-02, -1.8427e-01, -8.2607e-02, -4.1991e-01, -8.1371e-02,\n",
      "         5.8949e-02,  4.9967e-02,  5.0258e-01,  6.6474e-03,  1.9998e-01,\n",
      "        -1.5105e-01,  1.3431e-02, -4.7105e-02,  1.0487e-01,  2.8384e-02,\n",
      "         1.2148e-01,  4.0586e-02, -2.2666e-02,  2.6119e-03, -1.3536e-02,\n",
      "         6.1397e-02, -1.3939e-01, -2.8744e-02,  9.7436e-02,  7.2952e-02,\n",
      "        -2.2344e-02,  8.7343e-02, -8.5361e-04, -1.3410e-01, -4.3912e-02,\n",
      "         4.2544e-02,  3.3063e-02,  2.6390e-01, -1.8318e-01, -1.9519e-01,\n",
      "        -2.8616e-03, -6.1187e-02,  8.4968e-02, -3.6233e-02,  2.4546e-03,\n",
      "         4.8311e-02, -1.2671e-02, -3.6989e-02, -3.0424e-02, -9.7928e-02,\n",
      "         3.0149e-02, -2.9879e-03,  4.6784e-02,  6.4783e-02, -5.0377e-02,\n",
      "        -8.3384e-02, -8.3896e-02,  4.4080e-02,  1.7769e-01, -1.7463e-02,\n",
      "         7.1572e-02,  2.6860e-03, -4.8224e-02, -1.2665e-01,  2.9068e-02,\n",
      "        -1.4622e-01,  8.5072e-04,  9.1824e-02, -5.6699e-03,  4.4865e-02,\n",
      "         3.2361e-02, -6.2175e-02,  1.9639e-02,  5.7000e-02,  2.9973e-02,\n",
      "         3.0416e-02,  5.4551e-02,  7.4156e-03,  1.3131e-01, -4.6062e-03,\n",
      "        -5.5730e-02, -1.2153e-02,  3.9130e-02,  7.4578e-02,  2.9891e-02,\n",
      "        -1.0045e-01, -1.7314e-02,  1.2232e-01, -5.9393e-02,  3.0092e-01,\n",
      "         1.5674e-02, -1.1214e-01,  4.6964e-02,  5.0302e-01,  5.8648e-02,\n",
      "         8.1714e-02,  2.8048e-02,  7.4191e-02, -4.9536e-02,  5.7530e-02,\n",
      "        -6.1101e-02,  3.9989e-02, -5.9853e-02, -4.5743e-03,  7.8258e-02,\n",
      "         4.1251e-02, -5.4877e-03, -1.1064e-02,  5.6787e-02, -3.6624e-01,\n",
      "        -5.0822e-02,  1.9833e-02, -5.5570e-02, -3.2358e-02,  2.5240e-01,\n",
      "        -1.1061e-02, -6.0045e-03,  3.6087e-02,  1.8008e-02,  3.0698e-02,\n",
      "         6.2603e-02,  1.2697e-02,  3.9399e-02, -5.2082e-02,  1.3836e-01,\n",
      "         1.7208e-02,  1.6067e-01,  1.0202e-02, -1.6848e-02,  2.8475e-02,\n",
      "         2.1448e-03, -1.8016e-02,  6.0330e-03,  2.8406e-02, -1.3855e-01,\n",
      "        -1.2674e-01, -6.7189e-02, -3.1313e-02, -3.3864e-01, -1.3948e-01,\n",
      "         4.5129e-01,  1.0971e-01,  1.1238e-01,  1.1949e-04, -4.0578e-02,\n",
      "        -4.5835e-02, -6.2649e-02,  7.8701e-02,  1.6686e-02, -3.4291e-02,\n",
      "         3.3224e-02,  8.7847e-03, -1.3744e-02,  5.7415e-02, -2.1124e-01,\n",
      "         1.3091e-01,  1.7716e-01,  6.6378e-02, -6.7407e-02, -1.9361e-02,\n",
      "        -7.5460e-02,  4.4593e-02, -2.3042e-01, -3.4067e-01, -5.0525e-02,\n",
      "         2.0509e-02,  5.9857e-02, -1.0259e-01,  2.4921e-02,  5.4175e-02,\n",
      "        -7.9221e-02, -5.7431e-02,  1.7582e+00,  3.0088e-03, -3.1242e-02,\n",
      "        -2.6507e-02,  3.4031e-02,  2.5919e-02,  1.0335e-01,  8.6144e-02,\n",
      "        -5.6050e-02,  4.8389e-02,  6.2283e-02,  6.9064e-02,  5.3293e-02,\n",
      "        -3.6621e-02, -6.4885e-03,  7.9310e-02, -3.5737e-03, -3.1962e-02,\n",
      "         1.1502e-01, -6.7398e-02,  7.9364e-03,  5.6057e-02, -2.3105e-03,\n",
      "        -5.6272e-02, -1.3259e-02, -2.5787e-02,  9.0442e-02,  2.9741e-02,\n",
      "        -1.6275e-01,  5.9982e-02, -1.9292e-02, -4.0746e-02,  6.4424e-03,\n",
      "         4.6659e-01,  4.7798e-02, -8.0501e-02,  5.4277e-02, -3.0321e-02,\n",
      "         6.4624e-03,  1.2147e-01,  5.2346e-02, -9.1359e-03, -5.5610e-02,\n",
      "        -2.8568e-03, -5.6057e-02,  5.2469e-02,  5.0544e-03, -1.2043e-02,\n",
      "         3.7316e-02, -1.6162e-02,  2.1346e-02, -4.1474e-02, -2.9694e-03,\n",
      "        -1.8936e-02, -1.5839e-02, -4.0021e-02,  9.0628e-02,  4.1732e-02,\n",
      "         4.3278e-02,  4.6495e-02,  2.6198e-02, -1.9891e-02,  3.6949e-03,\n",
      "        -7.9123e-03, -1.1483e-01,  1.0158e-01,  1.8477e-02, -1.2930e-02,\n",
      "        -1.2561e-01, -5.4256e-02, -2.3722e-02, -2.7595e-01,  3.9103e-02,\n",
      "        -2.3482e-02,  8.5949e-02,  1.4963e-01, -3.0673e-01, -7.0097e-02,\n",
      "        -9.7923e-02,  1.3557e-01, -7.0708e-02,  1.0236e-01,  6.0417e-03,\n",
      "        -3.9513e-02], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0261,  0.0376, -0.0512,  ...,  0.0287,  0.0362,  0.1145],\n",
      "        [ 0.0267, -0.0609,  0.0208,  ...,  0.0315, -0.0421,  0.0132],\n",
      "        [-0.0486, -0.0859, -0.0304,  ..., -0.0180, -0.0175,  0.0002],\n",
      "        ...,\n",
      "        [-0.0988, -0.0108,  0.0382,  ...,  0.0269,  0.0451,  0.0535],\n",
      "        [ 0.1484,  0.0494, -0.0999,  ..., -0.0319,  0.1082,  0.0605],\n",
      "        [-0.0797, -0.0679, -0.0126,  ..., -0.0104,  0.0354,  0.0476]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0115, -0.4979,  0.0443,  ...,  0.1021, -0.2266, -0.0149],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0417, -0.0427, -0.0962,  ...,  0.0423, -0.1532,  0.0867],\n",
      "        [-0.0222,  0.0334, -0.0331,  ...,  0.0002,  0.0101,  0.0171],\n",
      "        [ 0.0753, -0.0077,  0.0129,  ...,  0.0038, -0.0616,  0.0972],\n",
      "        ...,\n",
      "        [-0.0240, -0.0175,  0.0884,  ...,  0.0296,  0.0185,  0.0473],\n",
      "        [-0.0064,  0.0141,  0.1068,  ..., -0.0601, -0.0252, -0.0379],\n",
      "        [-0.0395, -0.0106,  0.0753,  ..., -0.0775,  0.1101, -0.0193]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0036, -0.0645,  0.0565, -0.0392, -0.0014, -0.0551,  0.0190,  0.0352,\n",
      "        -0.0609, -0.0105, -0.0306, -0.0416, -0.0630, -0.0353,  0.0105, -0.0153,\n",
      "        -0.0348, -0.0405, -0.0042,  0.0306, -0.0150, -0.0096,  0.0573, -0.0269,\n",
      "        -0.0346, -0.0102,  0.0760, -0.0644,  0.0216, -0.0225, -0.0299,  0.0442,\n",
      "        -0.0387, -0.0569, -0.0011, -0.0327, -0.0238, -0.0470, -0.0024,  0.0510,\n",
      "        -0.0524,  0.1394, -0.0113,  0.0048,  0.0287, -0.0540,  0.0170, -0.0070,\n",
      "         0.1079,  0.0048,  0.0373,  0.0070,  0.0236,  0.0985, -0.0513, -0.0653,\n",
      "         0.0675,  0.0112,  0.0264,  0.0348, -0.0262,  0.0507,  0.0255,  0.0562,\n",
      "        -0.0043,  0.0245, -0.0010,  0.0094, -0.0042,  0.0525,  0.0400,  0.0896,\n",
      "        -0.0517,  0.0094,  0.0607, -0.0599,  0.0631,  0.0111, -0.0159,  0.0376,\n",
      "         0.0234,  0.0250,  0.0263,  0.0186, -0.0219,  0.0086,  0.0856,  0.0781,\n",
      "         0.0073, -0.0049,  0.0190,  0.0291,  0.0199, -0.0196, -0.0762,  0.0742,\n",
      "        -0.0150, -0.0683, -0.0199,  0.0105, -0.0154, -0.0360,  0.0620, -0.0221,\n",
      "         0.0528,  0.0530, -0.0554, -0.0391,  0.0153,  0.0810,  0.0303,  0.0002,\n",
      "         0.0390, -0.0572, -0.0149, -0.0149, -0.0637, -0.0373,  0.0188, -0.0220,\n",
      "         0.0153, -0.1046, -0.0515,  0.0324,  0.0049,  0.0840, -0.0304,  0.0087,\n",
      "        -0.0036,  0.0041, -0.0104, -0.0014,  0.0166,  0.0052,  0.0571, -0.0401,\n",
      "         0.0508,  0.0546,  0.0146, -0.0449, -0.0304, -0.0592,  0.0153, -0.0578,\n",
      "         0.0007, -0.0021, -0.0418, -0.0179,  0.0627,  0.0050,  0.0566,  0.0624,\n",
      "         0.0117,  0.0230,  0.0783,  0.0046, -0.0208, -0.0260, -0.0141, -0.0222,\n",
      "         0.0707,  0.0077,  0.0118,  0.0466, -0.0417, -0.0273, -0.0011,  0.0015,\n",
      "        -0.0339,  0.0160,  0.0427,  0.0288, -0.0505, -0.0341,  0.0080, -0.0062,\n",
      "        -0.0363, -0.0004,  0.0423, -0.0648, -0.0054,  0.0223, -0.0583, -0.0615,\n",
      "        -0.0017,  0.0013,  0.0405,  0.0028, -0.0783, -0.0618, -0.0904,  0.0631,\n",
      "         0.0359, -0.0096, -0.0205,  0.0109, -0.0184,  0.0471,  0.0415, -0.0214,\n",
      "        -0.0357, -0.0125, -0.0303,  0.0179, -0.0514, -0.0311,  0.0765, -0.0059,\n",
      "        -0.0094,  0.0507,  0.0568, -0.0283, -0.0271, -0.0265,  0.0283, -0.0464,\n",
      "         0.0036,  0.0036, -0.0172, -0.0173,  0.0084, -0.0350, -0.0300, -0.0365,\n",
      "        -0.0407,  0.0768,  0.0344, -0.0162,  0.0536, -0.0741, -0.0249,  0.0402,\n",
      "         0.0415, -0.0160, -0.0372, -0.0471, -0.0293, -0.0203,  0.0408,  0.0387,\n",
      "        -0.0037,  0.0013, -0.0128,  0.1938, -0.0269,  0.0079, -0.0426, -0.0787,\n",
      "        -0.0302,  0.0381, -0.0040,  0.0107,  0.0297, -0.0055,  0.0371, -0.0205],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.1362, 1.2631, 1.1450, 1.2386, 1.1908, 1.2092, 1.2332, 1.2250, 1.2206,\n",
      "        1.2451, 1.2722, 1.2648, 1.2591, 1.2168, 1.2788, 1.2465, 1.1497, 1.2989,\n",
      "        1.2629, 1.2132, 1.2282, 1.2096, 1.2449, 1.2371, 1.2539, 1.2018, 1.2421,\n",
      "        1.2412, 1.2477, 1.2224, 1.1946, 1.2220, 1.2247, 1.2023, 1.2704, 1.2386,\n",
      "        1.2298, 1.2518, 1.2399, 1.2013, 1.2536, 1.0897, 1.2286, 1.1941, 1.2103,\n",
      "        1.2745, 1.1359, 1.2613, 1.0559, 1.2265, 1.2049, 1.2551, 1.2407, 1.1387,\n",
      "        1.2161, 1.2521, 1.2475, 1.2542, 0.8771, 1.2659, 1.2442, 1.2395, 1.2648,\n",
      "        1.2295, 1.2335, 1.1590, 1.2221, 1.2261, 1.2395, 1.2462, 1.2732, 1.2129,\n",
      "        1.2476, 1.1885, 1.2504, 1.2537, 1.2606, 1.1821, 1.1537, 1.2119, 1.2563,\n",
      "        1.1959, 1.1971, 1.1857, 1.2691, 1.2119, 1.2051, 1.2139, 1.2684, 1.2599,\n",
      "        1.1005, 1.0306, 1.2731, 1.1599, 1.2597, 1.2159, 1.2279, 1.1691, 1.2163,\n",
      "        1.2159, 1.1957, 1.2516, 1.2226, 1.2720, 1.1228, 1.2216, 1.1745, 1.1963,\n",
      "        1.2672, 1.2386, 1.2198, 1.2590, 1.2771, 1.2334, 1.1759, 1.2149, 1.2356,\n",
      "        1.2305, 1.2087, 1.2264, 1.2861, 1.2173, 1.2011, 1.2402, 1.2017, 1.1980,\n",
      "        1.1977, 1.2077, 1.3353, 1.2470, 1.2190, 1.2887, 1.1742, 1.2503, 1.2300,\n",
      "        1.2356, 1.1824, 1.2511, 0.8630, 1.2576, 1.1653, 1.2377, 1.2343, 1.2601,\n",
      "        1.2400, 1.2452, 1.2132, 1.1903, 1.1978, 1.1717, 1.1722, 1.2607, 1.2161,\n",
      "        1.3199, 1.2085, 1.1253, 1.1991, 1.1886, 1.1896, 1.2169, 1.2006, 1.2177,\n",
      "        1.2296, 1.0012, 1.3018, 1.2078, 1.2062, 1.2342, 1.2171, 1.2434, 1.2661,\n",
      "        1.2470, 0.5275, 1.2089, 1.2660, 1.3027, 1.2256, 1.2031, 1.2090, 1.2310,\n",
      "        1.2738, 1.2526, 1.1881, 1.2638, 1.2679, 1.2640, 1.2046, 1.2477, 1.2485,\n",
      "        1.1477, 1.1704, 1.2207, 1.1014, 1.2463, 1.1232, 1.2239, 1.2737, 1.1725,\n",
      "        1.2653, 1.2296, 1.0938, 1.2436, 1.1626, 1.2491, 1.1544, 0.8699, 1.2075,\n",
      "        1.1893, 1.2613, 1.2383, 1.1906, 1.2165, 1.2339, 1.2356, 1.2145, 1.2246,\n",
      "        1.2289, 1.2176, 1.2147, 1.2779, 1.2156, 1.2637, 1.1638, 1.2526, 1.1685,\n",
      "        1.2283, 1.2699, 1.2096, 1.2399, 1.1933, 1.2323, 1.2380, 1.2005, 1.2422,\n",
      "        1.2549, 1.2603, 1.1953, 1.1343, 1.2153, 1.2314, 1.0721, 1.2098, 1.2538,\n",
      "        0.8293, 1.2434, 1.1766, 1.1855, 1.2713, 1.2146, 1.1859, 1.2722, 1.1967,\n",
      "        1.2533, 1.1954, 1.2033, 1.3405], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 1.1204e-02,  3.0044e-02,  4.7514e-02, -2.7316e-02,  4.1139e-02,\n",
      "        -4.8397e-02,  1.1767e-02, -1.1245e-02, -9.1970e-02, -7.0652e-03,\n",
      "        -2.8740e-02, -1.5427e-02,  1.2584e-01,  1.9101e-02,  5.0620e-02,\n",
      "        -1.2271e-03,  2.7113e-02,  6.7334e-02, -7.4394e-02, -3.2273e-02,\n",
      "        -4.0873e-02, -3.3657e-02,  2.4347e-02, -7.0067e-02, -2.2859e-02,\n",
      "         1.3300e-02,  5.3392e-02,  8.7362e-02,  1.2896e-01, -1.0652e-02,\n",
      "        -3.9323e-02, -4.7317e-02,  3.9542e-02,  4.2495e-03,  5.3550e-02,\n",
      "         1.4690e-02, -9.2842e-02,  2.7292e-02, -4.2417e-02, -3.5778e-02,\n",
      "        -5.0272e-02,  1.1144e-01,  1.8718e-02, -3.4187e-02,  4.9793e-02,\n",
      "        -2.8200e-02,  5.9278e-02,  3.5113e-02,  1.7017e-01, -2.2391e-03,\n",
      "         3.3869e-02,  3.0305e-02, -3.3392e-02,  8.9509e-02, -1.0456e-01,\n",
      "         8.2791e-03, -1.2664e-02,  2.3441e-02, -4.9811e-02,  4.4234e-02,\n",
      "         7.4949e-03, -1.2128e-02,  3.5178e-02, -1.9004e-02, -1.4090e-02,\n",
      "         5.2449e-02,  6.3435e-02, -6.2404e-02, -3.4291e-02, -4.5749e-03,\n",
      "        -1.5964e-02,  6.7673e-02, -5.1874e-03,  3.7942e-02,  4.4245e-02,\n",
      "        -1.3906e-02,  1.5857e-02,  3.4593e-02, -7.3573e-02, -1.5846e-02,\n",
      "         4.8238e-02,  3.4781e-02, -1.5532e-02,  5.3215e-02, -1.1664e-02,\n",
      "        -7.7435e-03,  9.1653e-02,  2.0535e-02,  5.0094e-02,  1.3769e-02,\n",
      "        -8.5059e-02,  7.3696e-02, -2.6509e-02,  2.1922e-01, -2.1250e-02,\n",
      "         1.1030e-02, -1.2503e-02, -2.1786e-02,  9.4675e-02,  2.8897e-02,\n",
      "        -2.5524e-02,  2.6754e-02,  4.6087e-02,  1.0062e-02, -3.0255e-04,\n",
      "        -1.5025e-02,  1.4073e-03,  9.8348e-04,  6.4346e-03, -3.9845e-02,\n",
      "         4.3301e-02, -2.4845e-02,  3.6646e-02,  4.2875e-03,  7.7394e-02,\n",
      "        -1.1329e-02, -3.2186e-02, -3.2444e-02,  1.4928e-02,  3.4439e-04,\n",
      "         5.1877e-02, -2.6987e-02,  3.9658e-03, -4.9805e-02,  1.7194e-04,\n",
      "         2.0300e-02, -3.6198e-02,  5.3637e-02,  2.7264e-02, -3.4831e-02,\n",
      "        -8.5552e-02, -3.7770e-02, -5.8650e-02,  5.8317e-03,  1.2525e-02,\n",
      "        -1.8350e-02, -4.7067e-02,  9.4605e-02, -2.0911e-02, -6.7104e-02,\n",
      "         7.9093e-02, -1.1045e-02,  3.7559e-02,  4.1427e-02, -4.7110e-03,\n",
      "         2.4780e-02, -2.9140e-02, -1.6165e-02,  7.1190e-02,  5.0111e-02,\n",
      "         4.9773e-02,  6.0704e-02, -5.1748e-06,  1.5454e-02,  9.6651e-02,\n",
      "        -2.6353e-02, -7.6640e-02,  4.9827e-02, -3.0066e-02,  3.4317e-02,\n",
      "        -3.1517e-03,  3.7694e-02, -1.0514e-01,  6.8397e-02, -4.7147e-02,\n",
      "        -8.0042e-04,  2.7508e-02,  5.8459e-02, -3.9849e-02, -6.4349e-03,\n",
      "        -1.6724e-02,  7.0500e-02,  4.1142e-01,  2.3239e-02, -9.9715e-03,\n",
      "        -1.0679e-02, -3.6362e-02, -9.2111e-03,  1.8167e-03,  5.3014e-02,\n",
      "         3.8940e-02,  2.4482e-02, -4.0023e-02,  1.6135e-02,  2.9111e-02,\n",
      "        -2.6326e-02, -4.7499e-03,  2.6920e-02, -1.2108e-02,  9.9643e-03,\n",
      "         1.1687e-01,  7.0469e-03,  9.7841e-02, -1.3165e-02, -2.3962e-02,\n",
      "         3.5497e-02, -2.9607e-02, -2.7529e-02,  1.6400e-02,  3.3692e-02,\n",
      "         3.7272e-02, -2.3467e-02,  8.0064e-03,  1.6868e-02, -2.7913e-02,\n",
      "         4.6372e-01,  2.3560e-02, -3.9941e-02, -1.4653e-02, -1.2897e-02,\n",
      "        -6.8099e-03,  1.6641e-03, -1.1672e-01,  3.8175e-02, -1.4449e-02,\n",
      "        -1.4293e-02,  1.4530e-03,  5.9361e-02, -2.0251e-02,  8.0493e-02,\n",
      "        -1.2167e-02, -2.1653e-02,  5.5952e-04, -1.1882e-02, -8.1105e-02,\n",
      "        -6.6240e-02,  2.4232e-02,  2.2008e-02,  6.5442e-03, -9.5476e-03,\n",
      "         1.2586e-02,  7.8051e-02,  4.0425e-03,  1.6857e-02,  6.1504e-02,\n",
      "        -1.7522e-02,  3.1420e-02, -4.3196e-02,  2.1348e-02,  2.8221e-02,\n",
      "        -1.3428e-02,  4.4096e-02,  1.7183e-02,  1.4041e-01, -2.2713e-02,\n",
      "        -2.4814e-02, -9.8954e-02, -2.8787e-02, -7.4009e-02,  2.6151e-02,\n",
      "        -3.2733e-02,  8.9789e-03, -2.4487e-02, -1.6375e-02,  1.5338e-02,\n",
      "        -6.1263e-02], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in self.base_model.encoder.layer[0].parameters():\n",
    "    print(p.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.base_model.encoder.layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, torch.Size([2, 512, 256]), torch.Size([2, 512, 256]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_model_outputs.past_key_values), base_model_outputs.past_key_values[0].shape, base_model_outputs.past_key_values[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, torch.Size([2, 512, 256]), torch.Size([2, 512, 256]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out['hidden_states']), out['hidden_states'][0].shape, out['hidden_states'][-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/booydar/Desktop/MIPT/memory_experiments/notebooks/debug_rmt.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/booydar/Desktop/MIPT/memory_experiments/notebooks/debug_rmt.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m1\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m0\u001b[39;49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmt.model.base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'logits', 'hidden_states'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out['hidden_states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'logits', 'hidden_states'])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = forward(self.model, **seg_kwargs, output_hidden_states=True, use_cache=True)\n",
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(per_device_train_batch_size=2, per_device_eval_batch_size=1, output_dir=\"test_trainer\", evaluation_strategy=\"epoch\", no_cuda=True, max_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented_inputs = np.load('augmented_inputs.npy', allow_pickle=True)\n",
    "# attn_masks = np.load('attention_masks.npy', allow_pickle=True)\n",
    "# tokenizer.decode(augmented_inputs[0][512:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set  don't have a corresponding argument in `RMTEncoderForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RMTEncoderForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[  101, 29206, 29207,  ...,     0,     0,     0],\n",
      "        [  101, 29206, 29207,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [21:23<?, ?it/s]\n",
      "  0%|          | 0/5 [20:56<?, ?it/s]\n",
      "  0%|          | 0/5 [14:10<?, ?it/s]\n",
      "  0%|          | 0/5 [11:58<?, ?it/s]\n",
      "  0%|          | 0/5 [07:14<?, ?it/s]\n",
      "  0%|          | 0/5 [06:41<?, ?it/s]\n",
      "  0%|          | 0/5 [04:25<?, ?it/s]\n",
      "  0%|          | 0/5 [03:41<?, ?it/s]\n",
      "  0%|          | 0/5 [02:55<?, ?it/s]\n",
      "  0%|          | 0/5 [02:18<?, ?it/s]\n",
      "  0%|          | 0/5 [01:49<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/booydar/Desktop/MIPT/memory_experiments/debug_rmt.ipynb Cell 24'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/booydar/Desktop/MIPT/memory_experiments/debug_rmt.ipynb#ch0000035?line=0'>1</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/booydar/Desktop/MIPT/memory_experiments/debug_rmt.ipynb#ch0000035?line=1'>2</a>\u001b[0m     model\u001b[39m=\u001b[39mrmt,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/booydar/Desktop/MIPT/memory_experiments/debug_rmt.ipynb#ch0000035?line=2'>3</a>\u001b[0m     \u001b[39m# model=classic_bert,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/booydar/Desktop/MIPT/memory_experiments/debug_rmt.ipynb#ch0000035?line=6'>7</a>\u001b[0m     compute_metrics\u001b[39m=\u001b[39mcompute_metrics,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/booydar/Desktop/MIPT/memory_experiments/debug_rmt.ipynb#ch0000035?line=7'>8</a>\u001b[0m )\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/booydar/Desktop/MIPT/memory_experiments/debug_rmt.ipynb#ch0000035?line=8'>9</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py:1400\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py?line=1397'>1398</a>\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py?line=1398'>1399</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py?line=1399'>1400</a>\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py?line=1401'>1402</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py?line=1402'>1403</a>\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py?line=1403'>1404</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py?line=1404'>1405</a>\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py?line=1405'>1406</a>\u001b[0m ):\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py?line=1406'>1407</a>\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py?line=1407'>1408</a>\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py:1984\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py?line=1980'>1981</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py?line=1982'>1983</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautocast_smart_context_manager():\n\u001b[0;32m-> <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py?line=1983'>1984</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py?line=1985'>1986</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py?line=1986'>1987</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py:2016\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py?line=2013'>2014</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py?line=2014'>2015</a>\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py?line=2015'>2016</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py?line=2016'>2017</a>\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py?line=2017'>2018</a>\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/trainer.py?line=2018'>2019</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;32m/home/booydar/Desktop/MIPT/memory_experiments/debug_rmt.ipynb Cell 16'\u001b[0m in \u001b[0;36mRMTEncoderForSequenceClassification.__call__\u001b[0;34m(self, input_ids, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/booydar/Desktop/MIPT/memory_experiments/debug_rmt.ipynb#ch0000018?line=73'>74</a>\u001b[0m     seg_kwargs[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m attention_mask\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/booydar/Desktop/MIPT/memory_experiments/debug_rmt.ipynb#ch0000018?line=74'>75</a>\u001b[0m     seg_kwargs[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m token_type_ids\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/booydar/Desktop/MIPT/memory_experiments/debug_rmt.ipynb#ch0000018?line=76'>77</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mseg_kwargs, output_hidden_states\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/booydar/Desktop/MIPT/memory_experiments/debug_rmt.ipynb#ch0000018?line=77'>78</a>\u001b[0m     memory \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mhidden_states[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][:, :\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_mem_tokens]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/booydar/Desktop/MIPT/memory_experiments/debug_rmt.ipynb#ch0000018?line=79'>80</a>\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:1545\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1536'>1537</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1537'>1538</a>\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1538'>1539</a>\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1539'>1540</a>\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1540'>1541</a>\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1541'>1542</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1542'>1543</a>\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1544'>1545</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1545'>1546</a>\u001b[0m     input_ids,\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1546'>1547</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1547'>1548</a>\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1548'>1549</a>\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1549'>1550</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1550'>1551</a>\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1551'>1552</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1552'>1553</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1553'>1554</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1554'>1555</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1556'>1557</a>\u001b[0m pooled_output \u001b[39m=\u001b[39m outputs[\u001b[39m1\u001b[39m]\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1558'>1559</a>\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m~/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:996\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=986'>987</a>\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=988'>989</a>\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=989'>990</a>\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=990'>991</a>\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=993'>994</a>\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=994'>995</a>\u001b[0m )\n\u001b[0;32m--> <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=995'>996</a>\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=996'>997</a>\u001b[0m     embedding_output,\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=997'>998</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=998'>999</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=999'>1000</a>\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1000'>1001</a>\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1001'>1002</a>\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1002'>1003</a>\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1003'>1004</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1004'>1005</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1005'>1006</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1006'>1007</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1007'>1008</a>\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1008'>1009</a>\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=575'>576</a>\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=576'>577</a>\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=577'>578</a>\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=581'>582</a>\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=582'>583</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=583'>584</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=584'>585</a>\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=585'>586</a>\u001b[0m         hidden_states,\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=586'>587</a>\u001b[0m         attention_mask,\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=587'>588</a>\u001b[0m         layer_head_mask,\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=588'>589</a>\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=589'>590</a>\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=590'>591</a>\u001b[0m         past_key_value,\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=591'>592</a>\u001b[0m         output_attentions,\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=592'>593</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=594'>595</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=595'>596</a>\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:513\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=509'>510</a>\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=510'>511</a>\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=512'>513</a>\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=513'>514</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=514'>515</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=515'>516</a>\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=517'>518</a>\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/modeling_utils.py:2472\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=2468'>2469</a>\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=2469'>2470</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[0;32m-> <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/modeling_utils.py?line=2471'>2472</a>\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[0;32m~/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:525\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=523'>524</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[0;32m--> <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=524'>525</a>\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate(attention_output)\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=525'>526</a>\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=526'>527</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:426\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=424'>425</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states):\n\u001b[0;32m--> <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=425'>426</a>\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=426'>427</a>\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=427'>428</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/linear.py?line=101'>102</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///home/booydar/anaconda3/envs/dpenv/lib/python3.8/site-packages/torch/nn/modules/linear.py?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=rmt,\n",
    "    # model=classic_bert,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = SequentialSampler(small_train_dataset)\n",
    "dl = DataLoader(small_train_dataset, sampler=sampler, batch_size=4)\n",
    "gen = dl.__iter__()\n",
    "s = next(gen)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15ebdd31b1273fe4d2b1fe1822219a570cf61693f7cab545dbe286c10cf9691f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('dpenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
